title,companyName,location,via,description,jobHighlights,relatedLinks,extras,metadata,applyLink,query,run_time
Data Analyst,Royal Bank of Canada,Toronto,via RBC Careers,"Job Summary

Job Description

What is the opportunity?

You will join an experienced Investor Services Data and Analytics team to provide senior stakeholders with the relevant insights to make better informed decisions and achieve business goals. In this role, you will interact with multiple stakeholders across multiple lines of business to deliver analytical assets and data-driven solutions.

Successful candidate will look to take initiative when trying to solve abstract problems through creativity and structure. The candidate must demonstrate a Growth Mindset and be willing to learn and absorb concepts “on the job”.

What will you do?
• Collaborate with cross-functional teams to develop data-driven solutions by leading the complete data analysis and discovery
• Present insights to stakeholders by collecting, interpreting and analyzing structured (e.g. MySQL databases)/unstructured data (e.g. pdf’s)
• Apply hands on experience and knowledge for the development and maintenance of... business intelligence solutions
• Leverage visualization tools/packages to create powerful representations of results

What do you need to succeed?

Must-have
• An undergraduate degree in Business, Computer Science, Data Science, Mathematics, or other quantitative disciplines with 2+ years experience analyzing large volumes of data/building analytical asset
• Advanced Python coding skills and hands on experience with data analysis and transformation packages such as Pandas and Numpy
• Familiarity with database and query languages (e.g. SQL)
• Strong communication and presentation skills
• Must be a self-starter, with strong analytical and interpersonal skills, as well as the ability to work in a fast-paced environment and manage multiple competing priorities
• Attention to detail, organization, ability to multitask and time management is critical
• Exceptional problem-solving skills and ability to conceptualize strategy

Nice-to-have
• Experience in working with data science platforms like Dataiku, Azure Databricks, AWS
• Strong working knowledge of developing Power BI reports/dashboards
• Familiarity with ML concepts, NLP, and text analytics methods and packages

What’s in it for you?

We thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients thrive and communities prosper. We care about each other, reaching our potential, making a difference to our communities, and achieving success that is mutual.
• Excellent exposure to communicate with various business partners and stakeholders in Investor Services and within other platforms as appropriate
• Working with an exciting, close-knit, supportive & dynamic group
• Opportunity to collaborate with other business segments within the bank
• Excellent career development and progression opportunities
• A comprehensive Total Rewards Program including bonuses and flexible benefits
• Competitive compensation

Job Skills
Analytical Thinking, Business Analytics, Business Intelligence (BI), Critical Thinking, Data Mining, Data Modeling, Detail-Oriented, Group Problem Solving, Technical Problem-Solving

Additional Job Details

Address:

RBC CENTRE, 155 WELLINGTON ST W:TORONTO

City:

TORONTO

Country:

Canada

Work hours/week:

37.5

Employment Type:

Full time

Platform:

Wealth Management

Job Type:

Regular

Pay Type:

Salaried

Posted Date:

2024-04-12

Application Deadline:

2024-04-19

Inclusion and Equal Opportunity Employment

At RBC, we embrace diversity and inclusion for innovation and growth. We are committed to building inclusive teams and an equitable workplace for our employees to bring their true selves to work. We are taking actions to tackle issues of inequity and systemic bias to support our diverse talent, clients and communities.
​​​​​​​
We also strive to provide an accessible candidate experience for our prospective employees with different abilities. Please let us know if you need any accommodations during the recruitment process.

Join our Talent Community

Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.

Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at jobs.rbc.com","[{'items': ['Job Summary\n\nJob Description\n\nWhat is the opportunity?\n\nYou will join an experienced Investor Services Data and Analytics team to provide senior stakeholders with the relevant insights to make better informed decisions and achieve business goals. In this role, you will interact with multiple stakeholders across multiple lines of business to deliver analytical assets and data-driven solutions.\n\nSuccessful candidate will look to take initiative when trying to solve abstract problems through creativity and structure. The candidate must demonstrate a Growth Mindset and be willing to learn and absorb concepts “on the job”.\n\nWhat will you do?\n• Collaborate with cross-functional teams to develop data-driven solutions by leading the complete data analysis and discovery\n• Present insights to stakeholders by collecting, interpreting and analyzing structured (e.g. MySQL databases)/unstructured data (e.g. pdf’s)\n• Apply hands on experience and knowledge for the development and maintenance of... business intelligence solutions\n• Leverage visualization tools/packages to create powerful representations of results\n\nWhat do you need to succeed?\n\nMust-have\n• An undergraduate degree in Business, Computer Science, Data Science, Mathematics, or other quantitative disciplines with 2+ years experience analyzing large volumes of data/building analytical asset\n• Advanced Python coding skills and hands on experience with data analysis and transformation packages such as Pandas and Numpy\n• Familiarity with database and query languages (e.g. SQL)\n• Strong communication and presentation skills\n• Must be a self-starter, with strong analytical and interpersonal skills, as well as the ability to work in a fast-paced environment and manage multiple competing priorities\n• Attention to detail, organization, ability to multitask and time management is critical\n• Exceptional problem-solving skills and ability to conceptualize strategy\n\nNice-to-have\n• Experience in working with data science platforms like Dataiku, Azure Databricks, AWS\n• Strong working knowledge of developing Power BI reports/dashboards\n• Familiarity with ML concepts, NLP, and text analytics methods and packages\n\nWhat’s in it for you?\n\nWe thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients thrive and communities prosper. We care about each other, reaching our potential, making a difference to our communities, and achieving success that is mutual.\n• Excellent exposure to communicate with various business partners and stakeholders in Investor Services and within other platforms as appropriate\n• Working with an exciting, close-knit, supportive & dynamic group\n• Opportunity to collaborate with other business segments within the bank\n• Excellent career development and progression opportunities\n• A comprehensive Total Rewards Program including bonuses and flexible benefits\n• Competitive compensation\n\nJob Skills\nAnalytical Thinking, Business Analytics, Business Intelligence (BI), Critical Thinking, Data Mining, Data Modeling, Detail-Oriented, Group Problem Solving, Technical Problem-Solving\n\nAdditional Job Details\n\nAddress:\n\nRBC CENTRE, 155 WELLINGTON ST W:TORONTO\n\nCity:\n\nTORONTO\n\nCountry:\n\nCanada\n\nWork hours/week:\n\n37.5\n\nEmployment Type:\n\nFull time\n\nPlatform:\n\nWealth Management\n\nJob Type:\n\nRegular\n\nPay Type:\n\nSalaried\n\nPosted Date:\n\n2024-04-12\n\nApplication Deadline:\n\n2024-04-19\n\nInclusion and Equal Opportunity Employment\n\nAt RBC, we embrace diversity and inclusion for innovation and growth. We are committed to building inclusive teams and an equitable workplace for our employees to bring their true selves to work. We are taking actions to tackle issues of inequity and systemic bias to support our diverse talent, clients and communities.\n\u200b\u200b\u200b\u200b\u200b\u200b\u200b\nWe also strive to provide an accessible candidate experience for our prospective employees with different abilities. Please let us know if you need any accommodations during the recruitment process.\n\nJoin our Talent Community\n\nStay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.\n\nExpand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at jobs.rbc.com']}]","[{'link': 'http://www.rbc.com/', 'text': 'rbc.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=Royal+Bank+of+Canada&sa=X&ved=0ahUKEwiWg53F176FAxVSgIQIHVXXBMcQmJACCMkJ', 'text': 'See web results for Royal Bank of Canada'}]","['1 day ago', 'Full-time']","{'postedAt': '1 day ago', 'scheduleType': 'Full-time'}","{'title': '.nFg2eb{font-weight:500}.Bi6Ddc{font-weight:500}Apply on RBC Careers', 'link': 'https://jobs.rbc.com/ca/en/job/R-0000083851/Data-Analyst?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Analyst,2024-04-13 03:38:22.978861
Data Analyst - Intermediate,confidential,Toronto,via Apex Systems,"Data Analyst – Intermediate

Apex Systems is a global IT services provider and our consulting practice has an opening for a Data Analyst - Intermediate who specializes in Alteryx workflow development, and help the team to assess, design, and develop various reports required to meet future reporting for a Top Five Bank.
Client: Big 5 Bank
Location: Hybrid; 2 days a week in Toronto
Terms: 8 Month Contract, Strong possibility of extension or converting fulltime based on project budget & candidate performance.
Hours: 37.5 hours/week Monday-Friday, 9:00 am - 5:00 pm
Application Process: It is best to apply via the medium you are viewing this on. If you encounter technical difficulties, please contact Beth Armstrong at baarmstrong@apexsystems.com and reference Data Business Systems Analyst Consultant

Project:
Finance Modernization project - As a Data Analyst specializing in Alteryx workflow development, you will play a crucial role in collaborating with our Strategy and Business Analytics... team to assess, design, and develop various reports required by our finance department to meet future reporting needs. Additionally, you will lead project work packages aimed at developing automated solutions for finance, streamlining processes, and enhancing efficiency.

Team: Team consists of all developers with business/finance background. Agile team. Work on a use-case bases. Collaborative and supportive work environment where your ideas and contributions are valued. You will be working with Business team, Technology team, Finance, Taxation Office SMEs.

Job Description:

\tCollaborate with the Strategy and Business Analytics team to understand finances reporting requirements and translate them into actionable data solutions.
\tDevelop, maintain, and optimize Alteryx workflows to automate data extraction, transformation, and loading processes.
\tLead project work packages to design and implement automated solutions for finance, ensuring accuracy, reliability, and scalability.
\tWork closely with stakeholders to gather requirements, define project scope, and prioritize tasks to meet project timelines and deliverables.
\tConduct thorough testing and validation of developed solutions to ensure data accuracy and integrity.
\tProvide technical expertise and support to the finance team in utilizing Alteryx workflows and generating insights from data.
\tStay updated on emerging trends and best practices in data analytics, Alteryx platform, and finance domain to continuously improve processes and deliverables.

Must haves:

\t2-4 yrs of previous Data Analyst experience (more exp okay)
\tPrevious experience with Alteryx -developing Alteryx workflows for data extraction, transformation, and loading.
\tPrevious experience working with SMEs
\tStrong Excel knowledge (i.e. Macros, VLOOKUP, formulas)
\tPower BI ** very very nice to have

Nice to have:

\tSQL knowledge/ Visual basic
\t Previous banking experience
\tSAP S4 Hana experience
\tAble to translate technical terms to business

Soft Skills

\tExcellent analytical and problem-solving skills with a keen attention to detail.
\tStrong communication and interpersonal skills, with the ability to collaborate effectively with cross-functional teams.
\tProactive mindset with the ability to work independently and lead project initiatives.
\tEducation and Certifications: Post secondary - in Business, Computer Science, Finance

EEO EmployerApex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystems.com or 844-463-6178","[{'items': ['Data Analyst – Intermediate\n\nApex Systems is a global IT services provider and our consulting practice has an opening for a Data Analyst - Intermediate who specializes in Alteryx workflow development, and help the team to assess, design, and develop various reports required to meet future reporting for a Top Five Bank.\nClient: Big 5 Bank\nLocation: Hybrid; 2 days a week in Toronto\nTerms: 8 Month Contract, Strong possibility of extension or converting fulltime based on project budget & candidate performance.\nHours: 37.5 hours/week Monday-Friday, 9:00 am - 5:00 pm\nApplication Process: It is best to apply via the medium you are viewing this on. If you encounter technical difficulties, please contact Beth Armstrong at baarmstrong@apexsystems.com and reference Data Business Systems Analyst Consultant\n\nProject:\nFinance Modernization project - As a Data Analyst specializing in Alteryx workflow development, you will play a crucial role in collaborating with our Strategy and Business Analytics... team to assess, design, and develop various reports required by our finance department to meet future reporting needs. Additionally, you will lead project work packages aimed at developing automated solutions for finance, streamlining processes, and enhancing efficiency.\n\nTeam: Team consists of all developers with business/finance background. Agile team. Work on a use-case bases. Collaborative and supportive work environment where your ideas and contributions are valued. You will be working with Business team, Technology team, Finance, Taxation Office SMEs.\n\nJob Description:\n\n\\tCollaborate with the Strategy and Business Analytics team to understand finances reporting requirements and translate them into actionable data solutions.\n\\tDevelop, maintain, and optimize Alteryx workflows to automate data extraction, transformation, and loading processes.\n\\tLead project work packages to design and implement automated solutions for finance, ensuring accuracy, reliability, and scalability.\n\\tWork closely with stakeholders to gather requirements, define project scope, and prioritize tasks to meet project timelines and deliverables.\n\\tConduct thorough testing and validation of developed solutions to ensure data accuracy and integrity.\n\\tProvide technical expertise and support to the finance team in utilizing Alteryx workflows and generating insights from data.\n\\tStay updated on emerging trends and best practices in data analytics, Alteryx platform, and finance domain to continuously improve processes and deliverables.\n\nMust haves:\n\n\\t2-4 yrs of previous Data Analyst experience (more exp okay)\n\\tPrevious experience with Alteryx -developing Alteryx workflows for data extraction, transformation, and loading.\n\\tPrevious experience working with SMEs\n\\tStrong Excel knowledge (i.e. Macros, VLOOKUP, formulas)\n\\tPower BI ** very very nice to have\n\nNice to have:\n\n\\tSQL knowledge/ Visual basic\n\\t Previous banking experience\n\\tSAP S4 Hana experience\n\\tAble to translate technical terms to business\n\nSoft Skills\n\n\\tExcellent analytical and problem-solving skills with a keen attention to detail.\n\\tStrong communication and interpersonal skills, with the ability to collaborate effectively with cross-functional teams.\n\\tProactive mindset with the ability to work independently and lead project initiatives.\n\\tEducation and Certifications: Post secondary - in Business, Computer Science, Finance\n\nEEO EmployerApex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystems.com or 844-463-6178']}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=confidential&sa=X&ved=0ahUKEwiWg53F176FAxVSgIQIHVXXBMcQmJACCIMK', 'text': 'See web results for confidential'}]","['2 days ago', 'Full-time and Contractor', 'No degree mentioned']","{'postedAt': '2 days ago', 'scheduleType': 'Full-time and Contractor'}","{'title': 'Apply on Apex Systems', 'link': 'https://www.apexsystems.com/job/2024677_usa/data-analyst---intermediate?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Analyst,2024-04-13 03:38:22.978861
Data Analyst,ClickJobs.io,Toronto,via LinkedIn,"As a Data Analyst at Aventas, you will play a crucial role in optimizing our sales performance and enhancing our decision-making processes. You will be responsible for collecting, analyzing, and interpreting data to uncover actionable insights that will inform strategic initiatives and improve overall sales efficiency. Working closely with cross-functional teams, you will utilize your analytical skills to identify trends, forecast sales projections, and recommend data-driven solutions to achieve our business objectives. Key Responsibilities: Clean, validate, and organize datasets to ensure accuracy and reliability. Analyze sales performance metrics, such as conversion rates, customer acquisition costs, and sales funnel progression. Identify key trends and patterns within the data to uncover opportunities for revenue growth and cost optimization. Collaborate with sales and marketing teams to evaluate the effectiveness of campaigns and promotional strategies. Generate regular reports... and dashboards to communicate insights and recommendations to CEO. Continuously monitor data quality and integrity, implementing corrective measures as needed. Contribute to the development and implementation of data-driven strategies to improve sales performance and customer satisfaction. Qualifications : Bachelor’s degree in Business Analytics, Statistics, Mathematics, Computer Science, or a related field. Advanced degree preferred. Proven experience as a Data Analyst or similar role, preferably in a sales or marketing environment. Proficiency in data analysis tools and programming languages Strong analytical skills with the ability to translate complex data into actionable insights. Experience with data visualization techniques and tools to create informative reports. Excellent communication and presentation skills, with the ability to convey technical information to non-technical audiences. Detail-oriented with a commitment to maintaining data accuracy and integrity. Ability to work independently and collaboratively in a fast-paced environment, managing multiple priorities effectively. To apply, please submit your resume and a cover letter outlining your relevant experience and why you are interested in joining our team. We look forward to reviewing your application and considering you for this exciting opportunity","[{'items': ['As a Data Analyst at Aventas, you will play a crucial role in optimizing our sales performance and enhancing our decision-making processes. You will be responsible for collecting, analyzing, and interpreting data to uncover actionable insights that will inform strategic initiatives and improve overall sales efficiency. Working closely with cross-functional teams, you will utilize your analytical skills to identify trends, forecast sales projections, and recommend data-driven solutions to achieve our business objectives. Key Responsibilities: Clean, validate, and organize datasets to ensure accuracy and reliability. Analyze sales performance metrics, such as conversion rates, customer acquisition costs, and sales funnel progression. Identify key trends and patterns within the data to uncover opportunities for revenue growth and cost optimization. Collaborate with sales and marketing teams to evaluate the effectiveness of campaigns and promotional strategies. Generate regular reports... and dashboards to communicate insights and recommendations to CEO. Continuously monitor data quality and integrity, implementing corrective measures as needed. Contribute to the development and implementation of data-driven strategies to improve sales performance and customer satisfaction. Qualifications : Bachelor’s degree in Business Analytics, Statistics, Mathematics, Computer Science, or a related field. Advanced degree preferred. Proven experience as a Data Analyst or similar role, preferably in a sales or marketing environment. Proficiency in data analysis tools and programming languages Strong analytical skills with the ability to translate complex data into actionable insights. Experience with data visualization techniques and tools to create informative reports. Excellent communication and presentation skills, with the ability to convey technical information to non-technical audiences. Detail-oriented with a commitment to maintaining data accuracy and integrity. Ability to work independently and collaboratively in a fast-paced environment, managing multiple priorities effectively. To apply, please submit your resume and a cover letter outlining your relevant experience and why you are interested in joining our team. We look forward to reviewing your application and considering you for this exciting opportunity']}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=ClickJobs.io&sa=X&ved=0ahUKEwiWg53F176FAxVSgIQIHVXXBMcQmJACCLoK', 'text': 'See web results for ClickJobs.io'}]","['16 hours ago', 'Full-time']","{'postedAt': '16 hours ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/data-analyst-at-clickjobs-io-3895307630?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Analyst,2024-04-13 03:38:22.978861
Marketing Data Analyst - Toronto,PagerDuty,Toronto,via PagerDuty Careers,"PagerDuty empowers teams of all kinds to do the critical work that moves business forward through the PagerDuty Operations Cloud.

Visit our careers site to explore life at PagerDuty, discover opportunities, and sign-up for job alerts!

PagerDuty is looking for a strategic driven analyst to correlate goals to key performance indicators (KPIs), ensure tracking is set up to report and analyze, set up automated Tableau dashboards, run experimentation and a/b tests, and provide collaborative insights to internal stakeholders for performance reporting and optimization.

Reporting to the Director of Marketing Analytics and working closely with other senior analysts and analytics managers on the team, you will focus on identifying and mapping KPIs on the product led growth funnel and sales assist funnel in a SaaS environment. Additionally, you will work with key stakeholder groups on the web and growth teams (digital marketing focused) on KPI and goal mapping enablement, data driven... recommendations on testing & personalization strategies, implement web analytics tracking and tests, advise on CDP tracking, create performance reporting dashboards, and deliver insights.

You speak the language of marketers as well as data engineers, translating business questions into technical requirements. You provide simple, easy-to-digest reports and insights that will help our global marketing team drive more leads, pipeline and revenue, while keeping an eye on ROI.

You’re organized, work well autonomously, and can be trusted to deliver high quality work. You prioritize fiercely and communicate effectively. You take the work seriously, but you don’t take yourself too seriously.

Wherever possible, you’ll teach willing marketers how to answer their own questions with the flexible dashboards that you’ve built.

Key Responsibilities:
• Take analytics ownership of front-end tracking & reporting.
• Work with web developers to ensure proper & adequate front end tracking on all website features, and take an active role in identifying & resolving tracking gaps.
• Provide stakeholders with dashboards and reports on website engagement & performance, and identify key insights & opportunities for website enhancement.
• Analyze dashboards, provide insights and recommendations to stakeholders.
• See through recommendations and how that impacted performance.
• Conduct ad-hoc investigations analyses and provide data-based insights & recommendations to digital & web marketers.
• Assist in strategy and own implementation and reporting of A/B testing & experimentation.
• Have a firm grasp of statistical hypothesis testing, and familiarity with small-sample statistical testing methods.
• Provide appropriate interpretation of results & actionable recommendations to non-technical business stakeholders.
• Support senior analytics staff in digital marketing tracking, data connection, and reporting needs
• Actively participate in a collaborative analytics team. Support fellow team mates in knowledge building & sharing, QA’ing code & analyses, and creating documentation of best practices.
• Document how tracking was implemented and how dashboards were created for transparency and visibility for stakeholders and cross-team members

Basic Qualifications:
• 2-4 years of working with digital marketing and web analytics data set (e.g.Google Analytics 4, segment.io, Google Ads, Google Search Console, Google Display Network)
• Intermediate SQL skills
• 2-4 years experience testing and experimentation (a/b testing, causal inference)
• 2-4 years experience using Salesforce CRM data
• 2-4 years experience creating reports in a business intelligence tool like Tableau &
• Comfortable managing projects and working autonomously to complete projects
• Excellent communicator and collaborative team player

Preferred Qualifications:
• Enterprise SaaS experience
• Experience with Git / version control
• Experience with Snowflake or similar data warehouse
• Experience with Marketo
• Experience with Salesforce
• Experience building dashboards in Tableau desktop + server
• Google Tag Manager
• Google Analytics 4
• Testing tools like VWO
• Segment.io
• Marketing mix modeling experience

The base salary range for this position is 87,000 - 122,000 CAD. This role may also be eligible for bonus, commission, equity, and/or benefits.

Our base salary ranges are determined by role, level, and location. The range, which is subject to change based on primary work location, reflects the minimum and maximum base salary we expect to pay newly hired employees for the position. Within the range, we determine pay for an individual based on a number of factors including market location, job-related knowledge, skills/competencies and experience.

Your recruiter can share more about the specific offerings for this role, as well as the salary range for your primary work location during the hiring process.

Not sure if you qualify?

Apply anyway! We extend opportunities to a broad array of candidates, including those with diverse workplace experiences and backgrounds. Whether you're new to the corporate world, returning to work after a gap in employment, or simply looking to take the next step in your career path, we are excited to connect with you.

Where we work

PagerDuty currently has offices in Atlanta, Lisbon, London, San Francisco, Santiago, Sydney, Tokyo, and Toronto. We offer a hybrid, flexible workplace. We also provide ample opportunities for in-person and virtual connection, like team offsites and volunteering events.

How we work

Our values are deeply embedded in how we operate and the people we bring on board. You will see our values ingrained in how we support our customers, collaborate with our colleagues, develop our products and foster an inclusive and empathetic work culture.
• Champion the Customer | Put users first to design great products and experiences.
• Run Together | Build strong teams that amplify our impact on users.
• Take the Lead | Disrupt and invent to be the first choice for users.
• Ack + Own | Take ownership and action to deliver more efficiently to users.
• Bring Your Self | Bring your best self to build empathy and trust with users.

What we offer

One way we ensure our employees are inspired to do their best is through a comprehensive total rewards approach that supports them and their loved ones. As a global organization, our programs are competitive with industry standards and aligned with local laws and regulations.

Your package may include:
• Competitive salary and company equity
• Comprehensive benefits package from day one
• Flexible work arrangements
• ESPP (Employee Stock Purchase Program)
• Retirement or pension plan
• Paid parental leave - up to 22 weeks for pregnant parent, up to 12 weeks for non-pregnant parent (some countries have longer leave standards and we comply with local laws)
• Generous paid vacation time
• Paid holidays and sick leave
• Dutonian Wellness Days - scheduled company-wide paid days off in addition to PTO
• HibernationDuty - an annual company paid week off when everyone at PagerDuty, with the exception of a small, coverage crew, is asked to take a much needed break to truly disconnect and recharge
• Paid volunteer time off - 20 hours per year
• Company-wide hack weeks
• Mental wellness programs

About PagerDuty

PagerDuty, Inc. (NYSE:PD) is a global leader in digital operations management. The PagerDuty Operations Cloud revolutionizes how critical work gets done, and powers the agility that drives digital transformation. Customers rely on the PagerDuty Operations Cloud to compress costs, accelerate productivity, win revenue, sustain seamless digital experiences, and earn customer trust. More than half of the Fortune 500 and more than two thirds of the Fortune 100 trust PagerDuty including Cisco, Cox Automotive, DoorDash, Electronic Arts, Genentech, Shopify, Zoom and more.

Led by CEO Jennifer Tejada, PagerDuty’s Board of Directors is 50% female and 62% URP representation. We strive to build a more equitable world by investing 1% each of company equity, product, and employee volunteer time.

PagerDuty is Great Place to Work-certified™, a Fortune Best Workplace for Millennials, a Fortune Best Medium Workplace, a Fortune Best Workplace in Technology, and a top rated product on TrustRadius and G2.

Go behind-the-scenes @pagerduty on Instagram.

Additional Information

PagerDuty is committed to creating a diverse environment and is an equal opportunity employer. PagerDuty does not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, parental status, veteran status, or disability status.

PagerDuty is committed to providing reasonable accommodations for qualified individuals with disabilities in our job application process. Should you require accommodation, please email accommodation@pagerduty.com and we will work with you to meet your accessibility needs.

PagerDuty uses the E-Verify employment verification program","[{'items': [""PagerDuty empowers teams of all kinds to do the critical work that moves business forward through the PagerDuty Operations Cloud.\n\nVisit our careers site to explore life at PagerDuty, discover opportunities, and sign-up for job alerts!\n\nPagerDuty is looking for a strategic driven analyst to correlate goals to key performance indicators (KPIs), ensure tracking is set up to report and analyze, set up automated Tableau dashboards, run experimentation and a/b tests, and provide collaborative insights to internal stakeholders for performance reporting and optimization.\n\nReporting to the Director of Marketing Analytics and working closely with other senior analysts and analytics managers on the team, you will focus on identifying and mapping KPIs on the product led growth funnel and sales assist funnel in a SaaS environment. Additionally, you will work with key stakeholder groups on the web and growth teams (digital marketing focused) on KPI and goal mapping enablement, data driven... recommendations on testing & personalization strategies, implement web analytics tracking and tests, advise on CDP tracking, create performance reporting dashboards, and deliver insights.\n\nYou speak the language of marketers as well as data engineers, translating business questions into technical requirements. You provide simple, easy-to-digest reports and insights that will help our global marketing team drive more leads, pipeline and revenue, while keeping an eye on ROI.\n\nYou’re organized, work well autonomously, and can be trusted to deliver high quality work. You prioritize fiercely and communicate effectively. You take the work seriously, but you don’t take yourself too seriously.\n\nWherever possible, you’ll teach willing marketers how to answer their own questions with the flexible dashboards that you’ve built.\n\nKey Responsibilities:\n• Take analytics ownership of front-end tracking & reporting.\n• Work with web developers to ensure proper & adequate front end tracking on all website features, and take an active role in identifying & resolving tracking gaps.\n• Provide stakeholders with dashboards and reports on website engagement & performance, and identify key insights & opportunities for website enhancement.\n• Analyze dashboards, provide insights and recommendations to stakeholders.\n• See through recommendations and how that impacted performance.\n• Conduct ad-hoc investigations analyses and provide data-based insights & recommendations to digital & web marketers.\n• Assist in strategy and own implementation and reporting of A/B testing & experimentation.\n• Have a firm grasp of statistical hypothesis testing, and familiarity with small-sample statistical testing methods.\n• Provide appropriate interpretation of results & actionable recommendations to non-technical business stakeholders.\n• Support senior analytics staff in digital marketing tracking, data connection, and reporting needs\n• Actively participate in a collaborative analytics team. Support fellow team mates in knowledge building & sharing, QA’ing code & analyses, and creating documentation of best practices.\n• Document how tracking was implemented and how dashboards were created for transparency and visibility for stakeholders and cross-team members\n\nBasic Qualifications:\n• 2-4 years of working with digital marketing and web analytics data set (e.g.Google Analytics 4, segment.io, Google Ads, Google Search Console, Google Display Network)\n• Intermediate SQL skills\n• 2-4 years experience testing and experimentation (a/b testing, causal inference)\n• 2-4 years experience using Salesforce CRM data\n• 2-4 years experience creating reports in a business intelligence tool like Tableau &\n• Comfortable managing projects and working autonomously to complete projects\n• Excellent communicator and collaborative team player\n\nPreferred Qualifications:\n• Enterprise SaaS experience\n• Experience with Git / version control\n• Experience with Snowflake or similar data warehouse\n• Experience with Marketo\n• Experience with Salesforce\n• Experience building dashboards in Tableau desktop + server\n• Google Tag Manager\n• Google Analytics 4\n• Testing tools like VWO\n• Segment.io\n• Marketing mix modeling experience\n\nThe base salary range for this position is 87,000 - 122,000 CAD. This role may also be eligible for bonus, commission, equity, and/or benefits.\n\nOur base salary ranges are determined by role, level, and location. The range, which is subject to change based on primary work location, reflects the minimum and maximum base salary we expect to pay newly hired employees for the position. Within the range, we determine pay for an individual based on a number of factors including market location, job-related knowledge, skills/competencies and experience.\n\nYour recruiter can share more about the specific offerings for this role, as well as the salary range for your primary work location during the hiring process.\n\nNot sure if you qualify?\n\nApply anyway! We extend opportunities to a broad array of candidates, including those with diverse workplace experiences and backgrounds. Whether you're new to the corporate world, returning to work after a gap in employment, or simply looking to take the next step in your career path, we are excited to connect with you.\n\nWhere we work\n\nPagerDuty currently has offices in Atlanta, Lisbon, London, San Francisco, Santiago, Sydney, Tokyo, and Toronto. We offer a hybrid, flexible workplace. We also provide ample opportunities for in-person and virtual connection, like team offsites and volunteering events.\n\nHow we work\n\nOur values are deeply embedded in how we operate and the people we bring on board. You will see our values ingrained in how we support our customers, collaborate with our colleagues, develop our products and foster an inclusive and empathetic work culture.\n• Champion the Customer | Put users first to design great products and experiences.\n• Run Together | Build strong teams that amplify our impact on users.\n• Take the Lead | Disrupt and invent to be the first choice for users.\n• Ack + Own | Take ownership and action to deliver more efficiently to users.\n• Bring Your Self | Bring your best self to build empathy and trust with users.\n\nWhat we offer\n\nOne way we ensure our employees are inspired to do their best is through a comprehensive total rewards approach that supports them and their loved ones. As a global organization, our programs are competitive with industry standards and aligned with local laws and regulations.\n\nYour package may include:\n• Competitive salary and company equity\n• Comprehensive benefits package from day one\n• Flexible work arrangements\n• ESPP (Employee Stock Purchase Program)\n• Retirement or pension plan\n• Paid parental leave - up to 22 weeks for pregnant parent, up to 12 weeks for non-pregnant parent (some countries have longer leave standards and we comply with local laws)\n• Generous paid vacation time\n• Paid holidays and sick leave\n• Dutonian Wellness Days - scheduled company-wide paid days off in addition to PTO\n• HibernationDuty - an annual company paid week off when everyone at PagerDuty, with the exception of a small, coverage crew, is asked to take a much needed break to truly disconnect and recharge\n• Paid volunteer time off - 20 hours per year\n• Company-wide hack weeks\n• Mental wellness programs\n\nAbout PagerDuty\n\nPagerDuty, Inc. (NYSE:PD) is a global leader in digital operations management. The PagerDuty Operations Cloud revolutionizes how critical work gets done, and powers the agility that drives digital transformation. Customers rely on the PagerDuty Operations Cloud to compress costs, accelerate productivity, win revenue, sustain seamless digital experiences, and earn customer trust. More than half of the Fortune 500 and more than two thirds of the Fortune 100 trust PagerDuty including Cisco, Cox Automotive, DoorDash, Electronic Arts, Genentech, Shopify, Zoom and more.\n\nLed by CEO Jennifer Tejada, PagerDuty’s Board of Directors is 50% female and 62% URP representation. We strive to build a more equitable world by investing 1% each of company equity, product, and employee volunteer time.\n\nPagerDuty is Great Place to Work-certified™, a Fortune Best Workplace for Millennials, a Fortune Best Medium Workplace, a Fortune Best Workplace in Technology, and a top rated product on TrustRadius and G2.\n\nGo behind-the-scenes @pagerduty on Instagram.\n\nAdditional Information\n\nPagerDuty is committed to creating a diverse environment and is an equal opportunity employer. PagerDuty does not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, parental status, veteran status, or disability status.\n\nPagerDuty is committed to providing reasonable accommodations for qualified individuals with disabilities in our job application process. Should you require accommodation, please email accommodation@pagerduty.com and we will work with you to meet your accessibility needs.\n\nPagerDuty uses the E-Verify employment verification program""]}]","[{'link': 'http://www.pagerduty.com/', 'text': 'pagerduty.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=PagerDuty&sa=X&ved=0ahUKEwiWg53F176FAxVSgIQIHVXXBMcQmJACCPkK', 'text': 'See web results for PagerDuty'}]","['3 days ago', 'Full-time', 'No degree mentioned']","{'postedAt': '3 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on PagerDuty Careers', 'link': 'https://careers.pagerduty.com/jobs/marketing-data-analyst-toronto-toronto-ontario-canada?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Analyst,2024-04-13 03:38:22.978861
Data and Information Analyst,University of Toronto,Toronto,via Careers At U Of T - University Of Toronto,"Date Posted: 04/11/2024

Req ID: 36936

Faculty/Division: Vice-Provost, Students

Department: Office of Vice-Provost, Students

Campus: St. George (Downtown Toronto)

Position Number: 00056329

Description:

About us:

The Office of the Vice-Provost, Students (OVPS) manages policies and procedures for students and student organizations across three campuses, with a mandate to support and enhance the student experience. The Office of Strategic Enrollment Management (VPSEM) works to support the recruitment, enrolment, and retention of a diverse, dynamic, and academically robust group of students from Canada and across the globe. The Student Data and Analytics team supports the Office of Vice Provost Students and the Office of Strategic Enrollment Management in the development of structures, tools, and practices to institutionalize a data-driven culture of student success.

Your opportunity:

As a member of the Student Data & Analytics team, and under the general direction of the... Manager, Student Data and Analytics, the incumbent will support a range of analytical activities primarily related to Student Equity Census and other student data sources. This includes the production of ad-hoc statistical reports, creation of dashboards in both Microsoft Power BI/Tableau, and other analytical products.

Your responsibilities will include:
• Producing complex statistical information.
• Analyzing complex data that requires great precision and attention to many details.
• Running SQL queries to gather data from ROSI.
• Generating static reports.
• Developing and maintaining a dashboard in Power BI and/or Tableau for quick access to key performance indicators.
• Developing charter, scope, resources and schedule for project(s).
• Conducting detailed data analysis to inform management decision making.

Essential Qualifications:
• Bachelor's Degree in a business, analytical, quantitative, information management, or research-related discipline; or acceptable combination of equivalent experience.
• Minimum five years working in data collection, analysis and reporting or other related experience.
• Experience analyzing post-secondary student administrative data (e.g. ROSI).
• Demonstrated experience working with relational databases using Azure Data Studio/SQL.
• Demonstrated experience in quantitative and qualitative data.
• Demonstrated experience producing polished dashboards using Microsoft Power BI and/or Tableau.
• Demonstrated experience utilizing a variety of data visualization tools and methods to create graphs, charts, timelines, maps, dashboards, infographics, etc. is required.
• Strong analytical skills and demonstrated experience in accessing and utilizing data for decision making.
• Demonstrated experience in quantitative and qualitative data.Effective interpersonal skills, strong communicator, a collaborative style and the ability to work effectively across functional areas to achieve established goals.
• Proven understanding of Tableau (or similar visualization platform) and the ability to leverage the tool to craft stories, graphics, reports, and complex analysis.
• Excellent written and verbal communication skills, including the ability to share data and research results in ways that are easily understood.
• Familiarity with/or interest in learning about regression modeling.
• Familiarity statistical software like Stata, SAS, SPSS or R.

To be successful in this role you will be:
• Approachable
• Cooperative
• Multi-tasker
• Organized
• Proactive
• Problem solver
• Responsible

Closing Date: 04/25/2024, 11:59PM ET

Employee Group: USW

Appointment Type: Budget - Continuing

Schedule: Full-Time

Pay Scale Group & Hiring Zone:

USW Pay Band 13 -- $83,150 with an annual step progression to a maximum of $106,336. Pay scale and job class assignment is subject to determination pursuant to the Job Evaluation/Pay Equity Maintenance Protocol.

Job Category: Administrative / Managerial

Recruiter: Fiona Chan

Lived Experience Statement

Candidates who are members of Indigenous, Black, racialized and 2SLGBTQ+ communities, persons with disabilities, and other equity deserving groups are encouraged to apply, and their lived experience shall be taken into consideration as applicable to the posted position","[{'items': [""Date Posted: 04/11/2024\n\nReq ID: 36936\n\nFaculty/Division: Vice-Provost, Students\n\nDepartment: Office of Vice-Provost, Students\n\nCampus: St. George (Downtown Toronto)\n\nPosition Number: 00056329\n\nDescription:\n\nAbout us:\n\nThe Office of the Vice-Provost, Students (OVPS) manages policies and procedures for students and student organizations across three campuses, with a mandate to support and enhance the student experience. The Office of Strategic Enrollment Management (VPSEM) works to support the recruitment, enrolment, and retention of a diverse, dynamic, and academically robust group of students from Canada and across the globe. The Student Data and Analytics team supports the Office of Vice Provost Students and the Office of Strategic Enrollment Management in the development of structures, tools, and practices to institutionalize a data-driven culture of student success.\n\nYour opportunity:\n\nAs a member of the Student Data & Analytics team, and under the general direction of the... Manager, Student Data and Analytics, the incumbent will support a range of analytical activities primarily related to Student Equity Census and other student data sources. This includes the production of ad-hoc statistical reports, creation of dashboards in both Microsoft Power BI/Tableau, and other analytical products.\n\nYour responsibilities will include:\n• Producing complex statistical information.\n• Analyzing complex data that requires great precision and attention to many details.\n• Running SQL queries to gather data from ROSI.\n• Generating static reports.\n• Developing and maintaining a dashboard in Power BI and/or Tableau for quick access to key performance indicators.\n• Developing charter, scope, resources and schedule for project(s).\n• Conducting detailed data analysis to inform management decision making.\n\nEssential Qualifications:\n• Bachelor's Degree in a business, analytical, quantitative, information management, or research-related discipline; or acceptable combination of equivalent experience.\n• Minimum five years working in data collection, analysis and reporting or other related experience.\n• Experience analyzing post-secondary student administrative data (e.g. ROSI).\n• Demonstrated experience working with relational databases using Azure Data Studio/SQL.\n• Demonstrated experience in quantitative and qualitative data.\n• Demonstrated experience producing polished dashboards using Microsoft Power BI and/or Tableau.\n• Demonstrated experience utilizing a variety of data visualization tools and methods to create graphs, charts, timelines, maps, dashboards, infographics, etc. is required.\n• Strong analytical skills and demonstrated experience in accessing and utilizing data for decision making.\n• Demonstrated experience in quantitative and qualitative data.Effective interpersonal skills, strong communicator, a collaborative style and the ability to work effectively across functional areas to achieve established goals.\n• Proven understanding of Tableau (or similar visualization platform) and the ability to leverage the tool to craft stories, graphics, reports, and complex analysis.\n• Excellent written and verbal communication skills, including the ability to share data and research results in ways that are easily understood.\n• Familiarity with/or interest in learning about regression modeling.\n• Familiarity statistical software like Stata, SAS, SPSS or R.\n\nTo be successful in this role you will be:\n• Approachable\n• Cooperative\n• Multi-tasker\n• Organized\n• Proactive\n• Problem solver\n• Responsible\n\nClosing Date: 04/25/2024, 11:59PM ET\n\nEmployee Group: USW\n\nAppointment Type: Budget - Continuing\n\nSchedule: Full-Time\n\nPay Scale Group & Hiring Zone:\n\nUSW Pay Band 13 -- $83,150 with an annual step progression to a maximum of $106,336. Pay scale and job class assignment is subject to determination pursuant to the Job Evaluation/Pay Equity Maintenance Protocol.\n\nJob Category: Administrative / Managerial\n\nRecruiter: Fiona Chan\n\nLived Experience Statement\n\nCandidates who are members of Indigenous, Black, racialized and 2SLGBTQ+ communities, persons with disabilities, and other equity deserving groups are encouraged to apply, and their lived experience shall be taken into consideration as applicable to the posted position""]}]","[{'link': 'https://www.utoronto.ca/', 'text': 'utoronto.ca'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=University+of+Toronto&sa=X&ved=0ahUKEwiWg53F176FAxVSgIQIHVXXBMcQmJACCLgL', 'text': 'See web results for University of Toronto'}]","['2 days ago', 'Full-time']","{'postedAt': '2 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on Careers At U Of T - University Of Toronto', 'link': 'https://jobs.utoronto.ca/job/Toronto-Data-and-Information-Analyst-ON/579996417/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Analyst,2024-04-13 03:38:22.978861
Data Analyst,"LanceSoft, Inc.",Toronto,via LinkedIn,"Hiring manager: Senior Manager, Pricing Analytics

Location Address: 40 King Street W 13th Floor– Hybrid (In Office 2-3 Days a Week depending of workload).

Contract Duration: 6+ months

Purpose
• Support the overall success of pricing operations/functions in Canadian Business Banking by ensuring specific individual goals, plans, and initiatives are executed/delivered in support of the team’s business strategies and objectives. Ensures all activities conducted follow governing regulations, internal policies and procedures.
• Support the delivery of pricing operational excellence activities to ensure completeness in front-end and back-end operations. Led by Senior Manager, Pricing Analytics, the Analyst, will periodically reconcile data between booking and back-office systems, develop reports, and support remediation activities.

Business group: Canadian Business Banking Credit & Business

Commercial banking lending and deposits. We handle operations all the commercial banking and... day-to-day operations, data and analytics. To drive pricing and revenue optimization, we gather insights from different data sourcing and matrix from different dashboards to provide insights to our stakeholders.

Typical Day In Role
• Champions a customer-focused culture to deepen client relationships and leverage broader Bank relationships, systems and knowledge.
• Collaborate with key stakeholder relationships in support of pricing initiatives
• Works collaboratively with key stakeholders including Analytics, Data Engineering, Client Measurement, Treasury and Salesforce to understand data infrastructure and provide feedback for improvement
• Work with technology and other relevant stakeholders to support data infrastructure development, such as validating data quality and testing data linkage
• Contribute to delivering excellent user experience, such as supporting product owners with training, supporting user requests/escalations etc.
• Proactively support various pricing stakeholders on initiatives and ad-hoc analysis
• Understands how the Bank’s risk appetite and risk culture should be considered in day-to-day activities and decisions.
• Actively pursues effective and efficient operations of his/her respective areas by ***’s Values, its Code of Conduct and the Global Sales Principles, while ensuring the adequacy, adherence to and effectiveness of day-to-day business controls to meet obligations with respect to operational, compliance, AML/ATF/sanctions and conduct risk.
• Champions a high-performance environment and contributes to an inclusive work environment.

Candidate Requirements/Must Have Skills
• 5+ years of experience with MS office suite (Excel and Power Point)
• 5+ experience working with banking products, especially pricing methodological knowledge
• 1-2+ years of experience working with Data
• 1-2 years of experience reconciling, manipulating and interpreting data, performing analysis and make informed recommendations.

Nice-To-Have Skills:
• Experience with Business Intelligence tools such as Tableau, and Power BI, is highly desirable
• Experience with customer value and price elasticity is a plus but not essential

Soft Skills Required
• Enjoy discovering and learning new technologies
• Excellent analytical skills.
• Collaboration in diverse teams and settings
• Passionate about Innovation and Innovative technologies
• Being able to work up- down within the organization
• Excellent written and communication skills to clearly express concepts and ideas.
• Ability to work as part of a team, as well as work independently with minimal direction.
• Strong technical skills in Math, Computer Science or related fields
• Attention to detail and drive to deliver on time are required
• Excellent prioritizing, presentation, and communication skills would be a plus

Best VS. Average Candidate

The best candidate is someone with working knowledge of banking products especially pricing methodological knowledge. Very organized and responsible, very professional in all aspects at work.

Education & Certificates
• Bachelor's degree in related areas or previous experience.

Candidate Review And Selection

2 rounds – 1st round with Hiring Manager and team member 1 hour MS Teams Interview and 2nd round with Hiring manager and Director 30 mins MS Teams Interview

Introduction, and talk about experience and previous projects and behavioural questions and data-related questions
• NOTE: *** will review any requests for accommodations put forward by Suppliers***

The manager will be available with no time off planned","[{'items': [""Hiring manager: Senior Manager, Pricing Analytics\n\nLocation Address: 40 King Street W 13th Floor– Hybrid (In Office 2-3 Days a Week depending of workload).\n\nContract Duration: 6+ months\n\nPurpose\n• Support the overall success of pricing operations/functions in Canadian Business Banking by ensuring specific individual goals, plans, and initiatives are executed/delivered in support of the team’s business strategies and objectives. Ensures all activities conducted follow governing regulations, internal policies and procedures.\n• Support the delivery of pricing operational excellence activities to ensure completeness in front-end and back-end operations. Led by Senior Manager, Pricing Analytics, the Analyst, will periodically reconcile data between booking and back-office systems, develop reports, and support remediation activities.\n\nBusiness group: Canadian Business Banking Credit & Business\n\nCommercial banking lending and deposits. We handle operations all the commercial banking and... day-to-day operations, data and analytics. To drive pricing and revenue optimization, we gather insights from different data sourcing and matrix from different dashboards to provide insights to our stakeholders.\n\nTypical Day In Role\n• Champions a customer-focused culture to deepen client relationships and leverage broader Bank relationships, systems and knowledge.\n• Collaborate with key stakeholder relationships in support of pricing initiatives\n• Works collaboratively with key stakeholders including Analytics, Data Engineering, Client Measurement, Treasury and Salesforce to understand data infrastructure and provide feedback for improvement\n• Work with technology and other relevant stakeholders to support data infrastructure development, such as validating data quality and testing data linkage\n• Contribute to delivering excellent user experience, such as supporting product owners with training, supporting user requests/escalations etc.\n• Proactively support various pricing stakeholders on initiatives and ad-hoc analysis\n• Understands how the Bank’s risk appetite and risk culture should be considered in day-to-day activities and decisions.\n• Actively pursues effective and efficient operations of his/her respective areas by ***’s Values, its Code of Conduct and the Global Sales Principles, while ensuring the adequacy, adherence to and effectiveness of day-to-day business controls to meet obligations with respect to operational, compliance, AML/ATF/sanctions and conduct risk.\n• Champions a high-performance environment and contributes to an inclusive work environment.\n\nCandidate Requirements/Must Have Skills\n• 5+ years of experience with MS office suite (Excel and Power Point)\n• 5+ experience working with banking products, especially pricing methodological knowledge\n• 1-2+ years of experience working with Data\n• 1-2 years of experience reconciling, manipulating and interpreting data, performing analysis and make informed recommendations.\n\nNice-To-Have Skills:\n• Experience with Business Intelligence tools such as Tableau, and Power BI, is highly desirable\n• Experience with customer value and price elasticity is a plus but not essential\n\nSoft Skills Required\n• Enjoy discovering and learning new technologies\n• Excellent analytical skills.\n• Collaboration in diverse teams and settings\n• Passionate about Innovation and Innovative technologies\n• Being able to work up- down within the organization\n• Excellent written and communication skills to clearly express concepts and ideas.\n• Ability to work as part of a team, as well as work independently with minimal direction.\n• Strong technical skills in Math, Computer Science or related fields\n• Attention to detail and drive to deliver on time are required\n• Excellent prioritizing, presentation, and communication skills would be a plus\n\nBest VS. Average Candidate\n\nThe best candidate is someone with working knowledge of banking products especially pricing methodological knowledge. Very organized and responsible, very professional in all aspects at work.\n\nEducation & Certificates\n• Bachelor's degree in related areas or previous experience.\n\nCandidate Review And Selection\n\n2 rounds – 1st round with Hiring Manager and team member 1 hour MS Teams Interview and 2nd round with Hiring manager and Director 30 mins MS Teams Interview\n\nIntroduction, and talk about experience and previous projects and behavioural questions and data-related questions\n• NOTE: *** will review any requests for accommodations put forward by Suppliers***\n\nThe manager will be available with no time off planned""]}]","[{'link': 'http://www.lancesoft.com/', 'text': 'lancesoft.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=LanceSoft,+Inc.&sa=X&ved=0ahUKEwiWg53F176FAxVSgIQIHVXXBMcQmJACCPAL', 'text': 'See web results for LanceSoft, Inc.'}]","['2 days ago', 'Full-time and Temp work']","{'postedAt': '2 days ago', 'scheduleType': 'Full-time and Temp work'}","{'title': 'Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/data-analyst-at-lancesoft-inc-3894875445?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Analyst,2024-04-13 03:38:22.978861
Data Analyst,Alliance Search Partners,Toronto,via Indeed,"Position Title: IT - Data Analyst - Intermediate

Location Address: 81 Bay 26th Floor - Hybrid -Weds and Thurs in office
Line of Business: Business Transformation and Portfolio Delivery
Target Start Date: 5/21/2024
Contract Duration: 8 Months

Extension/FTE: Potential for extension and conversion to FTE

Number of Positions: 2

Schedule Hours: Mon - Fri, 9-5 - 37.5 hrs

Project: Finance Modernization project - Delivering new solutions to the business. Creating a work package and developing 20 reports for finance.

Team culture: Team consists of all developers with business/finance background. Agile team. Work on a use-case bases.

Selling point of the position: Opportunity to join the strategy and business analytics team and will work very closely on the 2nd biggest project at CIBC. Will be interacting with finance and developing solutions from scratch to help the Taxation Office. The successful candidate will gain a better understanding on finance procedures and have a close view on... the taxation process. There is also the potential for extension and conversion to FTE.

Who will the candidate be working with on a Daily basis: Business team, Technology team, Finance, Taxation Office SME's.

Job Description:
• Schedule Meetings/calls with the business
• Data mapping, business processing, assessments and planning
• Work directly with SMEs
• Input data to Excel - (knowledge of Macros, VLOOKUP, formulas)
• Transfer excel information to Alteryx (automation tool)
• Report status/issues to the project team

Must haves:

1. 2-4 yrs of previous Data Analyst experience

2. Previous experience with Alteryx (automation tool)

3. Previous experience working with SME's

4. Strong Excel knowledge (i.e. Macro's, VLOOKUP, formulas)

5. Power BI

Nice to have:
• SQL knowledge/ Visual basic
• Previous banking experience
• SAP S4 Hana experience
• Able to translate technical terms to business

Soft Skills
• Excellent communication skills both oral and written

Education and Certifications: Post secondary - in Business, Computer Science, Finance

Interview: 2 interviews

1st - with team members - 30 min - MS Teams

2nd - with HM - 30 min - MS Teams

Job Types: Full-time, Fixed term contract, Freelance
Contract length: 8 months

Pay: $50.00-$55.00 per hour

Expected hours: 37.5 per week

Flexible Language Requirement:
• French not required

Schedule:
• Monday to Friday

Experience:
• Data analysis skills: 3 years (required)
• Alteryx: 2 years (required)
• Power BI: 2 years (preferred)
• Excel knowledge (i.e. Macro's, VLOOKUP, formulas): 2 years (required)

Work Location: Hybrid remote in Toronto, ON M5J 0G1

Application deadline: 2024-04-14
Expected start date: 2024-05-06","[{'items': [""Position Title: IT - Data Analyst - Intermediate\n\nLocation Address: 81 Bay 26th Floor - Hybrid -Weds and Thurs in office\nLine of Business: Business Transformation and Portfolio Delivery\nTarget Start Date: 5/21/2024\nContract Duration: 8 Months\n\nExtension/FTE: Potential for extension and conversion to FTE\n\nNumber of Positions: 2\n\nSchedule Hours: Mon - Fri, 9-5 - 37.5 hrs\n\nProject: Finance Modernization project - Delivering new solutions to the business. Creating a work package and developing 20 reports for finance.\n\nTeam culture: Team consists of all developers with business/finance background. Agile team. Work on a use-case bases.\n\nSelling point of the position: Opportunity to join the strategy and business analytics team and will work very closely on the 2nd biggest project at CIBC. Will be interacting with finance and developing solutions from scratch to help the Taxation Office. The successful candidate will gain a better understanding on finance procedures and have a close view on... the taxation process. There is also the potential for extension and conversion to FTE.\n\nWho will the candidate be working with on a Daily basis: Business team, Technology team, Finance, Taxation Office SME's.\n\nJob Description:\n• Schedule Meetings/calls with the business\n• Data mapping, business processing, assessments and planning\n• Work directly with SMEs\n• Input data to Excel - (knowledge of Macros, VLOOKUP, formulas)\n• Transfer excel information to Alteryx (automation tool)\n• Report status/issues to the project team\n\nMust haves:\n\n1. 2-4 yrs of previous Data Analyst experience\n\n2. Previous experience with Alteryx (automation tool)\n\n3. Previous experience working with SME's\n\n4. Strong Excel knowledge (i.e. Macro's, VLOOKUP, formulas)\n\n5. Power BI\n\nNice to have:\n• SQL knowledge/ Visual basic\n• Previous banking experience\n• SAP S4 Hana experience\n• Able to translate technical terms to business\n\nSoft Skills\n• Excellent communication skills both oral and written\n\nEducation and Certifications: Post secondary - in Business, Computer Science, Finance\n\nInterview: 2 interviews\n\n1st - with team members - 30 min - MS Teams\n\n2nd - with HM - 30 min - MS Teams\n\nJob Types: Full-time, Fixed term contract, Freelance\nContract length: 8 months\n\nPay: $50.00-$55.00 per hour\n\nExpected hours: 37.5 per week\n\nFlexible Language Requirement:\n• French not required\n\nSchedule:\n• Monday to Friday\n\nExperience:\n• Data analysis skills: 3 years (required)\n• Alteryx: 2 years (required)\n• Power BI: 2 years (preferred)\n• Excel knowledge (i.e. Macro's, VLOOKUP, formulas): 2 years (required)\n\nWork Location: Hybrid remote in Toronto, ON M5J 0G1\n\nApplication deadline: 2024-04-14\nExpected start date: 2024-05-06""]}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=Alliance+Search+Partners&sa=X&ved=0ahUKEwiWg53F176FAxVSgIQIHVXXBMcQmJACCKoM', 'text': 'See web results for Alliance Search Partners'}]","['2 days ago', 'CA$50–CA$55 an hour', 'Full-time and Temp work', 'No degree mentioned']","{'postedAt': '2 days ago', 'scheduleType': 'Full-time and Temp work'}","{'title': 'Apply directly on Indeed', 'link': 'https://ca.indeed.com/m/viewjob?jk=1a837fe236815116&from=serp&tk=1hr79n0dfiodh801&advn=4152871913126665&adid=420235079&ad=-6NYlbfkN0B2rgPGb8iKQW7qLyTw0WXISuqlNuORLdf67EF1j2DWuvVL0wT4MD1qPdyqyoc4jJclob-fiwUEC4QCQBQziwWQJ8-9Ip_6ieu8QlU-KbA6PwLXe76vlCu_5-6d2KWkj3uMs-uIDPdNfkldLMn2rM-1IeUae42FZp6tU6fpnrioj3EMesZB3YL5NzBlgwgfz-O2hFpCfGv4iUrVcuNh4FZN9SnakNrP2QeEImzh13BKU7t-KaLgeCCT6Wi0Y6EByXXA9FtV3uOAHlTSJoW1-ZfqUkjbCVZ_otsSC1ufSQ651SYkdM9VZVjHtz6hFr2UkIusmqxzZ4KoiYVNTBYpuqReG7UpxcEqroVVLyei3I2x8cg61QSZieZELq3JoeFsdXg7wywz8NQCXpANnlvzfwaFfijTCUpKuuIxqZF-sqg4NryuchVCcCJs3XKm7tDyQQ6jgViQHUAJJcFGkfoYOhWsy1117okHbNp3rlhEgFIPHsfpUiEmmHJEsiDxWJHcjzIIENcuaZvqDLSrNViTJmtWw3mHjA0HV6r7XKsd8fXcZ9i5Xo6JiCHVBva70_jwWvTq189-skObtRDvbH9nm_HWfriu9jy1XdybqHsYN-sCo77sWP-5rgsoyxpukZk3IEM%3D&xkcb=SoBn6_M3CnbTxs25Q50ObzkdCdPP&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Analyst,2024-04-13 03:38:22.978861
Business and Data Analyst,Connexall,Toronto,via LinkedIn,"GlobeStar Systems is a leader in integrated clinical communication. Our cornerstone product, Connexall®, is an award-winning Enterprise-grade IoT platform, purpose-built for the healthcare industry. Connexall® is a sophisticated and customizable end-to-end integration and communication platform that helps its customers improve clinical workflow, reduce alarm fatigue, and drive better patient and staff outcomes.

Job Title: Business and Data Analyst

Type: Full-Time

Start Date: Immediate

Location: Toronto, Canada

Job Description

Reporting to the Director of Solutions Innovation and Design, the Business and Data Analyst plays a vital role in unlocking the power of Connexall’s connected healthcare data to deliver continuous value for our customers, partners, and internal departments with trust and integrity. The successful candidate is responsible for ensuring the accuracy of data and for preparing the primary and secondary data analysis, business intelligence, and advanced analytics... applications and metrics provided to the appropriate stakeholders.

Primary Responsibilities
• Work closely with Connexall customers and the Data and Analytics Development team to fully understand and maintain focus on analytics needs, including critical metrics and KPIs, and deliver actionable insights to relevant decision-makers.
• Focus on Connexall’s analytics products and offerings and become a subject matter expert in our various data sources.
• Support the development of Connexall’s analytics and services methodology, reporting packages, and analytical tools.
• Be a strong liaison between the customers and internal clinical team to bridge the data requirements, data story, representation to support clinical outcome-based best practice initiatives.
• Act as a vital contributor and participant for the end-to-end, outcomes-based, project delivery methodology initiative.
• Partner with stakeholders in other internal departments to gather requirements and define metrics that will drive strategy and business outcomes.
• Create meaningful use cases utilizing data tools for customers and appropriate stakeholders.
• Work closely with customers to present and train them on Connexall’s data analytics and business insights offerings.
• Use research skills, data analytical skills, and Connexall knowledge to review alarm data creating pre/post implementation differences and identify areas for further clinical consulting engagements such as, but not limited to, alarm flows and timers.
• Continuously challenge assumptions, dig beneath the surface, and use feedback to improve and push the boundaries of the work.
• Be responsible for data analysis-related documentation and knowledge sharing.
• Recommend and assist in developing ETL solutions and data architectural changes.
• Take the lead on data analytics projects with customers.
• Act as an analytics SME and educate stakeholders, internally and externally, to foster more knowledge and adoption around Connexall’s analytics capabilities.
• Other duties as required.

Qualifications
• A Bachelor’s degree in Computer Science, Engineering, Technology, Business, or other relevant fields.
• 3+ years of relevant experience, demonstrated knowledge, and decision-making abilities in a data analyst role.
• Previous experience or background in healthcare-related field a strong asset.
• Knowledge of and practical experience in statistical analysis with statistical packages a strong asset, including Excel, SPSS, SAS, R, Python packages (e.g. Pandas, Matplotlib, etc.), Julia, Power BI.
• Familiarity with SQL and ability to transform raw data into useful datasets.
• Experience with BI tools such as Power BI, Looker, Tableau, Mode, etc.
• Advanced Excel, some experience with Power Pivot and SQL preferred.
• Power BI and/or VBA experience a plus, or a desire to learn.
• Demonstrated business acumen with a drive and curiosity to seek data-driven answers to operational and strategic business questions.
• Experience with storytelling through data (logical reasoning, data visualization, communication).
• Resourceful and detail-oriented with the ability to effectively prioritize and execute tasks while under pressure.
• Exceptional research and analytical skills.
• Strong interpersonal and oral and written communication skills.
• Excel in working in a team-orientated and collaborative environment.
• Demonstrated strong listening, written, oral, and presentation skills with the ability to discuss highly technical concepts to a variety of audiences.
• Strong organizational and time management skills.
• Self-motivated and positive with a ""can-do"" attitude.

Benefits
• Competitive annual salary
• A rich benefits package, including: medical, dental, life, long-term disability insurance, pension
• RRSP matching program
• Vacation","[{'items': ['GlobeStar Systems is a leader in integrated clinical communication. Our cornerstone product, Connexall®, is an award-winning Enterprise-grade IoT platform, purpose-built for the healthcare industry. Connexall® is a sophisticated and customizable end-to-end integration and communication platform that helps its customers improve clinical workflow, reduce alarm fatigue, and drive better patient and staff outcomes.\n\nJob Title: Business and Data Analyst\n\nType: Full-Time\n\nStart Date: Immediate\n\nLocation: Toronto, Canada\n\nJob Description\n\nReporting to the Director of Solutions Innovation and Design, the Business and Data Analyst plays a vital role in unlocking the power of Connexall’s connected healthcare data to deliver continuous value for our customers, partners, and internal departments with trust and integrity. The successful candidate is responsible for ensuring the accuracy of data and for preparing the primary and secondary data analysis, business intelligence, and advanced analytics... applications and metrics provided to the appropriate stakeholders.\n\nPrimary Responsibilities\n• Work closely with Connexall customers and the Data and Analytics Development team to fully understand and maintain focus on analytics needs, including critical metrics and KPIs, and deliver actionable insights to relevant decision-makers.\n• Focus on Connexall’s analytics products and offerings and become a subject matter expert in our various data sources.\n• Support the development of Connexall’s analytics and services methodology, reporting packages, and analytical tools.\n• Be a strong liaison between the customers and internal clinical team to bridge the data requirements, data story, representation to support clinical outcome-based best practice initiatives.\n• Act as a vital contributor and participant for the end-to-end, outcomes-based, project delivery methodology initiative.\n• Partner with stakeholders in other internal departments to gather requirements and define metrics that will drive strategy and business outcomes.\n• Create meaningful use cases utilizing data tools for customers and appropriate stakeholders.\n• Work closely with customers to present and train them on Connexall’s data analytics and business insights offerings.\n• Use research skills, data analytical skills, and Connexall knowledge to review alarm data creating pre/post implementation differences and identify areas for further clinical consulting engagements such as, but not limited to, alarm flows and timers.\n• Continuously challenge assumptions, dig beneath the surface, and use feedback to improve and push the boundaries of the work.\n• Be responsible for data analysis-related documentation and knowledge sharing.\n• Recommend and assist in developing ETL solutions and data architectural changes.\n• Take the lead on data analytics projects with customers.\n• Act as an analytics SME and educate stakeholders, internally and externally, to foster more knowledge and adoption around Connexall’s analytics capabilities.\n• Other duties as required.\n\nQualifications\n• A Bachelor’s degree in Computer Science, Engineering, Technology, Business, or other relevant fields.\n• 3+ years of relevant experience, demonstrated knowledge, and decision-making abilities in a data analyst role.\n• Previous experience or background in healthcare-related field a strong asset.\n• Knowledge of and practical experience in statistical analysis with statistical packages a strong asset, including Excel, SPSS, SAS, R, Python packages (e.g. Pandas, Matplotlib, etc.), Julia, Power BI.\n• Familiarity with SQL and ability to transform raw data into useful datasets.\n• Experience with BI tools such as Power BI, Looker, Tableau, Mode, etc.\n• Advanced Excel, some experience with Power Pivot and SQL preferred.\n• Power BI and/or VBA experience a plus, or a desire to learn.\n• Demonstrated business acumen with a drive and curiosity to seek data-driven answers to operational and strategic business questions.\n• Experience with storytelling through data (logical reasoning, data visualization, communication).\n• Resourceful and detail-oriented with the ability to effectively prioritize and execute tasks while under pressure.\n• Exceptional research and analytical skills.\n• Strong interpersonal and oral and written communication skills.\n• Excel in working in a team-orientated and collaborative environment.\n• Demonstrated strong listening, written, oral, and presentation skills with the ability to discuss highly technical concepts to a variety of audiences.\n• Strong organizational and time management skills.\n• Self-motivated and positive with a ""can-do"" attitude.\n\nBenefits\n• Competitive annual salary\n• A rich benefits package, including: medical, dental, life, long-term disability insurance, pension\n• RRSP matching program\n• Vacation']}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=Connexall&sa=X&ved=0ahUKEwiWg53F176FAxVSgIQIHVXXBMcQmJACCOMM', 'text': 'See web results for Connexall'}]","['2 days ago', 'Full-time']","{'postedAt': '2 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/business-and-data-analyst-at-connexall-3894340440?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Analyst,2024-04-13 03:38:22.978861
Data Analyst,Hub International,Toronto,via Hub International Jobs,"ABOUT US

At HUB International, we are a team of entrepreneurs. We believe in empowering our clients, and we do so by protecting businesses and individuals in our local communities. We help businesses evaluate their risks and develop solutions tailored to their needs. We believe in empowering our employees. As a global firm, we offer employees resources in both technology and industry expertise, but we still maintain the local flavor of our offices. Our structure enables our teams to maintain their own unique, regional culture while leveraging support and resources from our corporate centers of excellence.

HUB is the 5th largest global insurance and employee benefits broker, providing a boundaryless array of property, casualty, risk management, life and health, employee benefits, investment and wealth management products and services. With over 17,000 employees in more than 550 offices throughout North America, HUB has grown substantially, in part due to our industry leading success... in mergers and acquisitions.

About the Position

In partnership with the Director of Marketing Analytics, you will manage the analytics, insights, reporting, and distribution of key marketing performance indicators to stakeholders. The ideal candidate has strong background in analytics and has a proven track record of delivering insights that have successfully driven new revenue and strengthened brands. Through partnering with the marketing team, agencies and IT the data analyst will provide insights that will enhance personalization capabilities, campaign execution, performance/predictive analytics, and help develop models for future improvements.

Role Description & Responsibilities:
• Conduct in-depth analysis of digital marketing campaigns to evaluate performance, identify trends, and generate actionable insights.
• Utilize web analytics tools such as Google Analytics or Adobe Analytics to track and measure key performance indicators (KPIs) across various digital channels.
• Collaborate with cross-functional teams including marketing, product, and sales to gather requirements and develop reporting solutions that address business needs.
• Establish yourself as a trusted advisor to key business stakeholders on data and analytics.
• Develop and maintain dashboards and reports to visualize campaign performance metrics and communicate findings to stakeholders.
• Use SQL queries to extract data from internal databases and perform data manipulation and cleansing as needed.
• Assist A/B testing, from identifying opportunities, running test, analyzing results and delivering recommendations to the business on optimization-based results
• Work closely with data engineers and IT teams to ensure data accuracy, integrity, and availability.
• Stay updated on industry trends and best practices in web analytics, digital marketing, and data analysis.

Job Requirements:
• Bachelor's degree in Computer Science, Statistics, Mathematics, Economics, or related field.
• 2+ years of experience in data analysis, preferably in a marketing or digital analytics role.
• Strong analytical and problem solving skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
• Proficiency in web analytics tools such as Google Analytics, Adobe Analytics, or similar platforms.
• Strong SQL skills with the ability to write complex queries to extract and manipulate data from relational databases.
• Experience with data visualization tools such as Tableau, Power BI, or Looker preferred.
• Extensive experience with Excel.
• Solid understanding of digital marketing concepts and metrics (e.g., CPC, CTR, conversion rates).
• Strong communication and collaboration skills with the ability to present complex data findings in a clear and concise manner.
• Ability to thrive in a fast-paced environment and manage multiple priorities effectively.

Preferred Qualifications:
• Experience working with CRM or marketing automation a plus
• Knowledge of key statistical principles including sample size calculation, design of experiments and familiarity with test designs a plus

JOIN OUR TEAM

Do you believe in the power of innovation, collaboration, and transformation? Do you thrive in a supportive and client focused work environment? Are you looking for an opportunity to help build and drive change in a rapidly growing and evolving organization? When you join HUB, you will be part of a community of learners and doers focused on helping our leaders maximize the potential of their employees.

Department Marketing

Required Experience: 2-5 years of relevant experience

Required Travel: Negligible

Required Education: Bachelor's degree (4-year degree)

HUB International Limited is an equal opportunity and affirmative action employer that does not discriminate on the basis of race/ethnicity, national origin, religion, age, color, sex, sexual orientation, gender identity, disability or veteran's status, or any other characteristic protected by local, state or federal laws, rules or regulations. The EEO is the Law poster and its supplement is available here athttp://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm.

EEOAA Policy

E-Verify Program

We endeavor to make this website accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact the US Recruiting Team toll-free at (844) 300-9193 orUSRecruiting@hubinternational.com. This contact information is for accommodation requests only; do not use this contact information to inquire about the status of applications","[{'items': [""ABOUT US\n\nAt HUB International, we are a team of entrepreneurs. We believe in empowering our clients, and we do so by protecting businesses and individuals in our local communities. We help businesses evaluate their risks and develop solutions tailored to their needs. We believe in empowering our employees. As a global firm, we offer employees resources in both technology and industry expertise, but we still maintain the local flavor of our offices. Our structure enables our teams to maintain their own unique, regional culture while leveraging support and resources from our corporate centers of excellence.\n\nHUB is the 5th largest global insurance and employee benefits broker, providing a boundaryless array of property, casualty, risk management, life and health, employee benefits, investment and wealth management products and services. With over 17,000 employees in more than 550 offices throughout North America, HUB has grown substantially, in part due to our industry leading success... in mergers and acquisitions.\n\nAbout the Position\n\nIn partnership with the Director of Marketing Analytics, you will manage the analytics, insights, reporting, and distribution of key marketing performance indicators to stakeholders. The ideal candidate has strong background in analytics and has a proven track record of delivering insights that have successfully driven new revenue and strengthened brands. Through partnering with the marketing team, agencies and IT the data analyst will provide insights that will enhance personalization capabilities, campaign execution, performance/predictive analytics, and help develop models for future improvements.\n\nRole Description & Responsibilities:\n• Conduct in-depth analysis of digital marketing campaigns to evaluate performance, identify trends, and generate actionable insights.\n• Utilize web analytics tools such as Google Analytics or Adobe Analytics to track and measure key performance indicators (KPIs) across various digital channels.\n• Collaborate with cross-functional teams including marketing, product, and sales to gather requirements and develop reporting solutions that address business needs.\n• Establish yourself as a trusted advisor to key business stakeholders on data and analytics.\n• Develop and maintain dashboards and reports to visualize campaign performance metrics and communicate findings to stakeholders.\n• Use SQL queries to extract data from internal databases and perform data manipulation and cleansing as needed.\n• Assist A/B testing, from identifying opportunities, running test, analyzing results and delivering recommendations to the business on optimization-based results\n• Work closely with data engineers and IT teams to ensure data accuracy, integrity, and availability.\n• Stay updated on industry trends and best practices in web analytics, digital marketing, and data analysis.\n\nJob Requirements:\n• Bachelor's degree in Computer Science, Statistics, Mathematics, Economics, or related field.\n• 2+ years of experience in data analysis, preferably in a marketing or digital analytics role.\n• Strong analytical and problem solving skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.\n• Proficiency in web analytics tools such as Google Analytics, Adobe Analytics, or similar platforms.\n• Strong SQL skills with the ability to write complex queries to extract and manipulate data from relational databases.\n• Experience with data visualization tools such as Tableau, Power BI, or Looker preferred.\n• Extensive experience with Excel.\n• Solid understanding of digital marketing concepts and metrics (e.g., CPC, CTR, conversion rates).\n• Strong communication and collaboration skills with the ability to present complex data findings in a clear and concise manner.\n• Ability to thrive in a fast-paced environment and manage multiple priorities effectively.\n\nPreferred Qualifications:\n• Experience working with CRM or marketing automation a plus\n• Knowledge of key statistical principles including sample size calculation, design of experiments and familiarity with test designs a plus\n\nJOIN OUR TEAM\n\nDo you believe in the power of innovation, collaboration, and transformation? Do you thrive in a supportive and client focused work environment? Are you looking for an opportunity to help build and drive change in a rapidly growing and evolving organization? When you join HUB, you will be part of a community of learners and doers focused on helping our leaders maximize the potential of their employees.\n\nDepartment Marketing\n\nRequired Experience: 2-5 years of relevant experience\n\nRequired Travel: Negligible\n\nRequired Education: Bachelor's degree (4-year degree)\n\nHUB International Limited is an equal opportunity and affirmative action employer that does not discriminate on the basis of race/ethnicity, national origin, religion, age, color, sex, sexual orientation, gender identity, disability or veteran's status, or any other characteristic protected by local, state or federal laws, rules or regulations. The EEO is the Law poster and its supplement is available here athttp://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm.\n\nEEOAA Policy\n\nE-Verify Program\n\nWe endeavor to make this website accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact the US Recruiting Team toll-free at (844) 300-9193 orUSRecruiting@hubinternational.com. This contact information is for accommodation requests only; do not use this contact information to inquire about the status of applications""]}]","[{'link': 'http://www.hubinternational.com/', 'text': 'hubinternational.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=Hub+International&sa=X&ved=0ahUKEwiWg53F176FAxVSgIQIHVXXBMcQmJACCKEN', 'text': 'See web results for Hub International'}]","['1 day ago', 'Full-time']","{'postedAt': '1 day ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on Hub International Jobs', 'link': 'https://hubinternational.jobs/toronto-on/data-analyst/BC413EC38A2A4B0E87568E6D69AEE553/job/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Analyst,2024-04-13 03:38:22.978861
Data Analyst,theScore,Toronto,via Simplify,"theScore, a wholly-owned subsidiary of PENN Entertainment , empowers millions of sports fans through its digital media and sports betting products. Its media app ‘theScore’ is one of the most popular in North America, delivering fans highly personalized live scores, news, stats, and betting information from their favorite teams, leagues, and players. theScore’s sports betting app ‘theScore Bet Sportsbook & Casino’ delivers an immersive and holistic mobile sports betting and iCasino experience. theScore Bet is currently live in the Company’s home province of Ontario. theScore also creates and distributes innovative digital content through its web, social and esports platforms.

About the Role & Team

On the Data Insights & Analytics team, our mission is to develop high-quality and sustainable data-driven solutions to improve profitability, growth and the user experience. As a Data Analyst, you’ll work directly with the marketing team to help them leverage data to track performance... make better decisions and ultimately reach their goals. The ideal candidate has strong communications skills, a passion for data, a background in quantitative analysis and an interest in professional sports, betting & eSports.

About the Work

As a key member of our Analytics team you will:
• Develop a deep understanding of how users interact with theScore’s apps and websites.
• Leverage marketing analytics tools (e.g. Branch, Optimove, Google Analytics) and identify opportunities to apply advanced analytics techniques to drive insights.
• Create data models via dbtCloud to assist in database optimization and analyses
• Monitor and report on all marketing KPIs and investigate anomalies as they arise.
• Analyze and compare quality of paid acquisition and CRM campaigns for media & betting apps.
• Answer ad-hoc questions & requests via SQL by leveraging data available in various databases.
• Analyze results of betting promotions and recommend improvements & optimizations.
• Design, create, execute and measure results from multivariate testing related to marketing activities.
• Stay on top of emerging trends in media, sports betting, analytics & marketing industries.
• Liaise with business stakeholders to identify data-drive projects and perform deep-dive analyses to provide recommendations and help make impactful, data-driven decisions
• Oversee team’s analysis to ensure data and insights shared are accurate and informative.
• Mentor Junior Data Analysts.

About You
• University degree in Business, Economics, Computer Science or related field.
• 2+ years of related experience.
• Demonstrated ability to work with a variety of analytics tools such as, but not limited to: Looker, Mode, ThoughtSpot, Tableau, Power BI, Amplitude, Branch, Sensor Tower, Google Analytics.
• Strong knowledge of relational databases and SQL.
• Familiarity with analysis tools; R or Python packages are preferred.
• A passion and curiosity for solving analytical problems using quantitative approaches.
• Ability to take complex data and present it in a clear and simple manner.
• Ability to focus in a fast paced environment and multitask.
• Excellent written and oral communications skills.

What We Offer
• Competitive compensation package
• Fun, relaxed work environment
• Education and conference reimbursements.
• Parental leave top up
• Opportunities for career progression and mentoring others

#LI-REMOTE

Candidates residing in Ontario requiring special accommodation can email accessibilityoffice@thescore.com

theScore is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability or age","[{'items': ['theScore, a wholly-owned subsidiary of PENN Entertainment , empowers millions of sports fans through its digital media and sports betting products. Its media app ‘theScore’ is one of the most popular in North America, delivering fans highly personalized live scores, news, stats, and betting information from their favorite teams, leagues, and players. theScore’s sports betting app ‘theScore Bet Sportsbook & Casino’ delivers an immersive and holistic mobile sports betting and iCasino experience. theScore Bet is currently live in the Company’s home province of Ontario. theScore also creates and distributes innovative digital content through its web, social and esports platforms.\n\nAbout the Role & Team\n\nOn the Data Insights & Analytics team, our mission is to develop high-quality and sustainable data-driven solutions to improve profitability, growth and the user experience. As a Data Analyst, you’ll work directly with the marketing team to help them leverage data to track performance... make better decisions and ultimately reach their goals. The ideal candidate has strong communications skills, a passion for data, a background in quantitative analysis and an interest in professional sports, betting & eSports.\n\nAbout the Work\n\nAs a key member of our Analytics team you will:\n• Develop a deep understanding of how users interact with theScore’s apps and websites.\n• Leverage marketing analytics tools (e.g. Branch, Optimove, Google Analytics) and identify opportunities to apply advanced analytics techniques to drive insights.\n• Create data models via dbtCloud to assist in database optimization and analyses\n• Monitor and report on all marketing KPIs and investigate anomalies as they arise.\n• Analyze and compare quality of paid acquisition and CRM campaigns for media & betting apps.\n• Answer ad-hoc questions & requests via SQL by leveraging data available in various databases.\n• Analyze results of betting promotions and recommend improvements & optimizations.\n• Design, create, execute and measure results from multivariate testing related to marketing activities.\n• Stay on top of emerging trends in media, sports betting, analytics & marketing industries.\n• Liaise with business stakeholders to identify data-drive projects and perform deep-dive analyses to provide recommendations and help make impactful, data-driven decisions\n• Oversee team’s analysis to ensure data and insights shared are accurate and informative.\n• Mentor Junior Data Analysts.\n\nAbout You\n• University degree in Business, Economics, Computer Science or related field.\n• 2+ years of related experience.\n• Demonstrated ability to work with a variety of analytics tools such as, but not limited to: Looker, Mode, ThoughtSpot, Tableau, Power BI, Amplitude, Branch, Sensor Tower, Google Analytics.\n• Strong knowledge of relational databases and SQL.\n• Familiarity with analysis tools; R or Python packages are preferred.\n• A passion and curiosity for solving analytical problems using quantitative approaches.\n• Ability to take complex data and present it in a clear and simple manner.\n• Ability to focus in a fast paced environment and multitask.\n• Excellent written and oral communications skills.\n\nWhat We Offer\n• Competitive compensation package\n• Fun, relaxed work environment\n• Education and conference reimbursements.\n• Parental leave top up\n• Opportunities for career progression and mentoring others\n\n#LI-REMOTE\n\nCandidates residing in Ontario requiring special accommodation can email accessibilityoffice@thescore.com\n\ntheScore is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability or age']}]","[{'link': 'http://www.thescore.com/', 'text': 'thescore.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=theScore&sa=X&ved=0ahUKEwiWg53F176FAxVSgIQIHVXXBMcQmJACCNsN', 'text': 'See web results for theScore'}]","['3 days ago', 'Full-time']","{'postedAt': '3 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on Simplify', 'link': 'https://simplify.jobs/p/f228c014-0d32-4ed1-a4ec-a25ded54545c/Data-Analyst?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Analyst,2024-04-13 03:38:22.978861
Data Engineer,"Resource Informatics Group, Inc",Toronto,via LinkedIn,"Job Description Data Engineer
Toronto, Canada (Local)
Long Term

Key: Python and Rust, PostgreSQL, MySQL, Apache Spark, DuckDb, Clickhouse, Hadoop, Snowflake, AWS Redshift, Google BigQuery

Responsibilities
· Build and optimize our data pipelines and architectures for ingesting, processing, and storing large volumes of structured and unstructured data from Github.
· Develop and maintain our robust ETL (Extract, Transform, Load) processes to ensure data integrity and consistency.
· Collaborate with cross-functional teams to understand data requirements and translate them into efficient data models and schemas.
· Maintaining our data warehousing solutions, utilizing both traditional and emerging database technologies (e.g., Postgres & Clickhouse).
· Develop and maintain data processing workflows using programming languages such as Python and Rust.
· Continuously monitor and optimize data systems for performance, scalability, and reliability.
· Contribute to the development of data... quality assurance processes and tools.
· Requirements
· 4+ years of experience as a Data Engineer or in a similar role, working with large-scale data pipelines and architectures.
· Bachelor s degree in Computer Science, or a related field
· Strong proficiency in Python and Rust.
· Extensive experience with relational databases (e.g., PostgreSQL, MySQL)
· Familiarity with emerging and big data technologies and frameworks (e.g., Apache Spark, DuckDb, Clickhouse, Hadoop).
· Experience with data warehousing solutions (e.g., Snowflake, AWS Redshift, Google BigQuery).
· Knowledge of data modeling techniques and best practices.
· Strong problem-solving and analytical skills.
· Excellent communication and collaboration abilities.
· Familiarity with Docker and Kubernetes.
· We are even more interested in chatting if you...
· Knowledge of cryptocurrency, blockchain technology, and the crypto ecosystem (e.g., DeFi, NFTs, L1s, L2s).
· Have experience in web scraping (puppeteer, selenium).
· Have experience with React and front-end development.

· Hands-on experience with cryptocurrency transactions and interacting with blockchain networks","[{'items': ['Job Description Data Engineer\nToronto, Canada (Local)\nLong Term\n\nKey: Python and Rust, PostgreSQL, MySQL, Apache Spark, DuckDb, Clickhouse, Hadoop, Snowflake, AWS Redshift, Google BigQuery\n\nResponsibilities\n· Build and optimize our data pipelines and architectures for ingesting, processing, and storing large volumes of structured and unstructured data from Github.\n· Develop and maintain our robust ETL (Extract, Transform, Load) processes to ensure data integrity and consistency.\n· Collaborate with cross-functional teams to understand data requirements and translate them into efficient data models and schemas.\n· Maintaining our data warehousing solutions, utilizing both traditional and emerging database technologies (e.g., Postgres & Clickhouse).\n· Develop and maintain data processing workflows using programming languages such as Python and Rust.\n· Continuously monitor and optimize data systems for performance, scalability, and reliability.\n· Contribute to the development of data... quality assurance processes and tools.\n· Requirements\n· 4+ years of experience as a Data Engineer or in a similar role, working with large-scale data pipelines and architectures.\n· Bachelor s degree in Computer Science, or a related field\n· Strong proficiency in Python and Rust.\n· Extensive experience with relational databases (e.g., PostgreSQL, MySQL)\n· Familiarity with emerging and big data technologies and frameworks (e.g., Apache Spark, DuckDb, Clickhouse, Hadoop).\n· Experience with data warehousing solutions (e.g., Snowflake, AWS Redshift, Google BigQuery).\n· Knowledge of data modeling techniques and best practices.\n· Strong problem-solving and analytical skills.\n· Excellent communication and collaboration abilities.\n· Familiarity with Docker and Kubernetes.\n· We are even more interested in chatting if you...\n· Knowledge of cryptocurrency, blockchain technology, and the crypto ecosystem (e.g., DeFi, NFTs, L1s, L2s).\n· Have experience in web scraping (puppeteer, selenium).\n· Have experience with React and front-end development.\n\n· Hands-on experience with cryptocurrency transactions and interacting with blockchain networks']}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=Resource+Informatics+Group,+Inc&sa=X&ved=0ahUKEwjHoZHM176FAxXHkokEHfRSBicQmJACCMIJ', 'text': 'See web results for Resource Informatics Group, Inc'}]","['12 hours ago', 'Contractor']","{'postedAt': '12 hours ago', 'scheduleType': 'Contractor'}","{'title': '.nFg2eb{font-weight:500}.Bi6Ddc{font-weight:500}Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/data-engineer-at-resource-informatics-group-inc-3892970991?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
Data Platform Engineer Specialist_IaC and DataOps principles,Sanofi,Toronto,via Sanofi U.S.,"Reference No. R2715512

Position Title: Data Platform Engineer Specialist

Department: Global Data Platform

Location: Toronto, Ontario

At Sanofi, we chase the miracles of science to improve people’s lives. We believe our cutting-edge science and manufacturing, fueled by data and digital technologies, have the potential to transform the practice of medicine, turning the impossible into possible for millions of people.

As one of Canada’s leading investors in life sciences, manufacturing and research and development, we focus on delivering new and better ways to address unmet medical needs. Our life-changing and lifesaving products are grounded in science that Canadians can trust. They empower self-care, prevent and treat diseases, and help people live better.

Our vision for digital, data analytics and AI

Sanofi has embarked into a vast and ambitious digital transformation program. A cornerstone of this roadmap is the acceleration of its data transformation and of the adoption of... artificial intelligence (AI) and machine learning (ML) solutions. This has enabled us, to accelerate R&D, improve manufacturing and commercial performance, and bring novel drugs and vaccines to patients faster, all in order to improve health and save lives.

The Digital Team at Sanofi is a unique data-driven team. We pride ourselves on being data obsessed and highly focused on using state of the art processes along with global technologies to drive impact to our solutions. We measure our insights and products based on how they perform across the globe and hold ourselves to the highest regard as our solutions can impact millions of lives. When tackling a problem, we do not just ask how we will create a solution, but how we will create a solution that reaches across the world with the best possible societal outcome.

If you are passionate about improving the health and wellness of people across the globe using Data as your means, then you should look no farther than the Digital Team here at Sanofi. Join us on our journey in enabling Sanofi’s Digital Transformation through becoming an AI first organization.
• AI Factory - Versatile Teams Operating in Cross Functional Pods: Utilizing digital and data resources to develop AI products, bringing data management, AI and product development skills to products, programs and projects to create an agile, fulfilling and meaningful work environment.
• Leading Edge Tech Stack: Experience build products that will be deployed globally on a leading-edge tech stack.
• World Class Mentorship and Training: Working with renowned, published leaders and academics in machine learning to further develop your skillsets.

Who You Are:

You are an experienced data engineer who actively engages in designing and developing comprehensive solutions to support and enhance business operations. You have a strong understanding of back-end and front-end technologies and have experience implementing highly functional solutions that can scale. You have a passion for good user experience and know how to ensure user needs are met through agile development and stakeholder engagement. You are an excellent communicator who enjoys collaborating with cross functional teams, works with subject matter experts, mentor and support teams and manages to deliver professional grade solutions.

We are seeking an highly skilled Data Engineer with at least 4-6 years of diverse data engineering experience who will play vital role in implementation of Data platform for Sanofi's advanced analytic, AI, and ML initiatives. As a seasoned Data Engineer, you will play a critical role in designing and implementing globally scalable data engineering platform to make it easier for internal teams to start implementation of their user case and to enhance the lives of our global patients and customers. Your expertise will be instrumental in shaping the future of data-driven healthcare while providing technical leadership and mentorship to the data engineering team.

In your role, you will be reporting to Senior Data Platform Manager, working closely with leadership to build data platform with inputs and feedback received from various teams across data foundations and business to address their immediate and long-term needs. You will be responsible for mentoring data platform engineers and have opportunity to learn from technical teams, SME's and business leaders about available platforms, tools and business processes.

Key Responsibilities:
• Collaborate with experienced data engineers, data scientists, and other stakeholders to understand intricate data requirements, especially in areas like bioinformatics, omics, clinical data, and more.
• Design, implement, and maintain data infrastructure on AWS Cloud to support our data mesh architecture.
• Develop, automate, optimize, and fine-tune data platform provisioning, scaling, and maintenance tasks to improve operational efficiency, performance, scalability, and cost-effectiveness.
• Lead data pipeline design, development, and optimization, drawing on your expertise in data integration, ETL/ELT, modern tools, and AWS Cloud, to ensure efficient data processing and cutting-edge solutions.
• Implement data monitoring and alerting solutions while collaborating with DevOps teams to proactively identify and address data issues.
• Ensure data security, compliance, and governance standards are met throughout the data platform, adhering to global data engineering standards and principles.
• Establish and enforce global data engineering standards, ensuring strict adherence to data architecture, platform, quality, and governance principles.
• Demonstrate your expertise in implementing data warehouse/lake solutions, data mesh architectures, and distributed processing technologies (e.g., Spark, Hadoop, Kafka) for production environments.
• Showcase your advanced proficiency in SQL (preferably in Snowflake) and relational/non-relational databases to optimize complex data queries and manipulations.
• Exhibit mastery in programming languages such as Python, Shell scripting, and Scala/Java, leveraging them to develop sophisticated data engineering solutions.
• Work hand-in-hand with cross-functional agile teams to architect and implement hybrid-cloud solutions with automated pipelines, ensuring seamless and high-performance data processing.
• Act as a mentor and leader, providing guidance and mentorship to junior data engineers, fostering a collaborative and growth-oriented team culture.
• Engage actively with the data engineering community, sharing insights, best practices, and innovative ideas to contribute to the growth of the industry.
• Document data infrastructure design, configuration, and processes for reference and training purposes.

Key Requirements:
• Bachelor's/Master's degree in Computer Science, Engineering, Mathematics, or a related field. 4-6 years of proven and progressive experience in data engineering, with a strong preference for experience in the life sciences/pharmaceutical industry.
• Extensive background in designing, developing, and optimizing data solutions, including data pipelines, architectures, and data sets.
• Proven expertise in data integration technologies, ETL / ELT processes, and modern data engineering tools, with an emphasis on Informatica/IICS.
• Experience with multimodal data systems and architectures, including batch, near real-time, and streaming data.
• Demonstrated success in developing distributed architectures and processing technologies (e.g., Spark, Hadoop, Kafka) for large-scale data processing.
• Expertise in developing cloud-native data platforms on AWS, ensuring high performance, scalability, and fault tolerance.
• Advanced knowledge of SQL, relational/non-relational databases, and data query optimization.
• Proficiency in programming languages such as Python, Shell scripting, and Scala/Java.
• Expertise in managing cloud-native systems following IaC and DataOps principles (terraform, CI/CD, Orchestration, Actions)
• Extensive experience with agile development processes and concepts.
• Exceptional problem-solving skills and attention to detail.
• Excellent communication, presentation, and interpersonal skills.
• Ability to lead teams effectively and collaborate with stakeholders at all levels.

Pursue Progress

Discover Extraordinary

Better is out there. Better medications, better outcomes, better science. But progress doesn’t happen without people – people from different backgrounds, in different locations, doing different roles, all united by one thing: a desire to make miracles happen. So, let’s be those people.

Watch our ALL IN video and check out our Diversity, Equity and Inclusion actions at sanofi.com!

Sanofi is an equal opportunity employer committed to diversity and inclusion. Our goal is to attract, develop and retain highly talented employees from diverse backgrounds, allowing us to benefit from a wide variety of experiences and perspectives. We welcome and encourage applications from all qualified applicants. Accommodations for persons with disabilities required during the recruitment process are available upon request.

Thank you in advance for your interest.

Only those candidates selected for interviews will be contacted.

Follow Sanofi on Twitter: @SanofiCanada and on LinkedIn: https://www.linkedin.com/company/sanofi

#DBBCA #DDB

Pursue progress, discover extraordinary

Better is out there. Better medications, better outcomes, better science. But progress doesn’t happen without people – people from different backgrounds, in different locations, doing different roles, all united by one thing: a desire to make miracles happen. So, let’s be those people.

At Sanofi, we provide equal opportunities to all regardless of race, colour, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, ability or gender identity.

Watch our ALL IN video and check out our Diversity Equity and Inclusion actions at sanofi.com","[{'items': [""Reference No. R2715512\n\nPosition Title: Data Platform Engineer Specialist\n\nDepartment: Global Data Platform\n\nLocation: Toronto, Ontario\n\nAt Sanofi, we chase the miracles of science to improve people’s lives. We believe our cutting-edge science and manufacturing, fueled by data and digital technologies, have the potential to transform the practice of medicine, turning the impossible into possible for millions of people.\n\nAs one of Canada’s leading investors in life sciences, manufacturing and research and development, we focus on delivering new and better ways to address unmet medical needs. Our life-changing and lifesaving products are grounded in science that Canadians can trust. They empower self-care, prevent and treat diseases, and help people live better.\n\nOur vision for digital, data analytics and AI\n\nSanofi has embarked into a vast and ambitious digital transformation program. A cornerstone of this roadmap is the acceleration of its data transformation and of the adoption of... artificial intelligence (AI) and machine learning (ML) solutions. This has enabled us, to accelerate R&D, improve manufacturing and commercial performance, and bring novel drugs and vaccines to patients faster, all in order to improve health and save lives.\n\nThe Digital Team at Sanofi is a unique data-driven team. We pride ourselves on being data obsessed and highly focused on using state of the art processes along with global technologies to drive impact to our solutions. We measure our insights and products based on how they perform across the globe and hold ourselves to the highest regard as our solutions can impact millions of lives. When tackling a problem, we do not just ask how we will create a solution, but how we will create a solution that reaches across the world with the best possible societal outcome.\n\nIf you are passionate about improving the health and wellness of people across the globe using Data as your means, then you should look no farther than the Digital Team here at Sanofi. Join us on our journey in enabling Sanofi’s Digital Transformation through becoming an AI first organization.\n• AI Factory - Versatile Teams Operating in Cross Functional Pods: Utilizing digital and data resources to develop AI products, bringing data management, AI and product development skills to products, programs and projects to create an agile, fulfilling and meaningful work environment.\n• Leading Edge Tech Stack: Experience build products that will be deployed globally on a leading-edge tech stack.\n• World Class Mentorship and Training: Working with renowned, published leaders and academics in machine learning to further develop your skillsets.\n\nWho You Are:\n\nYou are an experienced data engineer who actively engages in designing and developing comprehensive solutions to support and enhance business operations. You have a strong understanding of back-end and front-end technologies and have experience implementing highly functional solutions that can scale. You have a passion for good user experience and know how to ensure user needs are met through agile development and stakeholder engagement. You are an excellent communicator who enjoys collaborating with cross functional teams, works with subject matter experts, mentor and support teams and manages to deliver professional grade solutions.\n\nWe are seeking an highly skilled Data Engineer with at least 4-6 years of diverse data engineering experience who will play vital role in implementation of Data platform for Sanofi's advanced analytic, AI, and ML initiatives. As a seasoned Data Engineer, you will play a critical role in designing and implementing globally scalable data engineering platform to make it easier for internal teams to start implementation of their user case and to enhance the lives of our global patients and customers. Your expertise will be instrumental in shaping the future of data-driven healthcare while providing technical leadership and mentorship to the data engineering team.\n\nIn your role, you will be reporting to Senior Data Platform Manager, working closely with leadership to build data platform with inputs and feedback received from various teams across data foundations and business to address their immediate and long-term needs. You will be responsible for mentoring data platform engineers and have opportunity to learn from technical teams, SME's and business leaders about available platforms, tools and business processes.\n\nKey Responsibilities:\n• Collaborate with experienced data engineers, data scientists, and other stakeholders to understand intricate data requirements, especially in areas like bioinformatics, omics, clinical data, and more.\n• Design, implement, and maintain data infrastructure on AWS Cloud to support our data mesh architecture.\n• Develop, automate, optimize, and fine-tune data platform provisioning, scaling, and maintenance tasks to improve operational efficiency, performance, scalability, and cost-effectiveness.\n• Lead data pipeline design, development, and optimization, drawing on your expertise in data integration, ETL/ELT, modern tools, and AWS Cloud, to ensure efficient data processing and cutting-edge solutions.\n• Implement data monitoring and alerting solutions while collaborating with DevOps teams to proactively identify and address data issues.\n• Ensure data security, compliance, and governance standards are met throughout the data platform, adhering to global data engineering standards and principles.\n• Establish and enforce global data engineering standards, ensuring strict adherence to data architecture, platform, quality, and governance principles.\n• Demonstrate your expertise in implementing data warehouse/lake solutions, data mesh architectures, and distributed processing technologies (e.g., Spark, Hadoop, Kafka) for production environments.\n• Showcase your advanced proficiency in SQL (preferably in Snowflake) and relational/non-relational databases to optimize complex data queries and manipulations.\n• Exhibit mastery in programming languages such as Python, Shell scripting, and Scala/Java, leveraging them to develop sophisticated data engineering solutions.\n• Work hand-in-hand with cross-functional agile teams to architect and implement hybrid-cloud solutions with automated pipelines, ensuring seamless and high-performance data processing.\n• Act as a mentor and leader, providing guidance and mentorship to junior data engineers, fostering a collaborative and growth-oriented team culture.\n• Engage actively with the data engineering community, sharing insights, best practices, and innovative ideas to contribute to the growth of the industry.\n• Document data infrastructure design, configuration, and processes for reference and training purposes.\n\nKey Requirements:\n• Bachelor's/Master's degree in Computer Science, Engineering, Mathematics, or a related field. 4-6 years of proven and progressive experience in data engineering, with a strong preference for experience in the life sciences/pharmaceutical industry.\n• Extensive background in designing, developing, and optimizing data solutions, including data pipelines, architectures, and data sets.\n• Proven expertise in data integration technologies, ETL / ELT processes, and modern data engineering tools, with an emphasis on Informatica/IICS.\n• Experience with multimodal data systems and architectures, including batch, near real-time, and streaming data.\n• Demonstrated success in developing distributed architectures and processing technologies (e.g., Spark, Hadoop, Kafka) for large-scale data processing.\n• Expertise in developing cloud-native data platforms on AWS, ensuring high performance, scalability, and fault tolerance.\n• Advanced knowledge of SQL, relational/non-relational databases, and data query optimization.\n• Proficiency in programming languages such as Python, Shell scripting, and Scala/Java.\n• Expertise in managing cloud-native systems following IaC and DataOps principles (terraform, CI/CD, Orchestration, Actions)\n• Extensive experience with agile development processes and concepts.\n• Exceptional problem-solving skills and attention to detail.\n• Excellent communication, presentation, and interpersonal skills.\n• Ability to lead teams effectively and collaborate with stakeholders at all levels.\n\nPursue Progress\n\nDiscover Extraordinary\n\nBetter is out there. Better medications, better outcomes, better science. But progress doesn’t happen without people – people from different backgrounds, in different locations, doing different roles, all united by one thing: a desire to make miracles happen. So, let’s be those people.\n\nWatch our ALL IN video and check out our Diversity, Equity and Inclusion actions at sanofi.com!\n\nSanofi is an equal opportunity employer committed to diversity and inclusion. Our goal is to attract, develop and retain highly talented employees from diverse backgrounds, allowing us to benefit from a wide variety of experiences and perspectives. We welcome and encourage applications from all qualified applicants. Accommodations for persons with disabilities required during the recruitment process are available upon request.\n\nThank you in advance for your interest.\n\nOnly those candidates selected for interviews will be contacted.\n\nFollow Sanofi on Twitter: @SanofiCanada and on LinkedIn: https://www.linkedin.com/company/sanofi\n\n#DBBCA #DDB\n\nPursue progress, discover extraordinary\n\nBetter is out there. Better medications, better outcomes, better science. But progress doesn’t happen without people – people from different backgrounds, in different locations, doing different roles, all united by one thing: a desire to make miracles happen. So, let’s be those people.\n\nAt Sanofi, we provide equal opportunities to all regardless of race, colour, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, ability or gender identity.\n\nWatch our ALL IN video and check out our Diversity Equity and Inclusion actions at sanofi.com""]}]","[{'link': 'http://www.sanofi.com/', 'text': 'sanofi.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=Sanofi&sa=X&ved=0ahUKEwjHoZHM176FAxXHkokEHfRSBicQmJACCIAK', 'text': 'See web results for Sanofi'}]","['2 days ago', 'Full-time']","{'postedAt': '2 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on Sanofi U.S.', 'link': 'https://jobs.sanofi.us/job/toronto/data-platform-engineer-specialist/507/55092954048?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
"Senior Data Engineer, Data & Analytics",Viral Nation Inc.,Toronto,via Greenhouse,"Viral Nation is looking for a highly-skilled and experienced Senior Data Engineer, Data & Analytics to join our dynamic organization. This role will play a pivotal role in shaping the technical direction of our data engineering and analytics team. As a senior member of the tech org, this role will collaborate within a cross-functional team, but also with technical and non-technical teams across the business, providing technical leadership, architectural guidance, and ensuring the successful delivery of high-quality, scalable, and maintainable solutions.

Responsibilities:
• Data Pipeline Development: Design, develop, and maintain robust, scalable data pipelines to collect, process, and store structured and unstructured data from several data sources for the purposes of reporting and analytics.
• Data Modeling and Architecture: Design and implement efficient data models and architectures to support analytical and reporting needs, ensuring data integrity, reliability, and performance.
•... Data Integration: Integrate data from various internal and external sources to ingest first, second and third-party data, including databases, APIs, and third-party platforms, while ensuring data quality and consistency.
• Performance Optimization: Continuously optimize data pipelines and infrastructure for improved performance, scalability, and cost-effectiveness, leveraging cloud-based technologies and other frameworks.
• Data Governance and Security: Implement and enforce data governance policies and security measures to protect sensitive data and ensure compliance with regulatory requirements.
• Monitoring and Maintenance: Monitor data pipelines and systems for performance issues and errors. Proactively identify and resolve issues to ensure the reliability and availability of data infrastructure.
• Documentation and Knowledge Sharing: Document data pipelines, architectures, and processes comprehensively. Share knowledge and best practices with team members to promote continuous learning and improvement.
• Collaboration and Communication: Collaborate closely with cross-functional teams, including, BI, Product and other stakeholders, to understand reporting and analytics requirements and deliver technical solutions. Communicate technical concepts and solutions effectively to non-technical stakeholders.

Qualifications and Skills:
• A minimum of 5+ years of experience as a Data Engineer or similar role, with a focus on designing and building scalable data pipelines and infrastructure.
• Deep understanding of database systems and data modeling techniques. Experience with both relational and NoSQL databases is preferred.
• Hands-on experience with cloud platforms such as AWS, Azure, or Google Cloud, and proficiency in cloud-based data technologies such as Google BigQuery, AWS Redshift and others.
• Strong proficiency in programming languages such as Python and ELT/ETL tooling such as DBT.
• Experience with data governance, security best practices, and compliance standards is desirable.
• Strong analytical and problem-solving skills, with the ability to translate complex business requirements into scalable technical solutions.
• Clear and concise cross-functional communication and collaboration skills.
• Bachelor's or Master’s degree in Computer Science, Software Engineering, or a related field, OR relevant experience is nice-to-have","[{'items': [""Viral Nation is looking for a highly-skilled and experienced Senior Data Engineer, Data & Analytics to join our dynamic organization. This role will play a pivotal role in shaping the technical direction of our data engineering and analytics team. As a senior member of the tech org, this role will collaborate within a cross-functional team, but also with technical and non-technical teams across the business, providing technical leadership, architectural guidance, and ensuring the successful delivery of high-quality, scalable, and maintainable solutions.\n\nResponsibilities:\n• Data Pipeline Development: Design, develop, and maintain robust, scalable data pipelines to collect, process, and store structured and unstructured data from several data sources for the purposes of reporting and analytics.\n• Data Modeling and Architecture: Design and implement efficient data models and architectures to support analytical and reporting needs, ensuring data integrity, reliability, and performance.\n•... Data Integration: Integrate data from various internal and external sources to ingest first, second and third-party data, including databases, APIs, and third-party platforms, while ensuring data quality and consistency.\n• Performance Optimization: Continuously optimize data pipelines and infrastructure for improved performance, scalability, and cost-effectiveness, leveraging cloud-based technologies and other frameworks.\n• Data Governance and Security: Implement and enforce data governance policies and security measures to protect sensitive data and ensure compliance with regulatory requirements.\n• Monitoring and Maintenance: Monitor data pipelines and systems for performance issues and errors. Proactively identify and resolve issues to ensure the reliability and availability of data infrastructure.\n• Documentation and Knowledge Sharing: Document data pipelines, architectures, and processes comprehensively. Share knowledge and best practices with team members to promote continuous learning and improvement.\n• Collaboration and Communication: Collaborate closely with cross-functional teams, including, BI, Product and other stakeholders, to understand reporting and analytics requirements and deliver technical solutions. Communicate technical concepts and solutions effectively to non-technical stakeholders.\n\nQualifications and Skills:\n• A minimum of 5+ years of experience as a Data Engineer or similar role, with a focus on designing and building scalable data pipelines and infrastructure.\n• Deep understanding of database systems and data modeling techniques. Experience with both relational and NoSQL databases is preferred.\n• Hands-on experience with cloud platforms such as AWS, Azure, or Google Cloud, and proficiency in cloud-based data technologies such as Google BigQuery, AWS Redshift and others.\n• Strong proficiency in programming languages such as Python and ELT/ETL tooling such as DBT.\n• Experience with data governance, security best practices, and compliance standards is desirable.\n• Strong analytical and problem-solving skills, with the ability to translate complex business requirements into scalable technical solutions.\n• Clear and concise cross-functional communication and collaboration skills.\n• Bachelor's or Master’s degree in Computer Science, Software Engineering, or a related field, OR relevant experience is nice-to-have""]}]","[{'link': 'http://www.viralnation.com/', 'text': 'viralnation.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=Viral+Nation+Inc.&sa=X&ved=0ahUKEwjHoZHM176FAxXHkokEHfRSBicQmJACCL4K', 'text': 'See web results for Viral Nation Inc.'}]","['3 days ago', 'Full-time']","{'postedAt': '3 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on Greenhouse', 'link': 'https://boards.greenhouse.io/viralnation/jobs/4345843007?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
Sr./Lead Data Engineer - Data Products & Platforms,Insight Global,Toronto,via BASF Veterans Jobs,"Job Description

Insight Global is looking for a Senior Data Engineer to join the team at the top pension client. This team seeks a Lead and Sr. Data Engineer focusing on Backend Development and Devops experience. The chosen candidate will work within a team building out new features for their data analytics tools and work with Data for Portfolio strategy deployment.

Role Overview:

 - Design solutions aligned with long-term architecture and technology strategy using Amazon Web Services (AWS) for Cloud development

 - Participate in the development life cycle from start to completion - requirements analysis, development, testing, and deployment.

 - Develop tools that prepare, transform, combine, and manage structured and unstructured data for use by business users

 - Intersection of data services and products.

 - Collaboration with data scientists and analytical workbench development.

Close collaboration with investment teams.

We are a company committed to creating diverse and... inclusive environments where people can bring their full, authentic selves to work every day. We are an equal opportunity/affirmative action employer that believes everyone matters. Qualified candidates will receive consideration for employment regardless of their race, color, ethnicity, religion, sex (including pregnancy), sexual orientation, gender identity and expression, marital status, national origin, ancestry, genetic factors, age, disability, protected veteran status, military or uniformed service member status, or any other status or characteristic protected by applicable laws, regulations, and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application or recruiting process, please send a request to HR@insightglobal.com .

   

To learn more about how we collect, keep, and process your private information, please review Insight Global's Workforce Privacy Policy: https://insightglobal.com/workforce-privacy-policy/ .

Skills and Requirements

Must Haves:

 - Backend development with Python, SQL and PySpark

 - Strong Cloud (AWS) Experience, working with AWS EMR

 - Kubernetes & Docker, Experience with Amazon Elastic Kubernetes Service (Amazon EKS)

 - Experience with DevOps

 - Strong experience in CI/CD and infrastructure as code.

 - Experience with Data Ingestion into Data Lakes Nice to Have:

 - Machine learning

 - Financial Institution experience

Front-end experience (react) null

We are a company committed to creating diverse and inclusive environments where people can bring their full, authentic selves to work every day. We are an equal employment opportunity/affirmative action employer that believes everyone matters. Qualified candidates will receive consideration for employment without regard to race, color, ethnicity, religion,sex (including pregnancy), sexual orientation, gender identity and expression, marital status, national origin, ancestry, genetic factors, age, disability, protected veteran status, military oruniformed service member status, or any other status or characteristic protected by applicable laws, regulations, andordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request to HR@insightglobal.com","[{'items': [""Job Description\n\nInsight Global is looking for a Senior Data Engineer to join the team at the top pension client. This team seeks a Lead and Sr. Data Engineer focusing on Backend Development and Devops experience. The chosen candidate will work within a team building out new features for their data analytics tools and work with Data for Portfolio strategy deployment.\n\nRole Overview:\n\n\u2003- Design solutions aligned with long-term architecture and technology strategy using Amazon Web Services (AWS) for Cloud development\n\n\u2003- Participate in the development life cycle from start to completion - requirements analysis, development, testing, and deployment.\n\n\u2003- Develop tools that prepare, transform, combine, and manage structured and unstructured data for use by business users\n\n\u2003- Intersection of data services and products.\n\n\u2003- Collaboration with data scientists and analytical workbench development.\n\nClose collaboration with investment teams.\n\nWe are a company committed to creating diverse and... inclusive environments where people can bring their full, authentic selves to work every day. We are an equal opportunity/affirmative action employer that believes everyone matters. Qualified candidates will receive consideration for employment regardless of their race, color, ethnicity, religion, sex (including pregnancy), sexual orientation, gender identity and expression, marital status, national origin, ancestry, genetic factors, age, disability, protected veteran status, military or uniformed service member status, or any other status or characteristic protected by applicable laws, regulations, and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application or recruiting process, please send a request to HR@insightglobal.com .\n\n\u2003\u2003\u2003\n\nTo learn more about how we collect, keep, and process your private information, please review Insight Global's Workforce Privacy Policy: https://insightglobal.com/workforce-privacy-policy/ .\n\nSkills and Requirements\n\nMust Haves:\n\n\u2003- Backend development with Python, SQL and PySpark\n\n\u2003- Strong Cloud (AWS) Experience, working with AWS EMR\n\n\u2003- Kubernetes & Docker, Experience with Amazon Elastic Kubernetes Service (Amazon EKS)\n\n\u2003- Experience with DevOps\n\n\u2003- Strong experience in CI/CD and infrastructure as code.\n\n\u2003- Experience with Data Ingestion into Data Lakes Nice to Have:\n\n\u2003- Machine learning\n\n\u2003- Financial Institution experience\n\nFront-end experience (react) null\n\nWe are a company committed to creating diverse and inclusive environments where people can bring their full, authentic selves to work every day. We are an equal employment opportunity/affirmative action employer that believes everyone matters. Qualified candidates will receive consideration for employment without regard to race, color, ethnicity, religion,sex (including pregnancy), sexual orientation, gender identity and expression, marital status, national origin, ancestry, genetic factors, age, disability, protected veteran status, military oruniformed service member status, or any other status or characteristic protected by applicable laws, regulations, andordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request to HR@insightglobal.com""]}]","[{'link': 'http://www.insightglobal.com/', 'text': 'insightglobal.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=Insight+Global&sa=X&ved=0ahUKEwjHoZHM176FAxXHkokEHfRSBicQmJACCPcK', 'text': 'See web results for Insight Global'}]","['2 days ago', 'Full-time', 'No degree mentioned']","{'postedAt': '2 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on BASF Veterans Jobs', 'link': 'https://veterans.basf.us/toronto-on/srlead-data-engineer-data-products-platforms/0B92BF328C124E11B4EE216374860283/job/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
Data Engineer,TEEMA,Toronto,via LinkedIn,"Sr Data Engineer – 3 month contract

Must be in office 3-4 days per week

40 hour work week

6 plus years experience as a Data Engineer

Must have Capital Markets experience

• Airflow

• PySpark

• AWS (EMR, Athena, Iceberg)

• Python

• Hudi or Redshift (Hudi preferred)

• Capital Market experience

In this role, you will:

• Create and execute the data platform strategy that aligns with the Data & Analytics strategy

• Own the data platform development, maintenance, and administration to ensure we have the right

technology that brings in the correct data in the right format

• Create APIs and BI Integrations to deliver large datasets to the customers

• Responsible for building, maintaining, and managing large-scale data pipelines that power critical features

• Leverage cloud resources to support the acquisition and ingestion of internal and external data

sources

• Maximize the availability, recoverability, and operational efficiency of data pipelines and supporting systems

•... Build up and improve the observability of the platform as well as ps provide visibility into system health

• Leverage modern software development processes and tooling (e.g., CI/CD) to ensure a reliable and

scalable data platform

• Participate in technical design reviews, code reviews and pair programming sessions","[{'items': ['Sr Data Engineer – 3 month contract\n\nMust be in office 3-4 days per week\n\n40 hour work week\n\n6 plus years experience as a Data Engineer\n\nMust have Capital Markets experience\n\n• Airflow\n\n• PySpark\n\n• AWS (EMR, Athena, Iceberg)\n\n• Python\n\n• Hudi or Redshift (Hudi preferred)\n\n• Capital Market experience\n\nIn this role, you will:\n\n• Create and execute the data platform strategy that aligns with the Data & Analytics strategy\n\n• Own the data platform development, maintenance, and administration to ensure we have the right\n\ntechnology that brings in the correct data in the right format\n\n• Create APIs and BI Integrations to deliver large datasets to the customers\n\n• Responsible for building, maintaining, and managing large-scale data pipelines that power critical features\n\n• Leverage cloud resources to support the acquisition and ingestion of internal and external data\n\nsources\n\n• Maximize the availability, recoverability, and operational efficiency of data pipelines and supporting systems\n\n•... Build up and improve the observability of the platform as well as ps provide visibility into system health\n\n• Leverage modern software development processes and tooling (e.g., CI/CD) to ensure a reliable and\n\nscalable data platform\n\n• Participate in technical design reviews, code reviews and pair programming sessions']}]","[{'link': 'http://www.teemagroup.com/', 'text': 'teemagroup.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=TEEMA&sa=X&ved=0ahUKEwjHoZHM176FAxXHkokEHfRSBicQmJACCLEL', 'text': 'See web results for TEEMA'}]","['15 hours ago', 'CA$90–CA$100 an hour', 'Contractor', 'No degree mentioned']","{'postedAt': '15 hours ago', 'scheduleType': 'Contractor'}","{'title': 'Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/data-engineer-at-teema-3892388635?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
Data Engineer,KUBRA,Toronto,via LinkedIn,"Overview

KUBRA is in growth mode and currently seeking a Data Engineer to join our Data Analytics Team!

As a Data Engineer, you will be working on designing and maintaining our data Infrastructure and ETL processes under the direction of the Team Lead, or Senior Data Engineer. The best part? You will also get the opportunity to collaborate with an amazing Data Analytics team to provide BI Analysis as a secondary focus!

This is a hybrid role for our Mississauga office.

What you get to do every day
• Design, build, and maintain data infrastructure, ETL processes, and data pipelines
• Design, build and maintain data pipelines in AWS and Databricks
• Build and optimize python/pyspark framework
• Maintain SQL Server and AWS data infrastructure
• Work with Unstructured/Semi Structured data and build reporting tables
• Assist the BI Analyst to manage client reporting requirements
• Build Data models and assist the BI Analyst to offer data driven insights
• Design data models and automate... manual processes
• Migrate on-premise data systems to AWS cloud and maintain existing SSIS packages
• Foster an environment that emphasizes trust, open communication, creative thinking, and cohesive team effort

What kind of person should you be?
• Excellent written and verbal communication skills and an ability to maintain a high degree of professionalism in all client communications
• Ability to influence others, build relationships, manage conflicts, and handle negotiations
• Excellent organization, time management, problem-solving, and analytical skills
• Proactive mindset and ability to work independently in a fast-paced environment focused on results
• Ability to handle pressure

What skills do you need?
• Bachelor's or Masters’ degree in Computer Science, Statistics, or Analytics
• Minimum of 3 to 4 years of cloud experience on any of the major cloud platforms preferably AWS
• Hands on Knowledge of Data Modeling, Warehousing and BI Reporting Tools
• Demonstrable experience with one or more of SQL, R, Python, Spark, or Kafka
• Preferable to have experience with one or more of BI tools, Databricks, Snowflake/Redshift, DBT
• Experience with handling streaming data is an asset

What can you expect from us?
• Award-winning culture that fosters growth, diversity and inclusion for all
• Paid day off for your birthday
• Access to LinkedIn learning courses
• Continued education with our education reimbursement program
• Flexible schedules
• Free unlimited access to our refreshment stations (fully stocked with tea, coffee and other beverages)
• Two paid days for volunteer opportunities
• Well-being days!

KUBRA is an equal opportunity employer dedicated to building an inclusive and diverse workforce. We will provide accommodations during the recruitment process upon request by emailing the recruitment-team@kubra.com. Information received relating to accommodation will be addressed confidentially. We thank all applicants for their interest; however, only candidates under consideration will be contacted.

While we value the skills and experiences listed in our job requirements, we also recognize that talent comes in many forms, and welcome applications from candidates who meet most but not all specified requirements. If you possess a strong desire to learn and grow in a dynamic work environment, apply now!

KUBRA is a fast-growing company that delivers customer communications solutions to some of the largest utility, insurance, and government entities across North America. KUBRA offers billing and payments, mapping, mobile apps, proactive communications, and artificial intelligence solutions for customers. With more than 1.5 billion customer interactions annually, KUBRA services reach over 40% of households in the U.S. and Canada. KUBRA is an operating subsidiary of Hearst.

Our office is small enough to allow creative individuals to flourish, yet large enough to provide long-term stability. We place a tremendous amount of responsibility on our team members to be productive, focused and self-motivated. We offer a casual work environment, competitive compensation and a stellar benefits program","[{'items': [""Overview\n\nKUBRA is in growth mode and currently seeking a Data Engineer to join our Data Analytics Team!\n\nAs a Data Engineer, you will be working on designing and maintaining our data Infrastructure and ETL processes under the direction of the Team Lead, or Senior Data Engineer. The best part? You will also get the opportunity to collaborate with an amazing Data Analytics team to provide BI Analysis as a secondary focus!\n\nThis is a hybrid role for our Mississauga office.\n\nWhat you get to do every day\n• Design, build, and maintain data infrastructure, ETL processes, and data pipelines\n• Design, build and maintain data pipelines in AWS and Databricks\n• Build and optimize python/pyspark framework\n• Maintain SQL Server and AWS data infrastructure\n• Work with Unstructured/Semi Structured data and build reporting tables\n• Assist the BI Analyst to manage client reporting requirements\n• Build Data models and assist the BI Analyst to offer data driven insights\n• Design data models and automate... manual processes\n• Migrate on-premise data systems to AWS cloud and maintain existing SSIS packages\n• Foster an environment that emphasizes trust, open communication, creative thinking, and cohesive team effort\n\nWhat kind of person should you be?\n• Excellent written and verbal communication skills and an ability to maintain a high degree of professionalism in all client communications\n• Ability to influence others, build relationships, manage conflicts, and handle negotiations\n• Excellent organization, time management, problem-solving, and analytical skills\n• Proactive mindset and ability to work independently in a fast-paced environment focused on results\n• Ability to handle pressure\n\nWhat skills do you need?\n• Bachelor's or Masters’ degree in Computer Science, Statistics, or Analytics\n• Minimum of 3 to 4 years of cloud experience on any of the major cloud platforms preferably AWS\n• Hands on Knowledge of Data Modeling, Warehousing and BI Reporting Tools\n• Demonstrable experience with one or more of SQL, R, Python, Spark, or Kafka\n• Preferable to have experience with one or more of BI tools, Databricks, Snowflake/Redshift, DBT\n• Experience with handling streaming data is an asset\n\nWhat can you expect from us?\n• Award-winning culture that fosters growth, diversity and inclusion for all\n• Paid day off for your birthday\n• Access to LinkedIn learning courses\n• Continued education with our education reimbursement program\n• Flexible schedules\n• Free unlimited access to our refreshment stations (fully stocked with tea, coffee and other beverages)\n• Two paid days for volunteer opportunities\n• Well-being days!\n\nKUBRA is an equal opportunity employer dedicated to building an inclusive and diverse workforce. We will provide accommodations during the recruitment process upon request by emailing the recruitment-team@kubra.com. Information received relating to accommodation will be addressed confidentially. We thank all applicants for their interest; however, only candidates under consideration will be contacted.\n\nWhile we value the skills and experiences listed in our job requirements, we also recognize that talent comes in many forms, and welcome applications from candidates who meet most but not all specified requirements. If you possess a strong desire to learn and grow in a dynamic work environment, apply now!\n\nKUBRA is a fast-growing company that delivers customer communications solutions to some of the largest utility, insurance, and government entities across North America. KUBRA offers billing and payments, mapping, mobile apps, proactive communications, and artificial intelligence solutions for customers. With more than 1.5 billion customer interactions annually, KUBRA services reach over 40% of households in the U.S. and Canada. KUBRA is an operating subsidiary of Hearst.\n\nOur office is small enough to allow creative individuals to flourish, yet large enough to provide long-term stability. We place a tremendous amount of responsibility on our team members to be productive, focused and self-motivated. We offer a casual work environment, competitive compensation and a stellar benefits program""]}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=KUBRA&sa=X&ved=0ahUKEwjHoZHM176FAxXHkokEHfRSBicQmJACCO8L', 'text': 'See web results for KUBRA'}]","['1 day ago', 'Full-time']","{'postedAt': '1 day ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/data-engineer-at-kubra-3891210216?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
Cloud Data Engineer/Python,ClickJobs.io,Toronto,via LinkedIn,"Role: Cloud Data engineer / Python Developer Location: Mississauga, ON Type: Full-time with Hybrid. Experience: 6+ Years This position is for a Cloud Data engineer with a background in Python, Pyspark, SQL and data warehousing for enterprise level systems. The position calls for someone that is comfortable working with business users along with business analyst expertise. Major Responsibilities- Build and optimize data pipelines for efficient data ingestion, transformation and loading from various sources while ensuring data quality and integrity. Design, develop, and deploy Spark program in databricks environment to process and analyze large volumes of data. Experience of Delta Lake, DWH, Data Integration, Cloud, Design and Data Modelling. Proficient in developing programs in Python and SQL Experience with Data warehouse Dimensional data modeling. Working with event based/streaming technologies to ingest and process data. Working with structured, semi structured and unstructured... data. Optimize Databricks jobs for performance and scalability to handle big data workloads. Monitor and troubleshoot Databricks jobs, identify and resolve issues or bottlenecks. Implement best practices for data management, security, and governance within the Databricks environment. Experience designing and developing Enterprise Data Warehouse solutions. Proficient writing SQL queries and programming including stored procedures and reverse engineering existing process. Perform code reviews to ensure fit to requirements, optimal execution patterns and adherence to established standards. Skills: 5+ years Python coding experience. 5+ years - SQL Server based development of large datasets 5+ years with Experience with developing and deploying ETL pipelines using Databricks Pyspark. Experience in any cloud data warehouse like Synapse, Big Query, Redshift, Snowflake. Experience in Data warehousing - OLTP, OLAP, Dimensions, Facts, and Data modeling. Previous experience leading an enterprise-wide Cloud Data Platform migration with strong architectural and design skills. Experience with Cloud based data architectures, messaging, and analytics. Cloud certification(s). Any experience with Airflow is a Plus. Education-
• Minimally a BA degree within an engineering and/or computer science discipline
• Master’s degree strongly preferred We can offer you A highly competitive compensation and benefits package. A multinational organization with 48 offices in 19 countries and the possibility to work abroad Laptop and a mobile phone 15 days of paid annual leave (plus national holidays) Maternity & Paternity leave plans A comprehensive insurance plan including: medical, dental, vision, life insurance, and long-/short-term disability RRSP with employer’s contribution A higher education certification policy Comprehensive Relocation Expense Coverage Commuter benefits Extensive training opportunities, focused on skills, substantive knowledge, and personal development On-demand Udemy for Business for all Synechron employees with free access to more than 5000 curated courses Coaching opportunities with experienced colleagues from our Financial Innovation Labs (FinLabs) and Center of Excellences (CoE) groups Cutting edge projects at the world’s leading tier-one banks, financial institutions and insurance firms A flat and approachable organization A truly diverse, fun-loving and global work culture SYNECHRON’S DIVERSITY & INCLUSION STATEMENT Diversity & Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and is an affirmative action employer. Our Diversity, Equity, and Inclusion (DEI) initiative ‘Same Difference’ is committed to fostering an inclusive culture – promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more. All employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant’s gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law","[{'items': ['Role: Cloud Data engineer / Python Developer Location: Mississauga, ON Type: Full-time with Hybrid. Experience: 6+ Years This position is for a Cloud Data engineer with a background in Python, Pyspark, SQL and data warehousing for enterprise level systems. The position calls for someone that is comfortable working with business users along with business analyst expertise. Major Responsibilities- Build and optimize data pipelines for efficient data ingestion, transformation and loading from various sources while ensuring data quality and integrity. Design, develop, and deploy Spark program in databricks environment to process and analyze large volumes of data. Experience of Delta Lake, DWH, Data Integration, Cloud, Design and Data Modelling. Proficient in developing programs in Python and SQL Experience with Data warehouse Dimensional data modeling. Working with event based/streaming technologies to ingest and process data. Working with structured, semi structured and unstructured... data. Optimize Databricks jobs for performance and scalability to handle big data workloads. Monitor and troubleshoot Databricks jobs, identify and resolve issues or bottlenecks. Implement best practices for data management, security, and governance within the Databricks environment. Experience designing and developing Enterprise Data Warehouse solutions. Proficient writing SQL queries and programming including stored procedures and reverse engineering existing process. Perform code reviews to ensure fit to requirements, optimal execution patterns and adherence to established standards. Skills: 5+ years Python coding experience. 5+ years - SQL Server based development of large datasets 5+ years with Experience with developing and deploying ETL pipelines using Databricks Pyspark. Experience in any cloud data warehouse like Synapse, Big Query, Redshift, Snowflake. Experience in Data warehousing - OLTP, OLAP, Dimensions, Facts, and Data modeling. Previous experience leading an enterprise-wide Cloud Data Platform migration with strong architectural and design skills. Experience with Cloud based data architectures, messaging, and analytics. Cloud certification(s). Any experience with Airflow is a Plus. Education-\n• Minimally a BA degree within an engineering and/or computer science discipline\n• Master’s degree strongly preferred We can offer you A highly competitive compensation and benefits package. A multinational organization with 48 offices in 19 countries and the possibility to work abroad Laptop and a mobile phone 15 days of paid annual leave (plus national holidays) Maternity & Paternity leave plans A comprehensive insurance plan including: medical, dental, vision, life insurance, and long-/short-term disability RRSP with employer’s contribution A higher education certification policy Comprehensive Relocation Expense Coverage Commuter benefits Extensive training opportunities, focused on skills, substantive knowledge, and personal development On-demand Udemy for Business for all Synechron employees with free access to more than 5000 curated courses Coaching opportunities with experienced colleagues from our Financial Innovation Labs (FinLabs) and Center of Excellences (CoE) groups Cutting edge projects at the world’s leading tier-one banks, financial institutions and insurance firms A flat and approachable organization A truly diverse, fun-loving and global work culture SYNECHRON’S DIVERSITY & INCLUSION STATEMENT Diversity & Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and is an affirmative action employer. Our Diversity, Equity, and Inclusion (DEI) initiative ‘Same Difference’ is committed to fostering an inclusive culture – promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more. All employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant’s gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law']}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=ClickJobs.io&sa=X&ved=0ahUKEwjHoZHM176FAxXHkokEHfRSBicQmJACCKYM', 'text': 'See web results for ClickJobs.io'}]","['16 hours ago', 'Full-time']","{'postedAt': '16 hours ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/cloud-data-engineer-python-at-clickjobs-io-3895303699?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
"Lead Data Engineer, Data Products, Data Platforms",CPP Investments,Toronto,via Smart Recruiters Jobs,"Company Description

Make an impact at a global and dynamic investment organization

When you invest your career in CPP Investments, you join one of the most respected and fastest growing institutional investors in the world. With current assets under management valued in excess of $500 billion, CPP Investments is a professional investment management organization that globally invests the funds of the Canada Pension Plan (CPP) to help ensure long-term sustainability. The CPP Fund is projected to reach $3 trillion by 2050. CPP Investments invests in all major asset classes, including public equity, private equity, real estate, infrastructure and fixed-income instruments, and is headquartered in Toronto with offices in Hong Kong, London, Luxembourg, Mumbai, New York City, San Francisco, São Paulo and Sydney.

CPP Investments attracts and selects high-calibre individuals from top-tier institutions around the globe. Join our team and look forward to:
• Diverse and inspiring colleagues and... approachable leaders
• Stimulating work in a fast-paced, intellectually challenging environment
• Accelerated exposure and responsibility
• Global career development opportunities
• Being motivated every day by CPP Investments’ important social purpose and unshakable principles
• A flexible/hybrid work environment combining in office collaboration and remote working
• A deeply rooted culture of Integrity, Partnership and High Performance

If you share a passion for performance, value a collegial and collaborative culture, and approach everything with the highest integrity, here’s an opportunity for you to invest your career at CPP Investments.

Job Description

The Data Engineering team is looking for people who are passionate about working in agile delivery environments and resolving the engineering challenges of building robust and scalable data systems aligned to enterprise data strategy.

As Lead, Data Engineer you will be responsible for developing, constructing, and testing large-scale data analytics systems based on AWS cloud that will help address the disparate analytics needs of a growing organization.

Through close partnership with investment professionals, you will see firsthand how your contribution is delivering long-term value to the CPP Fund for the benefit of 20 million CPP contributors and beneficiaries. You are encouraged to bring an entrepreneurial, innovative mindset to tackle complex business requirements in the investment industry.

The opportunity:
• Conceptualize, design, and implement analytics products that enhance CPP Investments analytics capabilities.
• Design solutions aligned with long-term architecture and technology strategy using Amazon Web Services (AWS) for Cloud development.
• Participate in the development life cycle from start to completion - requirements analysis, development, testing, and deployment.
• Work in a fast-paced environment collaborating with developers, data engineers, architects, researchers, and data scientists.
• Ensure architecture will support the requirements of CPP Investments business.
• Develop tools that prepare, transform, combine, and manage structured and unstructured data for use by CPP Investments business users.
• Define and shape CPP Investments’ future technology and research process.

Qualifications
• University degree in Engineering or Computer Science preferred.
• Hands-on experience building data exploratory interfaces using Notebooks (JupyterHub/Lab, Spark/Livy, Sparkmagic, Enterprise Gateway, matplotlib, Plotly/Dash, etc.).
• Hands-on expertise with building data pipelines and applications, leveraging Kubernetes, Python, AWS Sagemaker, PySpark, YARN, S3, Athena, Glue, Lakeformation, Step Functions, Airflow, Serverless frameworks.
• Experience with Cloud based data and analytics platforms, warehouses (Redshift/Spectrum, Databricks, Snowflake), BI Tools, OLAP systems (Clickhouse, Druid), including a mix of relational, non-relational, streaming and event-based architectures.
• Familiar with cloud technology best practices to enable the distribution and analysis of big data on the cloud (formatting/partitioning/etc.).
• Experience of ETL pipelines, managing multiple datasets and providing necessary support.
• Knowledge & experience with driving IaC concepts within an organization, leveraging Terraform, Ansible, Packer, Puppet/Chef, etc.
• Deep proficiency in Python with experience using Spark, Pandas or PySpark.
• Ability to work in an entrepreneurial environment and be a self-starter.
• Demonstrated ability to easily deal with both abstract and concrete concepts and be able to reconcile them for the appropriate audience and context preferred.
• Quickly understand organizational dynamics and management priorities, and to be able to work effectively in a fast paced, results driven company.
• Demonstrate strong facilitation, negotiation, interpersonal, communication and collaboration skills.
• Experience with front-end framework ie. Angular, React is a plus
• Interests in the financial industry.
• Exemplify CPP Investments' Guiding Principles of Integrity, Partnership and High Performance.

Additional Information

Visit our LinkedIn Career Page or Follow us on LinkedIn. #LI-KE1

At CPP Investments, we are committed to diversity and equitable access to employment opportunities based on ability.

We thank all applicants for their interest but will only contact candidates selected to advance in the hiring process.

Our Commitment to Inclusion and Diversity:

In addition to being dedicated to building a workforce that reflects diverse talent, we are committed to fostering an inclusive and accessible experience. If you require an accommodation for any part of the recruitment process (including alternate formats of materials, accessible meeting rooms, etc.), please let us know and we will work with you to meet your needs.

Disclaimer:

CPP Investments does not accept resumes from employment placement agencies, head-hunters or recruitment suppliers that are not in a formal contractual arrangement with us. Our recruitment supplier arrangements are restricted to specific hiring needs and do not include this or other web-site job postings. Any resume or other information received from a supplier not approved by CPP Investments to provide resumes to this posting or web-site will be considered unsolicited and will not be considered. CPP Investments will not pay any referral, placement or other fee for the supply of such unsolicited resumes or information","[{'items': [""Company Description\n\nMake an impact at a global and dynamic investment organization\n\nWhen you invest your career in CPP Investments, you join one of the most respected and fastest growing institutional investors in the world. With current assets under management valued in excess of $500 billion, CPP Investments is a professional investment management organization that globally invests the funds of the Canada Pension Plan (CPP) to help ensure long-term sustainability. The CPP Fund is projected to reach $3 trillion by 2050. CPP Investments invests in all major asset classes, including public equity, private equity, real estate, infrastructure and fixed-income instruments, and is headquartered in Toronto with offices in Hong Kong, London, Luxembourg, Mumbai, New York City, San Francisco, São Paulo and Sydney.\n\nCPP Investments attracts and selects high-calibre individuals from top-tier institutions around the globe. Join our team and look forward to:\n• Diverse and inspiring colleagues and... approachable leaders\n• Stimulating work in a fast-paced, intellectually challenging environment\n• Accelerated exposure and responsibility\n• Global career development opportunities\n• Being motivated every day by CPP Investments’ important social purpose and unshakable principles\n• A flexible/hybrid work environment combining in office collaboration and remote working\n• A deeply rooted culture of Integrity, Partnership and High Performance\n\nIf you share a passion for performance, value a collegial and collaborative culture, and approach everything with the highest integrity, here’s an opportunity for you to invest your career at CPP Investments.\n\nJob Description\n\nThe Data Engineering team is looking for people who are passionate about working in agile delivery environments and resolving the engineering challenges of building robust and scalable data systems aligned to enterprise data strategy.\n\nAs Lead, Data Engineer you will be responsible for developing, constructing, and testing large-scale data analytics systems based on AWS cloud that will help address the disparate analytics needs of a growing organization.\n\nThrough close partnership with investment professionals, you will see firsthand how your contribution is delivering long-term value to the CPP Fund for the benefit of 20 million CPP contributors and beneficiaries. You are encouraged to bring an entrepreneurial, innovative mindset to tackle complex business requirements in the investment industry.\n\nThe opportunity:\n• Conceptualize, design, and implement analytics products that enhance CPP Investments analytics capabilities.\n• Design solutions aligned with long-term architecture and technology strategy using Amazon Web Services (AWS) for Cloud development.\n• Participate in the development life cycle from start to completion - requirements analysis, development, testing, and deployment.\n• Work in a fast-paced environment collaborating with developers, data engineers, architects, researchers, and data scientists.\n• Ensure architecture will support the requirements of CPP Investments business.\n• Develop tools that prepare, transform, combine, and manage structured and unstructured data for use by CPP Investments business users.\n• Define and shape CPP Investments’ future technology and research process.\n\nQualifications\n• University degree in Engineering or Computer Science preferred.\n• Hands-on experience building data exploratory interfaces using Notebooks (JupyterHub/Lab, Spark/Livy, Sparkmagic, Enterprise Gateway, matplotlib, Plotly/Dash, etc.).\n• Hands-on expertise with building data pipelines and applications, leveraging Kubernetes, Python, AWS Sagemaker, PySpark, YARN, S3, Athena, Glue, Lakeformation, Step Functions, Airflow, Serverless frameworks.\n• Experience with Cloud based data and analytics platforms, warehouses (Redshift/Spectrum, Databricks, Snowflake), BI Tools, OLAP systems (Clickhouse, Druid), including a mix of relational, non-relational, streaming and event-based architectures.\n• Familiar with cloud technology best practices to enable the distribution and analysis of big data on the cloud (formatting/partitioning/etc.).\n• Experience of ETL pipelines, managing multiple datasets and providing necessary support.\n• Knowledge & experience with driving IaC concepts within an organization, leveraging Terraform, Ansible, Packer, Puppet/Chef, etc.\n• Deep proficiency in Python with experience using Spark, Pandas or PySpark.\n• Ability to work in an entrepreneurial environment and be a self-starter.\n• Demonstrated ability to easily deal with both abstract and concrete concepts and be able to reconcile them for the appropriate audience and context preferred.\n• Quickly understand organizational dynamics and management priorities, and to be able to work effectively in a fast paced, results driven company.\n• Demonstrate strong facilitation, negotiation, interpersonal, communication and collaboration skills.\n• Experience with front-end framework ie. Angular, React is a plus\n• Interests in the financial industry.\n• Exemplify CPP Investments' Guiding Principles of Integrity, Partnership and High Performance.\n\nAdditional Information\n\nVisit our LinkedIn Career Page or Follow us on LinkedIn. #LI-KE1\n\nAt CPP Investments, we are committed to diversity and equitable access to employment opportunities based on ability.\n\nWe thank all applicants for their interest but will only contact candidates selected to advance in the hiring process.\n\nOur Commitment to Inclusion and Diversity:\n\nIn addition to being dedicated to building a workforce that reflects diverse talent, we are committed to fostering an inclusive and accessible experience. If you require an accommodation for any part of the recruitment process (including alternate formats of materials, accessible meeting rooms, etc.), please let us know and we will work with you to meet your needs.\n\nDisclaimer:\n\nCPP Investments does not accept resumes from employment placement agencies, head-hunters or recruitment suppliers that are not in a formal contractual arrangement with us. Our recruitment supplier arrangements are restricted to specific hiring needs and do not include this or other web-site job postings. Any resume or other information received from a supplier not approved by CPP Investments to provide resumes to this posting or web-site will be considered unsolicited and will not be considered. CPP Investments will not pay any referral, placement or other fee for the supply of such unsolicited resumes or information""]}]","[{'link': 'http://www.cppib.com/', 'text': 'cppib.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=CPP+Investments&sa=X&ved=0ahUKEwjHoZHM176FAxXHkokEHfRSBicQmJACCOMM', 'text': 'See web results for CPP Investments'}]",['Full-time'],{'scheduleType': 'Full-time'},"{'title': 'Apply on Smart Recruiters Jobs', 'link': 'https://jobs.smartrecruiters.com/CPPInvestmentsInvestissementsRPC/743999969197453-lead-data-engineer-data-products-data-platforms?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
Data Engineer,ENTEGRA,Toronto,via LinkedIn,"Job Type

Full-time

Description

Position Summary:

Strong background in coding, database management, and machine learning practices. Experience in Python programming, Power BI, databases and SQL, and a passion for developing internal tools to enhance current processes and facilitate future developments. Support various projects by leveraging expertise in data engineering and machine learning practices.

Responsibilities
• Conduct data cleaning and preprocessing tasks to prepare raw data for analysis and modeling.
• Investigate trends and gain insights into the data to highlight issues and entitlements using BI tools.
• Build internal tools and frameworks to automate repetitive tasks, improve data quality, and streamline data workflows.
• Utilize Python to build data processing scripts, machine learning models, and internal tools to advance current processes.
• Develop and optimize databases and SQL queries to manage large volumes of structured and unstructured data effectively.
•... Support the development, deployment, and maintenance of data pipelines and AI advancements for our products.
• Stay updated on the latest advancements in data engineering, machine learning, and data science practices to drive innovation within the company.
• Operational Excellence: Actively participate in continuous improvement initiatives, consistently working towards the achievement of individual and team goals.
• Additional Duties: Perform all other duties as assigned.

Requirements
• Bachelor’s or Master’s (preferred) degree in Data Science, Computer Science, Engineering, Mathematics, or a related field.
• 2+ years of experience as an effective data engineer with knowledge of best practices.
• 2+ years proven efficiency and facility with Python.
• Proven capability with BI tools (Power BI, Tableau, etc.).
• Strong understanding of data structures, algorithms, and database concepts.
• Eagerness to expand skills in data science, machine learning and statistical modelling.
• Effective written and verbal communication skills.
• Ability to work autonomously and collaboratively with cross-functional teams.
• Strong attention to detail and analytical skills.
• Excellent communication and reporting skills.
• Experience within the in-line inspection industry (preferred).
• Demonstrates a commitment to integrating the ENTEGRA® Core Values into daily work and life. — Be Innovative. Be Devoted. Be Honest. Be Accountable. Be Genuine. Be Industrious. Be Stewards. Be Excellent.

Location:
• Woodbridge, ON L4L 5Z9, Canada - Global Technology Center
• ENG - Engineering
• Hybrid
• Full-time

Benefits
• Medical, Dental, and Vision Insurance
• RRSP match
• Paid Vacation & Holidays
• Life & Disability Insurance
• Professional Development Opportunities

Who We Are

ENTEGRA® is the global leader in Ultra-High Resolution (UHR) pipeline in-line inspection technologies, driving innovation in the realm of pipeline integrity. We are a dynamic and forward-thinking company, driven by experienced and talented individuals, advanced processes, and cutting-edge technology. Our commitment is unwavering as we strive to revolutionize the landscape of in-line inspection, setting new standards for excellence.

Entegra is an Equal Opportunity Employer

ENTEGRA® is committed to a diverse and inclusive workplace. ENTEGRA® is an Equal Opportunity Employer and does not discriminate on the basis of race, color, religion or belief, national origin, age, sexual orientation, sex (including pregnancy), gender, gender identity or expression, family or parental status, protected veteran status, disability status, or any other legally protected status. If you require assistance or would like to request an accommodation related to the application process due to a disability, you may contact us at jobs@entegrasolutions.com","[{'items': ['Job Type\n\nFull-time\n\nDescription\n\nPosition Summary:\n\nStrong background in coding, database management, and machine learning practices. Experience in Python programming, Power BI, databases and SQL, and a passion for developing internal tools to enhance current processes and facilitate future developments. Support various projects by leveraging expertise in data engineering and machine learning practices.\n\nResponsibilities\n• Conduct data cleaning and preprocessing tasks to prepare raw data for analysis and modeling.\n• Investigate trends and gain insights into the data to highlight issues and entitlements using BI tools.\n• Build internal tools and frameworks to automate repetitive tasks, improve data quality, and streamline data workflows.\n• Utilize Python to build data processing scripts, machine learning models, and internal tools to advance current processes.\n• Develop and optimize databases and SQL queries to manage large volumes of structured and unstructured data effectively.\n•... Support the development, deployment, and maintenance of data pipelines and AI advancements for our products.\n• Stay updated on the latest advancements in data engineering, machine learning, and data science practices to drive innovation within the company.\n• Operational Excellence: Actively participate in continuous improvement initiatives, consistently working towards the achievement of individual and team goals.\n• Additional Duties: Perform all other duties as assigned.\n\nRequirements\n• Bachelor’s or Master’s (preferred) degree in Data Science, Computer Science, Engineering, Mathematics, or a related field.\n• 2+ years of experience as an effective data engineer with knowledge of best practices.\n• 2+ years proven efficiency and facility with Python.\n• Proven capability with BI tools (Power BI, Tableau, etc.).\n• Strong understanding of data structures, algorithms, and database concepts.\n• Eagerness to expand skills in data science, machine learning and statistical modelling.\n• Effective written and verbal communication skills.\n• Ability to work autonomously and collaboratively with cross-functional teams.\n• Strong attention to detail and analytical skills.\n• Excellent communication and reporting skills.\n• Experience within the in-line inspection industry (preferred).\n• Demonstrates a commitment to integrating the ENTEGRA® Core Values into daily work and life. — Be Innovative. Be Devoted. Be Honest. Be Accountable. Be Genuine. Be Industrious. Be Stewards. Be Excellent.\n\nLocation:\n• Woodbridge, ON L4L 5Z9, Canada - Global Technology Center\n• ENG - Engineering\n• Hybrid\n• Full-time\n\nBenefits\n• Medical, Dental, and Vision Insurance\n• RRSP match\n• Paid Vacation & Holidays\n• Life & Disability Insurance\n• Professional Development Opportunities\n\nWho We Are\n\nENTEGRA® is the global leader in Ultra-High Resolution (UHR) pipeline in-line inspection technologies, driving innovation in the realm of pipeline integrity. We are a dynamic and forward-thinking company, driven by experienced and talented individuals, advanced processes, and cutting-edge technology. Our commitment is unwavering as we strive to revolutionize the landscape of in-line inspection, setting new standards for excellence.\n\nEntegra is an Equal Opportunity Employer\n\nENTEGRA® is committed to a diverse and inclusive workplace. ENTEGRA® is an Equal Opportunity Employer and does not discriminate on the basis of race, color, religion or belief, national origin, age, sexual orientation, sex (including pregnancy), gender, gender identity or expression, family or parental status, protected veteran status, disability status, or any other legally protected status. If you require assistance or would like to request an accommodation related to the application process due to a disability, you may contact us at jobs@entegrasolutions.com']}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=ENTEGRA&sa=X&ved=0ahUKEwjHoZHM176FAxXHkokEHfRSBicQmJACCJkN', 'text': 'See web results for ENTEGRA'}]","['2 days ago', 'Full-time']","{'postedAt': '2 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/data-engineer-at-entegra-3890849531?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
Intermediate Data Engineer,confidential,Toronto,via Apex Systems,"Intermediate Data Engineer
Apex Systems is a global IT services provider, and our staffing practice has an opening in the Online Retail space for a Data Engineer with strong experience in DBT SQL, and creating ETL pipelines from scratch to place at our client.
Start date: ASAP.
Office Location: 100% remote (within Canada)

Application Process: It is best to apply via the medium on which you are seeing this posting. If you encounter technical difficulties submitting your resume, please send a Word version of your resume to Johanna at jheffernan@apexsystems.com
Job description:

? Work closely with cross-functional partners to communicate discovered trends, resolve data issues,
troubleshooting and analysis, and bug fixes
? Work with teams across the Company on data quality and availability
? Develop new frameworks to collect data including automated data collection
? Collaborate with Data Warehouse and Engineering teams to manage relevant datasets within the Company.

Data Collection... and Strategy: Develop and implement effective data collection systems and strategies to support automation and integration projects. Ensure data accuracy, availability, integrity and reliability for various initiatives.
Cross-Functional Collaboration: Collaborate with teams across different functions to support entity and taxonomy realignments. Identify process improvement opportunities and provide regular recommendations to enhance data-related processes.
SQL Expertise: Utilize efficient SQL writing and querying techniques to troubleshoot issues directly within the Snowflake data warehouse. Optimize queries for performance and maintainability.
Data Workflows and Insights: Work with data tools including SQL and Tableau to automate data workflows. Build meaningful insights through data visualizations, standardized reports, and dashboards for ad-hoc analyses.

ABOUT YOU
? Experience in a quantitative role at a product company
? A high level of organization and attention to detail
? Familiarity with Database interface tools, SQL, and Programming concepts
? Relevant experience within the Retail space along
? Eagerness to learn, flexibility to pivot when needed, savviness to navigate and thrive in a dynamic
environment, and a growth mindset needed to build a successful team and company.
? Experience with Data mapping, Data architecture, Data integration, ETL, and working on large datasets

Requirements:

\tBachelor’s degree or equivalent work experience in a relevant business/domain.
\tHands-on experience with SQL, Data Manipulation, and Data Analysis.
\tAbility to work independently as an individual contributor, taking ownership of assigned tasks/projects. Capable of collaborating effectively in team environments, especially on large/complex projects.
\tFlexibility to adapt to changing project requirements and reprioritizations.
\tProficiency in documentation, creating and accepting handovers, and effectively managing change/release communications.
\tStrong verbal and written communication skills
\tExposure to working with large data platforms and handling sizable datasets is a plus.
\tSnowflake, Cassandra or Vertica
\tMode/Tableau
\tcomfortability working with raw/ad data and the ability to create a story out of it.

Nice to have:

\t2+ years of experience applying Python (NumPy, Pandas, Other common libraries) programming to solve business challenges.
\tScripting/development experience with Python, including working with Google APIs, building data pipelines, authentication, file handling, and raw data manipulation is a plus.

EEO EmployerApex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystems.com or 844-463-6178","[{'items': ['Intermediate Data Engineer\nApex Systems is a global IT services provider, and our staffing practice has an opening in the Online Retail space for a Data Engineer with strong experience in DBT SQL, and creating ETL pipelines from scratch to place at our client.\nStart date: ASAP.\nOffice Location: 100% remote (within Canada)\n\nApplication Process: It is best to apply via the medium on which you are seeing this posting. If you encounter technical difficulties submitting your resume, please send a Word version of your resume to Johanna at jheffernan@apexsystems.com\nJob description:\n\n? Work closely with cross-functional partners to communicate discovered trends, resolve data issues,\ntroubleshooting and analysis, and bug fixes\n? Work with teams across the Company on data quality and availability\n? Develop new frameworks to collect data including automated data collection\n? Collaborate with Data Warehouse and Engineering teams to manage relevant datasets within the Company.\n\nData Collection... and Strategy: Develop and implement effective data collection systems and strategies to support automation and integration projects. Ensure data accuracy, availability, integrity and reliability for various initiatives.\nCross-Functional Collaboration: Collaborate with teams across different functions to support entity and taxonomy realignments. Identify process improvement opportunities and provide regular recommendations to enhance data-related processes.\nSQL Expertise: Utilize efficient SQL writing and querying techniques to troubleshoot issues directly within the Snowflake data warehouse. Optimize queries for performance and maintainability.\nData Workflows and Insights: Work with data tools including SQL and Tableau to automate data workflows. Build meaningful insights through data visualizations, standardized reports, and dashboards for ad-hoc analyses.\n\nABOUT YOU\n? Experience in a quantitative role at a product company\n? A high level of organization and attention to detail\n? Familiarity with Database interface tools, SQL, and Programming concepts\n? Relevant experience within the Retail space along\n? Eagerness to learn, flexibility to pivot when needed, savviness to navigate and thrive in a dynamic\nenvironment, and a growth mindset needed to build a successful team and company.\n? Experience with Data mapping, Data architecture, Data integration, ETL, and working on large datasets\n\nRequirements:\n\n\\tBachelor’s degree or equivalent work experience in a relevant business/domain.\n\\tHands-on experience with SQL, Data Manipulation, and Data Analysis.\n\\tAbility to work independently as an individual contributor, taking ownership of assigned tasks/projects. Capable of collaborating effectively in team environments, especially on large/complex projects.\n\\tFlexibility to adapt to changing project requirements and reprioritizations.\n\\tProficiency in documentation, creating and accepting handovers, and effectively managing change/release communications.\n\\tStrong verbal and written communication skills\n\\tExposure to working with large data platforms and handling sizable datasets is a plus.\n\\tSnowflake, Cassandra or Vertica\n\\tMode/Tableau\n\\tcomfortability working with raw/ad data and the ability to create a story out of it.\n\nNice to have:\n\n\\t2+ years of experience applying Python (NumPy, Pandas, Other common libraries) programming to solve business challenges.\n\\tScripting/development experience with Python, including working with Google APIs, building data pipelines, authentication, file handling, and raw data manipulation is a plus.\n\nEEO EmployerApex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystems.com or 844-463-6178']}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&q=confidential&sa=X&ved=0ahUKEwjHoZHM176FAxXHkokEHfRSBicQmJACCNQN', 'text': 'See web results for confidential'}]","['24 days ago', 'Contractor']","{'postedAt': '24 days ago', 'scheduleType': 'Contractor'}","{'title': 'Apply on Apex Systems', 'link': 'https://www.apexsystems.com/job/2021315_usa/intermediate-data-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
Data Engineer,Raise,Toronto,via Glassdoor,"Data Engineer

Location: Toronto - Hybrid- (1 day per week in office)

Contract Length: 12 Months with Possibility of extension.

We at Raise are hiring a Data Engineer for one of our top clients. After establishing themselves as an industry leader, they’re now expanding their team to meet rising demand.

We’re hiring right now; if you’re interested, apply below for your chance to join a great place to work.

Responsibilities
• Collaborate with stakeholders to deliver data models to address operational needs
• Combine multiple data sources across all contact center platforms and applications to support advanced analytics products
• Ingest massive volumes of structure and unstructured format data, model, transform and store it in a variety of data stores
• Support the Senior Data Engineer in defining data quality metrics and processes to monitor data in production environment
• Assist MIS & Data Analytics team with infrastructure development
• Develop ETL/ELT for analytics solutions... using Python, Spark, SQL and Power BI
• Produce ad hoc analyses, deep-dives, and drill downs on specific issues, topics, or areas of opportunity (e.g. process improvements)
• Support the Senior Data Engineer in preparing reports and presentations to communicate findings to stakeholders
• Assist in mentoring and up-skilling peers for advanced analytics
• Streamline, enhance and automate existing products to create capacity for team to develop new solution.

Candidate Requirements/Must Have Skills:
• 8- 10+ years of data engineering experience working with cross-functional data teams
• 8- 10+ years using python or other programming languages , package management, dependencies, and deployment
• 8- 10+ years using SQL for ETL and data analysis, flexibility on syntax (SQL server, PostgreSQL)
• 8- 10+ years of experience with data modelling, data warehousing and database design
• 8- 10+ years’ experience designing and building ETL/ELT, data pipelines, or data engineering solutions
• Strong Experience with Linux tools and shell scripting.

Nice-To-Have Skills:
• Experience with cloud architecture and the security (Azure, AWS, GCP)
• Experience and understanding of various ML techniques including NLP
• Hands-on experience with Big Data ecosystem tools (e.g. Hadoop, Hive, Spark, BigQuery) and object storage (e.g. blob, MinIO, GCS).
• Understanding of Agile and Scrum methodologies and experience working in a Scrum environment (Jira and Confluence)
• Experience with Docker, CI/CD tools, and Airflow and Kubernetes
• French and / or Spanish fluency an asset
• Contact center experience an asset
• Experience with telephony data (Avaya, Genesys) and WFM data (Verint, Aspect) an asset.

Looking for meaningful work? We can help!

Raise is an established hiring firm with over 65 years of experience. We believe strongly in making the world a better place through work, which is why we’re a certified B Corporation and donate 10% of our profits to charity.

We strive to build teams that reflect the diversity of the communities we work in. We encourage all qualified applicants to apply, including people from traditionally underrepresented groups such as women, visible minorities, Indigenous peoples, people identifying as LGBTQ2SI, veterans, and people with visible/nonvisible disabilities.

We have a dedicated webpage for accommodations where you can learn more about what we offer, and request accommodation: https://raise.jobs/accommodations/

In order to submit candidates for roles, our clients will sometimes require personal information to confirm the identity of applicants and their legal status to work. Raise will never ask you for personal or banking information unless you have been selected for a job. If you are ever unsure about the legitimacy of this or another job posting by Raise (or have any other questions), please contact us at +1 800-567-9675 or hello@raiserecruiting.com

#FIN24","[{'items': ['Data Engineer\n\nLocation: Toronto - Hybrid- (1 day per week in office)\n\nContract Length: 12 Months with Possibility of extension.\n\nWe at Raise are hiring a Data Engineer for one of our top clients. After establishing themselves as an industry leader, they’re now expanding their team to meet rising demand.\n\nWe’re hiring right now; if you’re interested, apply below for your chance to join a great place to work.\n\nResponsibilities\n• Collaborate with stakeholders to deliver data models to address operational needs\n• Combine multiple data sources across all contact center platforms and applications to support advanced analytics products\n• Ingest massive volumes of structure and unstructured format data, model, transform and store it in a variety of data stores\n• Support the Senior Data Engineer in defining data quality metrics and processes to monitor data in production environment\n• Assist MIS & Data Analytics team with infrastructure development\n• Develop ETL/ELT for analytics solutions... using Python, Spark, SQL and Power BI\n• Produce ad hoc analyses, deep-dives, and drill downs on specific issues, topics, or areas of opportunity (e.g. process improvements)\n• Support the Senior Data Engineer in preparing reports and presentations to communicate findings to stakeholders\n• Assist in mentoring and up-skilling peers for advanced analytics\n• Streamline, enhance and automate existing products to create capacity for team to develop new solution.\n\nCandidate Requirements/Must Have Skills:\n• 8- 10+ years of data engineering experience working with cross-functional data teams\n• 8- 10+ years using python or other programming languages , package management, dependencies, and deployment\n• 8- 10+ years using SQL for ETL and data analysis, flexibility on syntax (SQL server, PostgreSQL)\n• 8- 10+ years of experience with data modelling, data warehousing and database design\n• 8- 10+ years’ experience designing and building ETL/ELT, data pipelines, or data engineering solutions\n• Strong Experience with Linux tools and shell scripting.\n\nNice-To-Have Skills:\n• Experience with cloud architecture and the security (Azure, AWS, GCP)\n• Experience and understanding of various ML techniques including NLP\n• Hands-on experience with Big Data ecosystem tools (e.g. Hadoop, Hive, Spark, BigQuery) and object storage (e.g. blob, MinIO, GCS).\n• Understanding of Agile and Scrum methodologies and experience working in a Scrum environment (Jira and Confluence)\n• Experience with Docker, CI/CD tools, and Airflow and Kubernetes\n• French and / or Spanish fluency an asset\n• Contact center experience an asset\n• Experience with telephony data (Avaya, Genesys) and WFM data (Verint, Aspect) an asset.\n\nLooking for meaningful work? We can help!\n\nRaise is an established hiring firm with over 65 years of experience. We believe strongly in making the world a better place through work, which is why we’re a certified B Corporation and donate 10% of our profits to charity.\n\nWe strive to build teams that reflect the diversity of the communities we work in. We encourage all qualified applicants to apply, including people from traditionally underrepresented groups such as women, visible minorities, Indigenous peoples, people identifying as LGBTQ2SI, veterans, and people with visible/nonvisible disabilities.\n\nWe have a dedicated webpage for accommodations where you can learn more about what we offer, and request accommodation: https://raise.jobs/accommodations/\n\nIn order to submit candidates for roles, our clients will sometimes require personal information to confirm the identity of applicants and their legal status to work. Raise will never ask you for personal or banking information unless you have been selected for a job. If you are ever unsure about the legitimacy of this or another job posting by Raise (or have any other questions), please contact us at +1 800-567-9675 or hello@raiserecruiting.com\n\n#FIN24']}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=Raise&sa=X&ved=0ahUKEwjKy8vN176FAxWbIkQIHeIVBDQ4ChCYkAIIxAk', 'text': 'See web results for Raise'}]","['5 days ago', 'Full-time', 'No degree mentioned']","{'postedAt': '5 days ago', 'scheduleType': 'Full-time'}","{'title': '.nFg2eb{font-weight:500}.Bi6Ddc{font-weight:500}Apply directly on Glassdoor', 'link': 'https://www.glassdoor.ca/job-listing/data-engineer-raise-JV_IC2281069_KO0,13_KE14,19.htm?jl=1009177754763&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
Data Engineer (Hybrid),Homebase,Toronto,via ZipRecruiter,"Hi, Future Homie!

As a Homie, you'll be part of an unstoppable team that puts customers first, embraces each day with excitement, and strives for excellence in everything you do. We're revolutionizing the way small businesses manage their teams and grow their business. What this means for you is a shared passion for innovation and making a difference for the people we serve. So what do you say, will you join us on our mission to empower small businesses?=

The Data Engineer will be responsible for developing and maintaining data pipelines, building data models, and creating reports and dashboards that support business choices. The ideal candidate will have a strong background in Python and SQL, experience with tools like DBT, Looker, Databricks, and Kafka, and expertise in cloud analytics databases like Snowflake or Redshift.

You will make an impact by:
• Developing, maintaining, and optimizing data pipelines that process large volumes of structured and unstructured data from... various sources.
• Building and maintaining data models using dimensional data modeling techniques
• Designing and developing reports and dashboards that provide insights into business performance
• Working closely with cross-functional teams to understand business requirements and translate them into technical specifications
• Troubleshooting data issues and providing timely resolutions
• Optimizing query performance and implementing best practices for database design and development
• Collaborating with data scientists and analysts to support their data needs
• Providing technical guidance and mentorship to junior members of the team
• Continuously improve the quality of our data and analytics processes through automation and innovation
• Showing high ownership over projects and taking the initiative to drive them to completion

You are a bar raiser, this means you come with:
• 5+ years of experience in data engineering or related field
• Expertise in SQL and proficiency in data modeling and database design
• Working knowledge of a scripting language like Python, Shell, or Ruby
• Previous experience with data modeling, ETL/ELT development principles, and data warehousing concepts
• Strong experience with data transformation tools like DBT or Databricks
• Ability to break down complex business problems into small constituent units
• Excellent problem-solving skills and attention to detail
• Strong communication skills and ability to collaborate effectively with cross-functional teams
• Ability to organize and work on multiple tasks at the same time
• Ability to work on your own as well as effectively within a team environment
• Working knowledge of Git, Jira, and testing frameworks like great expectations.

What We Offer
• Stock Options - Everyone is an Owner!
• Competitive group health benefits coverage for you and your eligible dependents
• Group Investments, TFSA as well as an RRSP plan which offers a 4% company match
• Employer supplemented Medical, Dental, and Vision Insurance Plans
• Company-paid holidays and 20 days accrued PTO per year
• Continued learning and development stipend
• Paid parental leave after 1-year of service
• Top-of-the-line equipment and stipend for workspace setup
• Work from home days, Monday, Thursday, & Friday
• Meals provided at our vibrant workspaces
• Team offsites and monthly opportunities to engage with fellow Homies

What to Expect During the Interview Process
• Meet the Talent Acquisition team, Mavel W
• Meet the Hiring Manager, Kanchana P
• Participate in a Technical Interview
• Meet the Leadership team
• Professional Reference Checks
• Background Check + Offer Stage
• Welcome to the team, Homie

Diversity, Equity, and Inclusion at Homebase

At Homebase, we take pride in fostering a welcoming space where every Homie of every gender, age, orientation, culture, and walk of life can be their full selves. Diverse perspectives empower us to build the best-in-class platform for small businesses and hourly shift workers. We recognize that experience comes in many forms, so if you think you're close to what we're looking for (even if you don't meet 100% of the qualifications), we encourage you to apply!

About Us

Our mission is to make small business teams unstoppable.

Homebase is the everything app for hourly teams, with employee scheduling, time clocks, payroll, team communication, HR, and more. More than 100,000 small (but mighty) businesses rely on Homebase to make work radically easy and give their teams superpowers. As the leader in small business team management, Homebase tracked 1+ billion hours for 2.5+ million workers last year.

Homebase is based in San Francisco, Houston, Denver, and Toronto. We are backed by leading venture investors L Catterton Growth, Emerson Collective, Notable Capital, Bain Capital Ventures, Khosla Ventures, Baseline Ventures, Cowboy Ventures, Bedrock Capital, and PLUS Capital.
• *Interview Recording Notice:

By participating in interviews with Homebase, you consent to the use of Metaview, a recording and transcription tool, during the interview process. Please be aware that all interviews may be recorded and transcribed for the purpose of evaluating candidates and ensuring the quality of our recruitment process. If you do not consent to being recorded, please inform the Talent Team at the beginning of the call, and appropriate arrangements will be made to accommodate your preference. Your privacy is important to us, and the recorded interviews will only be used for internal evaluation and assessment of candidates","[{'items': [""Hi, Future Homie!\n\nAs a Homie, you'll be part of an unstoppable team that puts customers first, embraces each day with excitement, and strives for excellence in everything you do. We're revolutionizing the way small businesses manage their teams and grow their business. What this means for you is a shared passion for innovation and making a difference for the people we serve. So what do you say, will you join us on our mission to empower small businesses?=\n\nThe Data Engineer will be responsible for developing and maintaining data pipelines, building data models, and creating reports and dashboards that support business choices. The ideal candidate will have a strong background in Python and SQL, experience with tools like DBT, Looker, Databricks, and Kafka, and expertise in cloud analytics databases like Snowflake or Redshift.\n\nYou will make an impact by:\n• Developing, maintaining, and optimizing data pipelines that process large volumes of structured and unstructured data from... various sources.\n• Building and maintaining data models using dimensional data modeling techniques\n• Designing and developing reports and dashboards that provide insights into business performance\n• Working closely with cross-functional teams to understand business requirements and translate them into technical specifications\n• Troubleshooting data issues and providing timely resolutions\n• Optimizing query performance and implementing best practices for database design and development\n• Collaborating with data scientists and analysts to support their data needs\n• Providing technical guidance and mentorship to junior members of the team\n• Continuously improve the quality of our data and analytics processes through automation and innovation\n• Showing high ownership over projects and taking the initiative to drive them to completion\n\nYou are a bar raiser, this means you come with:\n• 5+ years of experience in data engineering or related field\n• Expertise in SQL and proficiency in data modeling and database design\n• Working knowledge of a scripting language like Python, Shell, or Ruby\n• Previous experience with data modeling, ETL/ELT development principles, and data warehousing concepts\n• Strong experience with data transformation tools like DBT or Databricks\n• Ability to break down complex business problems into small constituent units\n• Excellent problem-solving skills and attention to detail\n• Strong communication skills and ability to collaborate effectively with cross-functional teams\n• Ability to organize and work on multiple tasks at the same time\n• Ability to work on your own as well as effectively within a team environment\n• Working knowledge of Git, Jira, and testing frameworks like great expectations.\n\nWhat We Offer\n• Stock Options - Everyone is an Owner!\n• Competitive group health benefits coverage for you and your eligible dependents\n• Group Investments, TFSA as well as an RRSP plan which offers a 4% company match\n• Employer supplemented Medical, Dental, and Vision Insurance Plans\n• Company-paid holidays and 20 days accrued PTO per year\n• Continued learning and development stipend\n• Paid parental leave after 1-year of service\n• Top-of-the-line equipment and stipend for workspace setup\n• Work from home days, Monday, Thursday, & Friday\n• Meals provided at our vibrant workspaces\n• Team offsites and monthly opportunities to engage with fellow Homies\n\nWhat to Expect During the Interview Process\n• Meet the Talent Acquisition team, Mavel W\n• Meet the Hiring Manager, Kanchana P\n• Participate in a Technical Interview\n• Meet the Leadership team\n• Professional Reference Checks\n• Background Check + Offer Stage\n• Welcome to the team, Homie\n\nDiversity, Equity, and Inclusion at Homebase\n\nAt Homebase, we take pride in fostering a welcoming space where every Homie of every gender, age, orientation, culture, and walk of life can be their full selves. Diverse perspectives empower us to build the best-in-class platform for small businesses and hourly shift workers. We recognize that experience comes in many forms, so if you think you're close to what we're looking for (even if you don't meet 100% of the qualifications), we encourage you to apply!\n\nAbout Us\n\nOur mission is to make small business teams unstoppable.\n\nHomebase is the everything app for hourly teams, with employee scheduling, time clocks, payroll, team communication, HR, and more. More than 100,000 small (but mighty) businesses rely on Homebase to make work radically easy and give their teams superpowers. As the leader in small business team management, Homebase tracked 1+ billion hours for 2.5+ million workers last year.\n\nHomebase is based in San Francisco, Houston, Denver, and Toronto. We are backed by leading venture investors L Catterton Growth, Emerson Collective, Notable Capital, Bain Capital Ventures, Khosla Ventures, Baseline Ventures, Cowboy Ventures, Bedrock Capital, and PLUS Capital.\n• *Interview Recording Notice:\n\nBy participating in interviews with Homebase, you consent to the use of Metaview, a recording and transcription tool, during the interview process. Please be aware that all interviews may be recorded and transcribed for the purpose of evaluating candidates and ensuring the quality of our recruitment process. If you do not consent to being recorded, please inform the Talent Team at the beginning of the call, and appropriate arrangements will be made to accommodate your preference. Your privacy is important to us, and the recorded interviews will only be used for internal evaluation and assessment of candidates""]}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=Homebase&sa=X&ved=0ahUKEwjKy8vN176FAxWbIkQIHeIVBDQ4ChCYkAII_Ak', 'text': 'See web results for Homebase'}]","['5 days ago', 'Work from home', 'Full-time']","{'postedAt': '5 days ago', 'scheduleType': 'Full-time', 'workFromHome': True}","{'title': 'Apply on ZipRecruiter', 'link': 'https://www.ziprecruiter.com/c/Homebase/Job/Data-Engineer-(Hybrid)/-in-Toronto,ON?jid=82626d94fba58fed&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
Data Engineer,Morgan McKinley,Toronto,via Morgan McKinley,"Job Description

Our client is a leader within the SaaS solutions loyalty and rewards space focused on increasing redemption and consumer loyalty looking for a Data Engineer to join their team.

Experience we need
• Familiarity with graph database technologies such as TigerGraph, Neo4j, Amazon Neptune.
• Knowledge of Snowflake data warehousing platform.
• Basic understanding of data modeling, query optimization, and performance tuning concepts in graph databases.
• Knowledge of data integration techniques and tools for graph databases.
• Proficiency in programming languages such as Python, Java, or Scala.

Role requirements
• Implement data integration strategies between graph databases and Snowflake.
• Assist in maintaining and optimizing graph database schemas tailored for member profile management.
• Collaborate with senior data engineers, data scientists, and analysts to optimize query performance.
• Design and implement backend APIs for data access and manipulation within the... graph database.

Morgan McKinley encourages applications from all qualified candidates who represent the full diversity of communities in Canada. We welcome and encourage applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process. Alternative format available upon request","[{'items': ['Job Description\n\nOur client is a leader within the SaaS solutions loyalty and rewards space focused on increasing redemption and consumer loyalty looking for a Data Engineer to join their team.\n\nExperience we need\n• Familiarity with graph database technologies such as TigerGraph, Neo4j, Amazon Neptune.\n• Knowledge of Snowflake data warehousing platform.\n• Basic understanding of data modeling, query optimization, and performance tuning concepts in graph databases.\n• Knowledge of data integration techniques and tools for graph databases.\n• Proficiency in programming languages such as Python, Java, or Scala.\n\nRole requirements\n• Implement data integration strategies between graph databases and Snowflake.\n• Assist in maintaining and optimizing graph database schemas tailored for member profile management.\n• Collaborate with senior data engineers, data scientists, and analysts to optimize query performance.\n• Design and implement backend APIs for data access and manipulation within the... graph database.\n\nMorgan McKinley encourages applications from all qualified candidates who represent the full diversity of communities in Canada. We welcome and encourage applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process. Alternative format available upon request']}]","[{'link': 'http://www.morganmckinley.com/', 'text': 'morganmckinley.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=Morgan+McKinley&sa=X&ved=0ahUKEwjKy8vN176FAxWbIkQIHeIVBDQ4ChCYkAIIvAo', 'text': 'See web results for Morgan McKinley'}]","['10 days ago', 'Full-time', 'No degree mentioned']","{'postedAt': '10 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply directly on Morgan McKinley', 'link': 'https://www.morganmckinley.com/ca/jobs/ontario/data-engineer/1081814?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
"Lead Data Engineer, Data Products, Data Platforms",CPP Investments,Toronto,via Smart Recruiters Jobs,"Company Description

Make an impact at a global and dynamic investment organization

When you invest your career in CPP Investments, you join one of the most respected and fastest growing institutional investors in the world. With current assets under management valued in excess of $500 billion, CPP Investments is a professional investment management organization that globally invests the funds of the Canada Pension Plan (CPP) to help ensure long-term sustainability. The CPP Fund is projected to reach $3 trillion by 2050. CPP Investments invests in all major asset classes, including public equity, private equity, real estate, infrastructure and fixed-income instruments, and is headquartered in Toronto with offices in Hong Kong, London, Luxembourg, Mumbai, New York City, San Francisco, São Paulo and Sydney.

CPP Investments attracts and selects high-calibre individuals from top-tier institutions around the globe. Join our team and look forward to:
• Diverse and inspiring colleagues and... approachable leaders
• Stimulating work in a fast-paced, intellectually challenging environment
• Accelerated exposure and responsibility
• Global career development opportunities
• Being motivated every day by CPP Investments’ important social purpose and unshakable principles
• A flexible/hybrid work environment combining in office collaboration and remote working
• A deeply rooted culture of Integrity, Partnership and High Performance

If you share a passion for performance, value a collegial and collaborative culture, and approach everything with the highest integrity, here’s an opportunity for you to invest your career at CPP Investments.

Job Description

The Data Engineering team is looking for people who are passionate about working in agile delivery environments and resolving the engineering challenges of building robust and scalable data systems aligned to enterprise data strategy.

As Lead, Data Engineer you will be responsible for developing, constructing, and testing large-scale data analytics systems based on AWS cloud that will help address the disparate analytics needs of a growing organization.

Through close partnership with investment professionals, you will see firsthand how your contribution is delivering long-term value to the CPP Fund for the benefit of 20 million CPP contributors and beneficiaries. You are encouraged to bring an entrepreneurial, innovative mindset to tackle complex business requirements in the investment industry.

The opportunity:
• Conceptualize, design, and implement analytics products that enhance CPP Investments analytics capabilities.
• Design solutions aligned with long-term architecture and technology strategy using Amazon Web Services (AWS) for Cloud development.
• Participate in the development life cycle from start to completion - requirements analysis, development, testing, and deployment.
• Work in a fast-paced environment collaborating with developers, data engineers, architects, researchers, and data scientists.
• Ensure architecture will support the requirements of CPP Investments business.
• Develop tools that prepare, transform, combine, and manage structured and unstructured data for use by CPP Investments business users.
• Define and shape CPP Investments’ future technology and research process.

Qualifications
• University degree in Engineering or Computer Science preferred.
• Hands-on experience building data exploratory interfaces using Notebooks (JupyterHub/Lab, Spark/Livy, Sparkmagic, Enterprise Gateway, matplotlib, Plotly/Dash, etc.).
• Hands-on expertise with building data pipelines and applications, leveraging Kubernetes, Python, AWS Sagemaker, PySpark, YARN, S3, Athena, Glue, Lakeformation, Step Functions, Airflow, Serverless frameworks.
• Experience with Cloud based data and analytics platforms, warehouses (Redshift/Spectrum, Databricks, Snowflake), BI Tools, OLAP systems (Clickhouse, Druid), including a mix of relational, non-relational, streaming and event-based architectures.
• Familiar with cloud technology best practices to enable the distribution and analysis of big data on the cloud (formatting/partitioning/etc.).
• Experience of ETL pipelines, managing multiple datasets and providing necessary support.
• Knowledge & experience with driving IaC concepts within an organization, leveraging Terraform, Ansible, Packer, Puppet/Chef, etc.
• Deep proficiency in Python with experience using Spark, Pandas or PySpark.
• Ability to work in an entrepreneurial environment and be a self-starter.
• Demonstrated ability to easily deal with both abstract and concrete concepts and be able to reconcile them for the appropriate audience and context preferred.
• Quickly understand organizational dynamics and management priorities, and to be able to work effectively in a fast paced, results driven company.
• Demonstrate strong facilitation, negotiation, interpersonal, communication and collaboration skills.
• Experience with front-end framework ie. Angular, React is a plus
• Interests in the financial industry.
• Exemplify CPP Investments' Guiding Principles of Integrity, Partnership and High Performance.

Additional Information

Visit our LinkedIn Career Page or Follow us on LinkedIn. #LI-KE1

At CPP Investments, we are committed to diversity and equitable access to employment opportunities based on ability.

We thank all applicants for their interest but will only contact candidates selected to advance in the hiring process.

Our Commitment to Inclusion and Diversity:

In addition to being dedicated to building a workforce that reflects diverse talent, we are committed to fostering an inclusive and accessible experience. If you require an accommodation for any part of the recruitment process (including alternate formats of materials, accessible meeting rooms, etc.), please let us know and we will work with you to meet your needs.

Disclaimer:

CPP Investments does not accept resumes from employment placement agencies, head-hunters or recruitment suppliers that are not in a formal contractual arrangement with us. Our recruitment supplier arrangements are restricted to specific hiring needs and do not include this or other web-site job postings. Any resume or other information received from a supplier not approved by CPP Investments to provide resumes to this posting or web-site will be considered unsolicited and will not be considered. CPP Investments will not pay any referral, placement or other fee for the supply of such unsolicited resumes or information","[{'items': [""Company Description\n\nMake an impact at a global and dynamic investment organization\n\nWhen you invest your career in CPP Investments, you join one of the most respected and fastest growing institutional investors in the world. With current assets under management valued in excess of $500 billion, CPP Investments is a professional investment management organization that globally invests the funds of the Canada Pension Plan (CPP) to help ensure long-term sustainability. The CPP Fund is projected to reach $3 trillion by 2050. CPP Investments invests in all major asset classes, including public equity, private equity, real estate, infrastructure and fixed-income instruments, and is headquartered in Toronto with offices in Hong Kong, London, Luxembourg, Mumbai, New York City, San Francisco, São Paulo and Sydney.\n\nCPP Investments attracts and selects high-calibre individuals from top-tier institutions around the globe. Join our team and look forward to:\n• Diverse and inspiring colleagues and... approachable leaders\n• Stimulating work in a fast-paced, intellectually challenging environment\n• Accelerated exposure and responsibility\n• Global career development opportunities\n• Being motivated every day by CPP Investments’ important social purpose and unshakable principles\n• A flexible/hybrid work environment combining in office collaboration and remote working\n• A deeply rooted culture of Integrity, Partnership and High Performance\n\nIf you share a passion for performance, value a collegial and collaborative culture, and approach everything with the highest integrity, here’s an opportunity for you to invest your career at CPP Investments.\n\nJob Description\n\nThe Data Engineering team is looking for people who are passionate about working in agile delivery environments and resolving the engineering challenges of building robust and scalable data systems aligned to enterprise data strategy.\n\nAs Lead, Data Engineer you will be responsible for developing, constructing, and testing large-scale data analytics systems based on AWS cloud that will help address the disparate analytics needs of a growing organization.\n\nThrough close partnership with investment professionals, you will see firsthand how your contribution is delivering long-term value to the CPP Fund for the benefit of 20 million CPP contributors and beneficiaries. You are encouraged to bring an entrepreneurial, innovative mindset to tackle complex business requirements in the investment industry.\n\nThe opportunity:\n• Conceptualize, design, and implement analytics products that enhance CPP Investments analytics capabilities.\n• Design solutions aligned with long-term architecture and technology strategy using Amazon Web Services (AWS) for Cloud development.\n• Participate in the development life cycle from start to completion - requirements analysis, development, testing, and deployment.\n• Work in a fast-paced environment collaborating with developers, data engineers, architects, researchers, and data scientists.\n• Ensure architecture will support the requirements of CPP Investments business.\n• Develop tools that prepare, transform, combine, and manage structured and unstructured data for use by CPP Investments business users.\n• Define and shape CPP Investments’ future technology and research process.\n\nQualifications\n• University degree in Engineering or Computer Science preferred.\n• Hands-on experience building data exploratory interfaces using Notebooks (JupyterHub/Lab, Spark/Livy, Sparkmagic, Enterprise Gateway, matplotlib, Plotly/Dash, etc.).\n• Hands-on expertise with building data pipelines and applications, leveraging Kubernetes, Python, AWS Sagemaker, PySpark, YARN, S3, Athena, Glue, Lakeformation, Step Functions, Airflow, Serverless frameworks.\n• Experience with Cloud based data and analytics platforms, warehouses (Redshift/Spectrum, Databricks, Snowflake), BI Tools, OLAP systems (Clickhouse, Druid), including a mix of relational, non-relational, streaming and event-based architectures.\n• Familiar with cloud technology best practices to enable the distribution and analysis of big data on the cloud (formatting/partitioning/etc.).\n• Experience of ETL pipelines, managing multiple datasets and providing necessary support.\n• Knowledge & experience with driving IaC concepts within an organization, leveraging Terraform, Ansible, Packer, Puppet/Chef, etc.\n• Deep proficiency in Python with experience using Spark, Pandas or PySpark.\n• Ability to work in an entrepreneurial environment and be a self-starter.\n• Demonstrated ability to easily deal with both abstract and concrete concepts and be able to reconcile them for the appropriate audience and context preferred.\n• Quickly understand organizational dynamics and management priorities, and to be able to work effectively in a fast paced, results driven company.\n• Demonstrate strong facilitation, negotiation, interpersonal, communication and collaboration skills.\n• Experience with front-end framework ie. Angular, React is a plus\n• Interests in the financial industry.\n• Exemplify CPP Investments' Guiding Principles of Integrity, Partnership and High Performance.\n\nAdditional Information\n\nVisit our LinkedIn Career Page or Follow us on LinkedIn. #LI-KE1\n\nAt CPP Investments, we are committed to diversity and equitable access to employment opportunities based on ability.\n\nWe thank all applicants for their interest but will only contact candidates selected to advance in the hiring process.\n\nOur Commitment to Inclusion and Diversity:\n\nIn addition to being dedicated to building a workforce that reflects diverse talent, we are committed to fostering an inclusive and accessible experience. If you require an accommodation for any part of the recruitment process (including alternate formats of materials, accessible meeting rooms, etc.), please let us know and we will work with you to meet your needs.\n\nDisclaimer:\n\nCPP Investments does not accept resumes from employment placement agencies, head-hunters or recruitment suppliers that are not in a formal contractual arrangement with us. Our recruitment supplier arrangements are restricted to specific hiring needs and do not include this or other web-site job postings. Any resume or other information received from a supplier not approved by CPP Investments to provide resumes to this posting or web-site will be considered unsolicited and will not be considered. CPP Investments will not pay any referral, placement or other fee for the supply of such unsolicited resumes or information""]}]","[{'link': 'http://www.cppib.com/', 'text': 'cppib.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=CPP+Investments&sa=X&ved=0ahUKEwjKy8vN176FAxWbIkQIHeIVBDQ4ChCYkAII-go', 'text': 'See web results for CPP Investments'}]",['Full-time'],{'scheduleType': 'Full-time'},"{'title': 'Apply on Smart Recruiters Jobs', 'link': 'https://jobs.smartrecruiters.com/CPPInvestmentsInvestissementsRPC/743999969197453-lead-data-engineer-data-products-data-platforms?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
"Senior Data Engineer, Digital Solutions",MNP,Toronto,via LinkedIn,"What do you think of when you hear the name MNP? Most likely tax and accounting. As one of Canada’s largest consulting organizations, we’re so much more! We’re also serious about technology.

Make an impact with our Digital Solutions team as a Senior Data Engineer. This diverse team of tech-savvy problem solvers has expertise and delivery depth across client platforms, applied data and analytics, applications and cloud and business platforms solutions. As a trusted advisor, you’ll gather, secure and organize meaningful insights to design digital solutions that meet clients’ evolving needs.

At MNP Digital, we’re a team of highly skilled and creative thinkers that continuously support and learn from each other. We pride ourselves on translating our clients’ challenges into real results by leveraging technology – and that all starts with having the right people to deliver. We’ve created an environment where you’ll continuously grow, always have a voice and collaborate on work that’s... meaningful and fulfilling. If you’re ready to take your career into your own hands, you’ve come to the right place.

Responsibilities
• Help enable public and private cloud platforms for our clients, focusing on Microsoft Azure, Snowflake, and Databricks.
• Understand business goals and drivers and translate those into an appropriate technical solution.
• Create innovative solutions leveraging cloud platforms to solve client business challenges.
• Gather requirements, assess client capabilities/needs and analyze findings to provide appropriate cloud recommendations and adoption strategy.
• Research, analyze, recommend and select technical approaches for solving difficult and challenging development and integration problems.
• Design, build, test, and deploy highly scalable and resilient cloud-based artifacts.
• Demonstrate expertise via client workshops and whiteboard sessions.
• Create conceptual, logical and physical design for cloud-based solutions for infrastructure and platforms.
• Build big data and IoT platforms using Delta Lake, Databricks, Azure Data Factory and other cloud-based tools.
• Work with Data Scientists to integrate and operationalize AI solutions.
• Learn and adopt new tools and techniques to increase performance, automation and scalability.
• Share the leading practices with internal team members and clients.
• Collaborate using Agile and Scrum as part of larger delivery teams, working with project managers, business analysts, architects, developers, and other professionals.
• Work with many areas of our client’s technologies, including but not limited to networking, compute, storage, information security, risk, enterprise identity and access management, and security operations.
• Be customer-oriented, diligent, proactive, focused on achieving customer’s business objectives as a top priority

Skills And Experience
• Completed post-secondary education in Computer Science, Software Engineering, or a comparable combination of education and experience
• 4+ years of project experience migrating and deploying cloud-based solutions with a focus on Azure.
• Ability to write and test quality code with languages such as SQL, Python, Pyspark
• Experience with message queuing, and stream processing.
• Broad experience with batch data processing concepts and solutions.
• Deep knowledge of data modeling and SQL.
• Experience with Azure Synapse, Snowflake, other Data Warehousing suites.
• Experience with Azure Data Factory & Data Flow, Function Apps, Automation and Batch Orchestration tools
• Experience with Logic Apps & Power Apps
• Project experience implementing core infrastructure, networking and cloud-based services.
• Product knowledge and understanding of product features, including:
• IaaS, PaaS, and SaaS Solutions
• Networking
• Security
• Identity
• Virtualization
• Hybrid Cloud Solutions
• Understanding of High Availability and Disaster Recovery principles, patterns and usage.
• An understanding of cloud ecosystem and leading-edge cloud emerging technologies.
• Experience configuring and tuning cloud-hosted solutions and platforms.
• Experience supporting production applications or workloads in a cloud-based environment.
• Experience with performance analysis, troubleshooting and remediation techniques.
• Knowledge of encryption and key management principles and design patterns.
• Experience with automation and DevOps principles.
• Demonstrate growth mindset, enthusiastic about learning new technologies quickly and applying the gained knowledge to address business problems.
• Familiarity with open-source tools, Git flow and common contributing practices
• The candidate must be able to undergo a criminal record check and federal security clearance screening
• Certifications in Azure and Databricks will be considered an asset:
• Microsoft Certified: Azure Administrator Associate
• Microsoft Certified: Azure Data Engineer Associate
• Microsoft Certified: Azure Solutions Architect Expert
• Databricks Certifications for Spark application developers and other relevant certifications

MyRewards@MNP

More than a paycheque, MNP is proud to offer customized rewards for our team members. With a focus on health and wealth, we provide an extensive list of benefits that support our unique culture and foster work-life integration.

Our MyRewards@MNP program offers benefits that allow you to thrive at work and outside of the office. Be rewarded with generous paid time off including 4 personal days, firm sponsored social events, a group pension plan with 4% matching contribution, voluntary savings products, bonus program eligibility, a wellness subsidy, health and dental benefits, mental health resources, exclusive access to perks and discounts, professional development assistance, learning opportunities through MNP University, a flexible ‘Dress for Your Day’ environment and more!

Diversity@MNP

We embrace diversity as a core value and celebrate our differences. We believe each team member contributes unique gifts and amplifying their potential makes our business stronger. We encourage people with disabilities to apply","[{'items': ['What do you think of when you hear the name MNP? Most likely tax and accounting. As one of Canada’s largest consulting organizations, we’re so much more! We’re also serious about technology.\n\nMake an impact with our Digital Solutions team as a Senior Data Engineer. This diverse team of tech-savvy problem solvers has expertise and delivery depth across client platforms, applied data and analytics, applications and cloud and business platforms solutions. As a trusted advisor, you’ll gather, secure and organize meaningful insights to design digital solutions that meet clients’ evolving needs.\n\nAt MNP Digital, we’re a team of highly skilled and creative thinkers that continuously support and learn from each other. We pride ourselves on translating our clients’ challenges into real results by leveraging technology – and that all starts with having the right people to deliver. We’ve created an environment where you’ll continuously grow, always have a voice and collaborate on work that’s... meaningful and fulfilling. If you’re ready to take your career into your own hands, you’ve come to the right place.\n\nResponsibilities\n• Help enable public and private cloud platforms for our clients, focusing on Microsoft Azure, Snowflake, and Databricks.\n• Understand business goals and drivers and translate those into an appropriate technical solution.\n• Create innovative solutions leveraging cloud platforms to solve client business challenges.\n• Gather requirements, assess client capabilities/needs and analyze findings to provide appropriate cloud recommendations and adoption strategy.\n• Research, analyze, recommend and select technical approaches for solving difficult and challenging development and integration problems.\n• Design, build, test, and deploy highly scalable and resilient cloud-based artifacts.\n• Demonstrate expertise via client workshops and whiteboard sessions.\n• Create conceptual, logical and physical design for cloud-based solutions for infrastructure and platforms.\n• Build big data and IoT platforms using Delta Lake, Databricks, Azure Data Factory and other cloud-based tools.\n• Work with Data Scientists to integrate and operationalize AI solutions.\n• Learn and adopt new tools and techniques to increase performance, automation and scalability.\n• Share the leading practices with internal team members and clients.\n• Collaborate using Agile and Scrum as part of larger delivery teams, working with project managers, business analysts, architects, developers, and other professionals.\n• Work with many areas of our client’s technologies, including but not limited to networking, compute, storage, information security, risk, enterprise identity and access management, and security operations.\n• Be customer-oriented, diligent, proactive, focused on achieving customer’s business objectives as a top priority\n\nSkills And Experience\n• Completed post-secondary education in Computer Science, Software Engineering, or a comparable combination of education and experience\n• 4+ years of project experience migrating and deploying cloud-based solutions with a focus on Azure.\n• Ability to write and test quality code with languages such as SQL, Python, Pyspark\n• Experience with message queuing, and stream processing.\n• Broad experience with batch data processing concepts and solutions.\n• Deep knowledge of data modeling and SQL.\n• Experience with Azure Synapse, Snowflake, other Data Warehousing suites.\n• Experience with Azure Data Factory & Data Flow, Function Apps, Automation and Batch Orchestration tools\n• Experience with Logic Apps & Power Apps\n• Project experience implementing core infrastructure, networking and cloud-based services.\n• Product knowledge and understanding of product features, including:\n• IaaS, PaaS, and SaaS Solutions\n• Networking\n• Security\n• Identity\n• Virtualization\n• Hybrid Cloud Solutions\n• Understanding of High Availability and Disaster Recovery principles, patterns and usage.\n• An understanding of cloud ecosystem and leading-edge cloud emerging technologies.\n• Experience configuring and tuning cloud-hosted solutions and platforms.\n• Experience supporting production applications or workloads in a cloud-based environment.\n• Experience with performance analysis, troubleshooting and remediation techniques.\n• Knowledge of encryption and key management principles and design patterns.\n• Experience with automation and DevOps principles.\n• Demonstrate growth mindset, enthusiastic about learning new technologies quickly and applying the gained knowledge to address business problems.\n• Familiarity with open-source tools, Git flow and common contributing practices\n• The candidate must be able to undergo a criminal record check and federal security clearance screening\n• Certifications in Azure and Databricks will be considered an asset:\n• Microsoft Certified: Azure Administrator Associate\n• Microsoft Certified: Azure Data Engineer Associate\n• Microsoft Certified: Azure Solutions Architect Expert\n• Databricks Certifications for Spark application developers and other relevant certifications\n\nMyRewards@MNP\n\nMore than a paycheque, MNP is proud to offer customized rewards for our team members. With a focus on health and wealth, we provide an extensive list of benefits that support our unique culture and foster work-life integration.\n\nOur MyRewards@MNP program offers benefits that allow you to thrive at work and outside of the office. Be rewarded with generous paid time off including 4 personal days, firm sponsored social events, a group pension plan with 4% matching contribution, voluntary savings products, bonus program eligibility, a wellness subsidy, health and dental benefits, mental health resources, exclusive access to perks and discounts, professional development assistance, learning opportunities through MNP University, a flexible ‘Dress for Your Day’ environment and more!\n\nDiversity@MNP\n\nWe embrace diversity as a core value and celebrate our differences. We believe each team member contributes unique gifts and amplifying their potential makes our business stronger. We encourage people with disabilities to apply']}]","[{'link': 'http://www.mnp.ca/', 'text': 'mnp.ca'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=MNP&sa=X&ved=0ahUKEwjKy8vN176FAxWbIkQIHeIVBDQ4ChCYkAIIuAs', 'text': 'See web results for MNP'}]","['3 days ago', 'Full-time', 'No degree mentioned']","{'postedAt': '3 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/senior-data-engineer-digital-solutions-at-mnp-3891131290?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
Data Developer,Robinhood,Toronto,via Greenhouse,"About the team + role

Robinhood is a metrics driven company and data is foundational to all key decisions from growth strategy to product optimization to our day-to-day operations. We are looking for a Data Engineer to build and maintain foundational datasets that will allow us to reliably and efficiently power decision making at Robinhood. These datasets include application events, database snapshots, and the derived datasets that describe and track Robinhood's key metrics across all products. You’ll partner closely with engineers, data scientists and business teams to power analytics, experimentation, and machine learning use cases. We are a fast-paced team in a fast growing company and this is a unique opportunity to help lay the foundation for reliable, impactful, data-driven decisions across the company for years to come.

What you’ll do
• Help define and build key datasets across all Robinhood product areas. Lead the evolution of these datasets as use cases grow.
• Build... scalable data pipelines using Python, Spark and Airflow to move data from different applications into our data lake.
• Partner with upstream engineering teams to enhance data generation patterns.
• Partner with data consumers across Robinhood to understand consumption patterns and design intuitive data models.
• Ideate and contribute to shared data engineering tooling and standards.
• Define and promote data engineering best practices across the company.

What you bring
• 4+ years of professional experience building end-to-end data pipelines
• Proven ability to implement software engineering-caliber code (preferably Python)
• Expert at building and maintaining large-scale data pipelines using open source frameworks (Spark, Flink, etc)
• Strong SQL (Presto, Spark SQL, etc) skills.
• Experience solving problems across the data stack (Data Infrastructure, Analytics and Visualization platforms)
• Expert collaborator with the ability to democratize data through actionable insights and solutions.

Our team is here to enable an inclusive and welcoming interview experience for all candidates. If you need additional assistance throughout the interview process related to a physical or mental condition, or if there is something our team can do to enable a more accessible experience at any time, please notify our team by completing this Applicant Accommodation Form","[{'items': [""About the team + role\n\nRobinhood is a metrics driven company and data is foundational to all key decisions from growth strategy to product optimization to our day-to-day operations. We are looking for a Data Engineer to build and maintain foundational datasets that will allow us to reliably and efficiently power decision making at Robinhood. These datasets include application events, database snapshots, and the derived datasets that describe and track Robinhood's key metrics across all products. You’ll partner closely with engineers, data scientists and business teams to power analytics, experimentation, and machine learning use cases. We are a fast-paced team in a fast growing company and this is a unique opportunity to help lay the foundation for reliable, impactful, data-driven decisions across the company for years to come.\n\nWhat you’ll do\n• Help define and build key datasets across all Robinhood product areas. Lead the evolution of these datasets as use cases grow.\n• Build... scalable data pipelines using Python, Spark and Airflow to move data from different applications into our data lake.\n• Partner with upstream engineering teams to enhance data generation patterns.\n• Partner with data consumers across Robinhood to understand consumption patterns and design intuitive data models.\n• Ideate and contribute to shared data engineering tooling and standards.\n• Define and promote data engineering best practices across the company.\n\nWhat you bring\n• 4+ years of professional experience building end-to-end data pipelines\n• Proven ability to implement software engineering-caliber code (preferably Python)\n• Expert at building and maintaining large-scale data pipelines using open source frameworks (Spark, Flink, etc)\n• Strong SQL (Presto, Spark SQL, etc) skills.\n• Experience solving problems across the data stack (Data Infrastructure, Analytics and Visualization platforms)\n• Expert collaborator with the ability to democratize data through actionable insights and solutions.\n\nOur team is here to enable an inclusive and welcoming interview experience for all candidates. If you need additional assistance throughout the interview process related to a physical or mental condition, or if there is something our team can do to enable a more accessible experience at any time, please notify our team by completing this Applicant Accommodation Form""]}]","[{'link': 'http://robinhood.com/', 'text': 'robinhood.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=Robinhood&sa=X&ved=0ahUKEwjKy8vN176FAxWbIkQIHeIVBDQ4ChCYkAII9ws', 'text': 'See web results for Robinhood'}]","['Full-time', 'No degree mentioned']",{'scheduleType': 'Full-time'},"{'title': 'Apply on Greenhouse', 'link': 'https://boards.greenhouse.io/robinhood/jobs/5638913?gh_src=NaN&gh_jid=5638913&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
Cloud Data Engineer,Bank of Montreal,Toronto,via BMO Careers,"Application Deadline:

04/29/2024

Address:
33 Dundas Street West

This role is Hybrid (2 days per week in the office) and a call for talented Lead ETL developers to maintain and enhance our AWS data pipeline.

Develops scalable and accessible business cloud applications with a focus on data processing and analytics. Leads the technical design, development, enhancement, testing, debugging and maintenance of Cloud applications and supports the design of business processes in the cloud. Applies expertise and in-depth understanding of managed services environments, next-generation databases and, developer tools. Migrates existing applications to the cloud, and modifies existing applications for the cloud, or builds new cloud-native applications.​
• Creates and maintains various applications using different types of programming languages.
• Integrates data sources and identifies the kinds of problems that can arise due to incompatibility or security concerns.​
• Designs, configures and... implements the cloud-native software that solves actual business problems using cloud technology​.
• Maintains applications and infrastructure for cloud-based platforms​.
• Supports the creation of strategies to enhance the performance of existing cloud technologies.
• Develops workflows and processes following best practices and the cloud architecture​.
• Understands specific cloud resources, services, architectures and service-level agreements in order to create scalable and extensive software products.​
• Creates instructions for cloud computing operations and documentation.
• Establishes a development environment and continuous integration pipeline. Utilizes modern application patterns and code efficiency.​
• Translates user needs into technical specifications by understanding, conceptualizing, and facilitating technical requirements from users.​
• Focus is primarily on business/group within BMO; may have broader, enterprise-wide focus.
• Provides specialized consulting, analytical and technical support.
• Exercises judgment to identify, diagnose, and solve problems within given rules.
• Works independently and regularly handles non-routine situations.
• Broader work or accountabilities may be assigned as needed.

Qualifications:

Advanced level of proficiency:
• Typically between 7 years of relevant experience as AWS Cloud Application development and post-secondary degree in related field of study or an equivalent combination of education and experience.
• Deep knowledge and technical proficiency gained through extensive education and business experience.
• Cloud computing with a focus on AWS (solid experience with Serverless, Lambda, Step Functions, QuickSight, Glue, RedShift).
• Cloud solutions in regulated environments (Financial, Government or Telco).
• Software development (on-prem and Cloud) using Java, Node.js following SDLC
• Data engineering, ETL, Data warehousing, PowerBI
• Scripting languages (Python, Shell)
• Troubleshooting.
• Cloud storage.

Intermediate level of proficiency:
• I.T. automation.
• Databases (SQL, DynamoDB, RedShift)
• Configuration management.
• Elastic computing.
• SaaS.
• PaaS.
• Cloud security.
• Customer Centricity.

Grade:
7

Job Category:
Individual Contributor / Collaborateur

We’re here to help

At BMO we are driven by a shared Purpose: Boldly Grow the Good in business and life. It calls on us to create lasting, positive change for our customers, our communities and our people. By working together, innovating and pushing boundaries, we transform lives and businesses, and power economic growth around the world.

As a member of the BMO team you are valued, respected and heard, and you have more ways to grow and make an impact. We strive to help you make an impact from day one – for yourself and our customers. We’ll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. From in-depth training and coaching, to manager support and network-building opportunities, we’ll help you gain valuable experience, and broaden your skillset.

BMO is committed to an inclusive, equitable and accessible workplace. By learning from each other’s differences, we gain strength through our people and our perspectives. Accommodations are available on request for candidates taking part in all aspects of the selection process. To request accommodation, please contact your recruiter","[{'items': ['Application Deadline:\n\n04/29/2024\n\nAddress:\n33 Dundas Street West\n\nThis role is Hybrid (2 days per week in the office) and a call for talented Lead ETL developers to maintain and enhance our AWS data pipeline.\n\nDevelops scalable and accessible business cloud applications with a focus on data processing and analytics. Leads the technical design, development, enhancement, testing, debugging and maintenance of Cloud applications and supports the design of business processes in the cloud. Applies expertise and in-depth understanding of managed services environments, next-generation databases and, developer tools. Migrates existing applications to the cloud, and modifies existing applications for the cloud, or builds new cloud-native applications.\u200b\n• Creates and maintains various applications using different types of programming languages.\n• Integrates data sources and identifies the kinds of problems that can arise due to incompatibility or security concerns.\u200b\n• Designs, configures and... implements the cloud-native software that solves actual business problems using cloud technology\u200b.\n• Maintains applications and infrastructure for cloud-based platforms\u200b.\n• Supports the creation of strategies to enhance the performance of existing cloud technologies.\n• Develops workflows and processes following best practices and the cloud architecture\u200b.\n• Understands specific cloud resources, services, architectures and service-level agreements in order to create scalable and extensive software products.\u200b\n• Creates instructions for cloud computing operations and documentation.\n• Establishes a development environment and continuous integration pipeline. Utilizes modern application patterns and code efficiency.\u200b\n• Translates user needs into technical specifications by understanding, conceptualizing, and facilitating technical requirements from users.\u200b\n• Focus is primarily on business/group within BMO; may have broader, enterprise-wide focus.\n• Provides specialized consulting, analytical and technical support.\n• Exercises judgment to identify, diagnose, and solve problems within given rules.\n• Works independently and regularly handles non-routine situations.\n• Broader work or accountabilities may be assigned as needed.\n\nQualifications:\n\nAdvanced level of proficiency:\n• Typically between 7 years of relevant experience as AWS Cloud Application development and post-secondary degree in related field of study or an equivalent combination of education and experience.\n• Deep knowledge and technical proficiency gained through extensive education and business experience.\n• Cloud computing with a focus on AWS (solid experience with Serverless, Lambda, Step Functions, QuickSight, Glue, RedShift).\n• Cloud solutions in regulated environments (Financial, Government or Telco).\n• Software development (on-prem and Cloud) using Java, Node.js following SDLC\n• Data engineering, ETL, Data warehousing, PowerBI\n• Scripting languages (Python, Shell)\n• Troubleshooting.\n• Cloud storage.\n\nIntermediate level of proficiency:\n• I.T. automation.\n• Databases (SQL, DynamoDB, RedShift)\n• Configuration management.\n• Elastic computing.\n• SaaS.\n• PaaS.\n• Cloud security.\n• Customer Centricity.\n\nGrade:\n7\n\nJob Category:\nIndividual Contributor / Collaborateur\n\nWe’re here to help\n\nAt BMO we are driven by a shared Purpose: Boldly Grow the Good in business and life. It calls on us to create lasting, positive change for our customers, our communities and our people. By working together, innovating and pushing boundaries, we transform lives and businesses, and power economic growth around the world.\n\nAs a member of the BMO team you are valued, respected and heard, and you have more ways to grow and make an impact. We strive to help you make an impact from day one – for yourself and our customers. We’ll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. From in-depth training and coaching, to manager support and network-building opportunities, we’ll help you gain valuable experience, and broaden your skillset.\n\nBMO is committed to an inclusive, equitable and accessible workplace. By learning from each other’s differences, we gain strength through our people and our perspectives. Accommodations are available on request for candidates taking part in all aspects of the selection process. To request accommodation, please contact your recruiter']}]","[{'link': 'http://www.bmo.com/', 'text': 'bmo.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=Bank+of+Montreal&sa=X&ved=0ahUKEwjKy8vN176FAxWbIkQIHeIVBDQ4ChCYkAIItQw', 'text': 'See web results for Bank of Montreal'}]","['8 days ago', 'Full-time']","{'postedAt': '8 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on BMO Careers', 'link': 'https://jobs.bmo.com/ca/en/job/R240008816/Cloud-Data-Engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
GCP Data Engineer,Questrade Financial Group,Toronto,via Dayforce HCM,"We’re looking for our next GCP Data Engineer. Could It Be You?
The ideal candidate will be an experienced Google Cloud Platform Data Engineer professional that demonstrates in-depth knowledge and understanding of data warehousing, data integration and analytics. Prepared to work in an agile environment.
What’s it like working as a GCP Data Engineer at Questrade?
The Data Masters Team at Questrade is expert at building data pipelines, data warehouses and reports that are used by various teams across the organization. This is a fast paced agile environment where we have a lot of fun, enjoy a high amount of collaboration and do great work. The ideal candidate will be an experienced Data Engineer professional that demonstrates in-depth knowledge and understanding of the data engineering tech stack with experience in data warehousing, data integration and analytics.
Need more details? Keep reading…

Atleast 3-5 years of experience working in the data engineering field
Very Strong Google... Cloud Platform data engineering experience working with BigQuery, Dataflow, Airflow, Pub/Sub, Data Catalog, Cloud Composer and CloudSQL Functions
Experience in working with/on data warehouses, including technical architecture, infrastructure, ETL/ELT and reporting/analytic tools
Design, document and develop complex MS Power Platform (PowerBI, Power Apps, etc.) solutions
Work closely with our application solution architects, data scientists and data engineering teams to develop BI solutions, enhance and/or define new data integrations and/or modeling efforts
Monitor, troubleshoot and resolve issues for the deployed reporting solutions
Good Knowledge in SQL language
Good Knowledge of Python language
Develop and maintain code and documentation for ETL and other data integration projects and procedures
Collaborate with the team to decide on which tools and strategies to use within specific data integration scenarios
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment
Ability to work, communicate effectively and influence stakeholders on external engineering teams, product development teams, Business stakeholders and external partners
Experience working on multiple projects simultaneously while troubleshooting technical issues and working with cross-functional stakeholders
Creating and maintaining optimal data architecture pipelines

So are YOU our next GCP Data Engineer? You are if you…

Strong DataFlow and Pubsub knowledge
SSIS, SSRS
Knowledge of NoSQL DB
Worked in SAFe - Agile development process

Additional kudos if you…

Have experience in the financial services industry
GCP Data Engineering Certification preferred

Sounds like you? Click below to apply! #LI-DM1 #LI-Hybrid #LI-Remote","[{'items': ['We’re looking for our next GCP Data Engineer. Could It Be You?\nThe ideal candidate will be an experienced Google Cloud Platform Data Engineer professional that demonstrates in-depth knowledge and understanding of data warehousing, data integration and analytics. Prepared to work in an agile environment.\nWhat’s it like working as a GCP Data Engineer at Questrade?\nThe Data Masters Team at Questrade is expert at building data pipelines, data warehouses and reports that are used by various teams across the organization. This is a fast paced agile environment where we have a lot of fun, enjoy a high amount of collaboration and do great work. The ideal candidate will be an experienced Data Engineer professional that demonstrates in-depth knowledge and understanding of the data engineering tech stack with experience in data warehousing, data integration and analytics.\nNeed more details? Keep reading…\n\nAtleast 3-5 years of experience working in the data engineering field\nVery Strong Google... Cloud Platform data engineering experience working with BigQuery, Dataflow, Airflow, Pub/Sub, Data Catalog, Cloud Composer and CloudSQL Functions\nExperience in working with/on data warehouses, including technical architecture, infrastructure, ETL/ELT and reporting/analytic tools\nDesign, document and develop complex MS Power Platform (PowerBI, Power Apps, etc.) solutions\nWork closely with our application solution architects, data scientists and data engineering teams to develop BI solutions, enhance and/or define new data integrations and/or modeling efforts\nMonitor, troubleshoot and resolve issues for the deployed reporting solutions\nGood Knowledge in SQL language\nGood Knowledge of Python language\nDevelop and maintain code and documentation for ETL and other data integration projects and procedures\nCollaborate with the team to decide on which tools and strategies to use within specific data integration scenarios\nDemonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment\nAbility to work, communicate effectively and influence stakeholders on external engineering teams, product development teams, Business stakeholders and external partners\nExperience working on multiple projects simultaneously while troubleshooting technical issues and working with cross-functional stakeholders\nCreating and maintaining optimal data architecture pipelines\n\nSo are YOU our next GCP Data Engineer? You are if you…\n\nStrong DataFlow and Pubsub knowledge\nSSIS, SSRS\nKnowledge of NoSQL DB\nWorked in SAFe - Agile development process\n\nAdditional kudos if you…\n\nHave experience in the financial services industry\nGCP Data Engineering Certification preferred\n\nSounds like you? Click below to apply! #LI-DM1 #LI-Hybrid #LI-Remote']}]","[{'link': 'http://www.questrade.com/', 'text': 'questrade.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=Questrade+Financial+Group&sa=X&ved=0ahUKEwjKy8vN176FAxWbIkQIHeIVBDQ4ChCYkAII8gw', 'text': 'See web results for Questrade Financial Group'}]",['Full-time'],{'scheduleType': 'Full-time'},"{'title': 'Apply on Dayforce HCM', 'link': 'https://can232.dayforcehcm.com/CandidatePortal/en-US/qfg/Posting/View/7618?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
Intermediate Data Engineer,confidential,Toronto,via Apex Systems,"Intermediate Data Engineer
Apex Systems is a global IT services provider, and our staffing practice has an opening in the Online Retail space for a Data Engineer with strong experience in DBT SQL, and creating ETL pipelines from scratch to place at our client.
Start date: ASAP.
Office Location: 100% remote (within Canada)

Application Process: It is best to apply via the medium on which you are seeing this posting. If you encounter technical difficulties submitting your resume, please send a Word version of your resume to Johanna at jheffernan@apexsystems.com
Job description:

? Work closely with cross-functional partners to communicate discovered trends, resolve data issues,
troubleshooting and analysis, and bug fixes
? Work with teams across the Company on data quality and availability
? Develop new frameworks to collect data including automated data collection
? Collaborate with Data Warehouse and Engineering teams to manage relevant datasets within the Company.

Data Collection... and Strategy: Develop and implement effective data collection systems and strategies to support automation and integration projects. Ensure data accuracy, availability, integrity and reliability for various initiatives.
Cross-Functional Collaboration: Collaborate with teams across different functions to support entity and taxonomy realignments. Identify process improvement opportunities and provide regular recommendations to enhance data-related processes.
SQL Expertise: Utilize efficient SQL writing and querying techniques to troubleshoot issues directly within the Snowflake data warehouse. Optimize queries for performance and maintainability.
Data Workflows and Insights: Work with data tools including SQL and Tableau to automate data workflows. Build meaningful insights through data visualizations, standardized reports, and dashboards for ad-hoc analyses.

ABOUT YOU
? Experience in a quantitative role at a product company
? A high level of organization and attention to detail
? Familiarity with Database interface tools, SQL, and Programming concepts
? Relevant experience within the Retail space along
? Eagerness to learn, flexibility to pivot when needed, savviness to navigate and thrive in a dynamic
environment, and a growth mindset needed to build a successful team and company.
? Experience with Data mapping, Data architecture, Data integration, ETL, and working on large datasets

Requirements:

\tBachelor’s degree or equivalent work experience in a relevant business/domain.
\tHands-on experience with SQL, Data Manipulation, and Data Analysis.
\tAbility to work independently as an individual contributor, taking ownership of assigned tasks/projects. Capable of collaborating effectively in team environments, especially on large/complex projects.
\tFlexibility to adapt to changing project requirements and reprioritizations.
\tProficiency in documentation, creating and accepting handovers, and effectively managing change/release communications.
\tStrong verbal and written communication skills
\tExposure to working with large data platforms and handling sizable datasets is a plus.
\tSnowflake, Cassandra or Vertica
\tMode/Tableau
\tcomfortability working with raw/ad data and the ability to create a story out of it.

Nice to have:

\t2+ years of experience applying Python (NumPy, Pandas, Other common libraries) programming to solve business challenges.
\tScripting/development experience with Python, including working with Google APIs, building data pipelines, authentication, file handling, and raw data manipulation is a plus.

EEO EmployerApex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystems.com or 844-463-6178","[{'items': ['Intermediate Data Engineer\nApex Systems is a global IT services provider, and our staffing practice has an opening in the Online Retail space for a Data Engineer with strong experience in DBT SQL, and creating ETL pipelines from scratch to place at our client.\nStart date: ASAP.\nOffice Location: 100% remote (within Canada)\n\nApplication Process: It is best to apply via the medium on which you are seeing this posting. If you encounter technical difficulties submitting your resume, please send a Word version of your resume to Johanna at jheffernan@apexsystems.com\nJob description:\n\n? Work closely with cross-functional partners to communicate discovered trends, resolve data issues,\ntroubleshooting and analysis, and bug fixes\n? Work with teams across the Company on data quality and availability\n? Develop new frameworks to collect data including automated data collection\n? Collaborate with Data Warehouse and Engineering teams to manage relevant datasets within the Company.\n\nData Collection... and Strategy: Develop and implement effective data collection systems and strategies to support automation and integration projects. Ensure data accuracy, availability, integrity and reliability for various initiatives.\nCross-Functional Collaboration: Collaborate with teams across different functions to support entity and taxonomy realignments. Identify process improvement opportunities and provide regular recommendations to enhance data-related processes.\nSQL Expertise: Utilize efficient SQL writing and querying techniques to troubleshoot issues directly within the Snowflake data warehouse. Optimize queries for performance and maintainability.\nData Workflows and Insights: Work with data tools including SQL and Tableau to automate data workflows. Build meaningful insights through data visualizations, standardized reports, and dashboards for ad-hoc analyses.\n\nABOUT YOU\n? Experience in a quantitative role at a product company\n? A high level of organization and attention to detail\n? Familiarity with Database interface tools, SQL, and Programming concepts\n? Relevant experience within the Retail space along\n? Eagerness to learn, flexibility to pivot when needed, savviness to navigate and thrive in a dynamic\nenvironment, and a growth mindset needed to build a successful team and company.\n? Experience with Data mapping, Data architecture, Data integration, ETL, and working on large datasets\n\nRequirements:\n\n\\tBachelor’s degree or equivalent work experience in a relevant business/domain.\n\\tHands-on experience with SQL, Data Manipulation, and Data Analysis.\n\\tAbility to work independently as an individual contributor, taking ownership of assigned tasks/projects. Capable of collaborating effectively in team environments, especially on large/complex projects.\n\\tFlexibility to adapt to changing project requirements and reprioritizations.\n\\tProficiency in documentation, creating and accepting handovers, and effectively managing change/release communications.\n\\tStrong verbal and written communication skills\n\\tExposure to working with large data platforms and handling sizable datasets is a plus.\n\\tSnowflake, Cassandra or Vertica\n\\tMode/Tableau\n\\tcomfortability working with raw/ad data and the ability to create a story out of it.\n\nNice to have:\n\n\\t2+ years of experience applying Python (NumPy, Pandas, Other common libraries) programming to solve business challenges.\n\\tScripting/development experience with Python, including working with Google APIs, building data pipelines, authentication, file handling, and raw data manipulation is a plus.\n\nEEO EmployerApex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystems.com or 844-463-6178']}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=confidential&sa=X&ved=0ahUKEwjKy8vN176FAxWbIkQIHeIVBDQ4ChCYkAIIrA0', 'text': 'See web results for confidential'}]","['24 days ago', 'Contractor']","{'postedAt': '24 days ago', 'scheduleType': 'Contractor'}","{'title': 'Apply on Apex Systems', 'link': 'https://www.apexsystems.com/job/2021315_usa/intermediate-data-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
Lead Data Engineer / Web3,Crypto Recruiters,Toronto,via LinkedIn,"We are actively searching for a Lead Data Engineer to join our team on a permanent basis. This role does require onsite work as you will be leading a team that is building a data product that will give insights to investors in the crypto and Web3 industry. In this role, you will be responsible for designing and building cutting-edge data analysis systems, building interactive dashboards and visualizations, analyzing and interpreting data, and collaborating with various teams to identify and resolve data-related issues.

Responsibilities
• Design, develop and deliver data products to production, complying with internal data governance, security and scalability of our system
• Solve technical problems of the highest scope and complexity
• Exert significant influence on the company’s analytical long-range goals and data architecture
• Define and extend our internal standards for style, maintenance, and best practices for a high-scale data platform
• Develop, design, create, modify... and/or test ETL pipelines or systems to support our Machine Learning and Analytics capabilities
• Collect, clean, and analyze data from our taxonomy and developer data.
• Develop and maintain interactive dashboards and visualizations to present key metrics.
• Monitor and track key performance indicators (KPIs) and metrics related to our data labeling, taxonomy management, and analysis processes.

Requirements:
• 7+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field
• 7+ years experience using Python
• Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)
• Experience with dimensional data modeling and schema design in Data Warehouses
• Bachelor's Degree in Data Science or related Field","[{'items': [""We are actively searching for a Lead Data Engineer to join our team on a permanent basis. This role does require onsite work as you will be leading a team that is building a data product that will give insights to investors in the crypto and Web3 industry. In this role, you will be responsible for designing and building cutting-edge data analysis systems, building interactive dashboards and visualizations, analyzing and interpreting data, and collaborating with various teams to identify and resolve data-related issues.\n\nResponsibilities\n• Design, develop and deliver data products to production, complying with internal data governance, security and scalability of our system\n• Solve technical problems of the highest scope and complexity\n• Exert significant influence on the company’s analytical long-range goals and data architecture\n• Define and extend our internal standards for style, maintenance, and best practices for a high-scale data platform\n• Develop, design, create, modify... and/or test ETL pipelines or systems to support our Machine Learning and Analytics capabilities\n• Collect, clean, and analyze data from our taxonomy and developer data.\n• Develop and maintain interactive dashboards and visualizations to present key metrics.\n• Monitor and track key performance indicators (KPIs) and metrics related to our data labeling, taxonomy management, and analysis processes.\n\nRequirements:\n• 7+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field\n• 7+ years experience using Python\n• Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)\n• Experience with dimensional data modeling and schema design in Data Warehouses\n• Bachelor's Degree in Data Science or related Field""]}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=Crypto+Recruiters&sa=X&ved=0ahUKEwjKy8vN176FAxWbIkQIHeIVBDQ4ChCYkAII4Q0', 'text': 'See web results for Crypto Recruiters'}]","['2 days ago', 'Full-time']","{'postedAt': '2 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/lead-data-engineer-web3-at-crypto-recruiters-3895205627?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Engineer,2024-04-13 03:38:42.509065
Data Scientist,confidential,Toronto,via Apex Systems,"Data Scientist

\t
\t\t
\t\t\tApex Systems is a global IT services provider and our staffing practice has an opening for a Data Analyst to place at our client, a Big Five Bank
\t\t
\t

Position Title: Senior Data Scientist, Liability Modeling
LOB: Business Analytics & Insights
Est. Start Date: Early - Mid May 2024
Duration: 12 months
Possibility of extension: Yes
Possibility of FTE: Yes
Working Hours: 9am - 5pm (37.5hrs/wk)
Working Location: Downtown Toronto, hybrid1-2 days/wk in office, Team typically goes in on Mondays)

Role Mandate: The incumbent will support Senior Manager, Research and Data Science in developing liability forecasting models for different loyalty programs. They will use advanced analytical algorithms and technologies (e.g. machine learning, deep learning, artificial intelligence) to mine and analyze large data sets, to model behavioral patterns and to produce robust predictions and forecasts for financial planning and to ensure effective management and stability... of the loyalty and partner programs. This role closely collaborates with other data and analytics professionals and teams to optimize, refine and scale analysis into mature analytics solutions.

Role Responsibilities Include (but are not limited to):
• Uses data mining and extracting usable data from valuable data sources to assess feasibility of AI/ML solutions for improved processing and usage of organization data.
• Designs and implement advanced projection models focused on ultimate redemption rate estimates and overall liability estimates.
• Develops rewards program liability estimation models, including sensitivity impact models and measuring the impact of program changes or redesign.
• Develops customer behavior analyses that allow a program to target more profitable members and increase overall program effectiveness, using advanced predictive models.
• Works independently on end-to-end development of Machine Learning and time series forecasting models to derive insights
• Conducts large-scale analysis of information to discover patterns and trends by combining different modules and algorithms.
• Collaborate together with the product team and partners to understand and provide data-driven decision making
• Focus is primarily on business/group within the bank; may have broader, enterprise-wide focus.
• Provides specialized consulting, analytical and technical support.
• Exercises judgment to identify, diagnose, and solve problems within given rules.
• Works independently and regularly handles non-routine situations.
• Broader work or accountabilities may be assigned as needed.

Must-Have Skills:

Intermediate level of proficiency:
• Mathematics, statistics & operations research.
• Deep learning.
• Machine learning.
• Trust, bias and ethics.
• Creative thinking.
• Critical thinking.
• CFA, CMA, or FSA is a plus
• Knowledge of financial modeling is a plus
• Knowledge of financial data modelling vs FI product data modelling is preferred
• Actuarial background an asset
• Banking experience is ideal

Advanced level of proficiency:
• Big data.
• Data visualization.
• Computational thinking and programming.
• Data wrangling.
• Data preprocessing.
• Creative reasoning.
• Verbal & written communication skills.
• Collaboration & team skills.
• Analytical and problem-solving skills.
• Influence skills.
• Data driven decision making.
• Expert knowledge of Python and/or SAS
• 5 - 7 years of relevant experience and post-secondary degree in related field of study or an equivalent combination of education and experience.
• Deep knowledge and technical proficiency gained through extensive education and business experience.

Interview Process:
First Round - 45 Teams meeting with HM and Senior Team Member

Format will consist of behavioral and getting to know you type questions and questions to assess technical proficiency.

If your profile meets 90% of the above requirements, please apply on the medium you are seeing this posting on, in addition please send your resume in word format to karauz@apexsystems.com
EEO Employer
Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystemsinc.com or 844-463-6178.

EEO EmployerApex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystems.com or 844-463-6178","[{'items': ['Data Scientist\n\n\\t\n\\t\\t\n\\t\\t\\tApex Systems is a global IT services provider and our staffing practice has an opening for a Data Analyst to place at our client, a Big Five Bank\n\\t\\t\n\\t\n\nPosition Title: Senior Data Scientist, Liability Modeling\nLOB: Business Analytics & Insights\nEst. Start Date: Early - Mid May 2024\nDuration: 12 months\nPossibility of extension: Yes\nPossibility of FTE: Yes\nWorking Hours: 9am - 5pm (37.5hrs/wk)\nWorking Location: Downtown Toronto, hybrid1-2 days/wk in office, Team typically goes in on Mondays)\n\nRole Mandate: The incumbent will support Senior Manager, Research and Data Science in developing liability forecasting models for different loyalty programs. They will use advanced analytical algorithms and technologies (e.g. machine learning, deep learning, artificial intelligence) to mine and analyze large data sets, to model behavioral patterns and to produce robust predictions and forecasts for financial planning and to ensure effective management and stability... of the loyalty and partner programs. This role closely collaborates with other data and analytics professionals and teams to optimize, refine and scale analysis into mature analytics solutions.\n\nRole Responsibilities Include (but are not limited to):\n• Uses data mining and extracting usable data from valuable data sources to assess feasibility of AI/ML solutions for improved processing and usage of organization data.\n• Designs and implement advanced projection models focused on ultimate redemption rate estimates and overall liability estimates.\n• Develops rewards program liability estimation models, including sensitivity impact models and measuring the impact of program changes or redesign.\n• Develops customer behavior analyses that allow a program to target more profitable members and increase overall program effectiveness, using advanced predictive models.\n• Works independently on end-to-end development of Machine Learning and time series forecasting models to derive insights\n• Conducts large-scale analysis of information to discover patterns and trends by combining different modules and algorithms.\n• Collaborate together with the product team and partners to understand and provide data-driven decision making\n• Focus is primarily on business/group within the bank; may have broader, enterprise-wide focus.\n• Provides specialized consulting, analytical and technical support.\n• Exercises judgment to identify, diagnose, and solve problems within given rules.\n• Works independently and regularly handles non-routine situations.\n• Broader work or accountabilities may be assigned as needed.\n\nMust-Have Skills:\n\nIntermediate level of proficiency:\n• Mathematics, statistics & operations research.\n• Deep learning.\n• Machine learning.\n• Trust, bias and ethics.\n• Creative thinking.\n• Critical thinking.\n• CFA, CMA, or FSA is a plus\n• Knowledge of financial modeling is a plus\n• Knowledge of financial data modelling vs FI product data modelling is preferred\n• Actuarial background an asset\n• Banking experience is ideal\n\nAdvanced level of proficiency:\n• Big data.\n• Data visualization.\n• Computational thinking and programming.\n• Data wrangling.\n• Data preprocessing.\n• Creative reasoning.\n• Verbal & written communication skills.\n• Collaboration & team skills.\n• Analytical and problem-solving skills.\n• Influence skills.\n• Data driven decision making.\n• Expert knowledge of Python and/or SAS\n• 5 - 7 years of relevant experience and post-secondary degree in related field of study or an equivalent combination of education and experience.\n• Deep knowledge and technical proficiency gained through extensive education and business experience.\n\nInterview Process:\nFirst Round - 45 Teams meeting with HM and Senior Team Member\n\nFormat will consist of behavioral and getting to know you type questions and questions to assess technical proficiency.\n\nIf your profile meets 90% of the above requirements, please apply on the medium you are seeing this posting on, in addition please send your resume in word format to karauz@apexsystems.com\nEEO Employer\nApex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystemsinc.com or 844-463-6178.\n\nEEO EmployerApex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystems.com or 844-463-6178']}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=confidential&sa=X&ved=0ahUKEwirvtnb176FAxW6RjABHef6BgEQmJACCJ4I', 'text': 'See web results for confidential'}]","['2 days ago', 'Contractor']","{'postedAt': '2 days ago', 'scheduleType': 'Contractor'}","{'title': '.nFg2eb{font-weight:500}.Bi6Ddc{font-weight:500}Apply on Apex Systems', 'link': 'https://www.apexsystems.com/job/2024433_usa/data-scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Scientist,2024-04-13 03:39:10.093019
Data Scientist,AdventInfotech,Toronto,via LinkedIn,"Data Scientist:

We are seeking a highly motivated and skilled Data Scientist to join our dynamic team. The Data Scientist will play a crucial role in turning complex data into actionable insights that drive business decisions and innovation. This position involves analyzing large datasets, developing models, and delivering strategic recommendations to enhance our products and services.

Skills Requirements:
• Bachelor's or Master's degree in Data Science, Statistics, Computer Science, Mathematics, or a related field.
• 6plus years experience in data analysis, machine learning, and predictive modeling.
• Proficiency in programming languages such as Python or R.
• Strong knowledge of machine learning frameworks and libraries (e.g., TensorFlow, scikit-learn, PyTorch).
• Experience with data visualization tools (e.g., Tableau, Power BI, Matplotlib, Seaborn).
• Excellent problem-solving skills and attention to detail.
• Effective communication and presentation skills.
• Ability to work in... a collaborative team environment and independently.
• Experience with big data technologies and platforms (e.g., Hadoop, Spark, SQL, NoSQL).
• Knowledge of natural language processing (NLP) and deep learning.
• Familiarity with cloud computing platforms (e.g., AWS, Azure, Google Cloud).
• Previous industry experience in a data scientist or analytics role.

What do we expect from you?
• Masters or Bachelor in CIS/ Engineering / Science / Mathematics / Statistics/ Design …etc
• Should have hands-on years of experience in any one of the above technology
• Advance English Speaking
• Ability to work independently
• Competitive Salary

About Advent Infotech:

Advent Infotech is a multinational IT services company with offices in 7 countries, including Mexico. Our clients mainly come from the United States. Our head office is located in New Jersey, USA Our delivery centers are located in six countries: India, Indonesia, Australia, Poland, Canada, and Mexico. Advent is led by great leadership with more than twenty years in the business. Our directors are highly ethical and come with a Harvard Business School education, serial entrepreneurs, and angel investors with long-standing business ethics. Advent's motto has always been to provide profitable technology solutions for our clients while creating value for our clients","[{'items': [""Data Scientist:\n\nWe are seeking a highly motivated and skilled Data Scientist to join our dynamic team. The Data Scientist will play a crucial role in turning complex data into actionable insights that drive business decisions and innovation. This position involves analyzing large datasets, developing models, and delivering strategic recommendations to enhance our products and services.\n\nSkills Requirements:\n• Bachelor's or Master's degree in Data Science, Statistics, Computer Science, Mathematics, or a related field.\n• 6plus years experience in data analysis, machine learning, and predictive modeling.\n• Proficiency in programming languages such as Python or R.\n• Strong knowledge of machine learning frameworks and libraries (e.g., TensorFlow, scikit-learn, PyTorch).\n• Experience with data visualization tools (e.g., Tableau, Power BI, Matplotlib, Seaborn).\n• Excellent problem-solving skills and attention to detail.\n• Effective communication and presentation skills.\n• Ability to work in... a collaborative team environment and independently.\n• Experience with big data technologies and platforms (e.g., Hadoop, Spark, SQL, NoSQL).\n• Knowledge of natural language processing (NLP) and deep learning.\n• Familiarity with cloud computing platforms (e.g., AWS, Azure, Google Cloud).\n• Previous industry experience in a data scientist or analytics role.\n\nWhat do we expect from you?\n• Masters or Bachelor in CIS/ Engineering / Science / Mathematics / Statistics/ Design …etc\n• Should have hands-on years of experience in any one of the above technology\n• Advance English Speaking\n• Ability to work independently\n• Competitive Salary\n\nAbout Advent Infotech:\n\nAdvent Infotech is a multinational IT services company with offices in 7 countries, including Mexico. Our clients mainly come from the United States. Our head office is located in New Jersey, USA Our delivery centers are located in six countries: India, Indonesia, Australia, Poland, Canada, and Mexico. Advent is led by great leadership with more than twenty years in the business. Our directors are highly ethical and come with a Harvard Business School education, serial entrepreneurs, and angel investors with long-standing business ethics. Advent's motto has always been to provide profitable technology solutions for our clients while creating value for our clients""]}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=AdventInfotech&sa=X&ved=0ahUKEwirvtnb176FAxW6RjABHef6BgEQmJACCNII', 'text': 'See web results for AdventInfotech'}]","['16 hours ago', 'Full-time']","{'postedAt': '16 hours ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/data-scientist-at-adventinfotech-3896473570?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Scientist,2024-04-13 03:39:10.093019
Data Scientist,Equifax,Toronto,via Equifax Careers,"Do you have a passion for being at the forefront of Data Science innovation and building cutting edge, scalable analytical solutions? Are you a tech savvy individual looking for an exciting, dynamic role to grow your career fast with one of the largest global data analytics and technology companies? Do you want to create new products and push business forward enabling Canadians to live their financial best? If you get excited about designing & developing Machine Learning solutions blending science, art & business logic and unlocking the power of data to solve complex business problems, we would love to hear from you!

As a Data scientist within the Data & Analytics team at Equifax Canada, you will be essential to driving Data Science forward, working closely with the rest of the Canadian Equifax Data Science & Insights team. You will partner with peers, internal stakeholders and external clients to deliver the best decision science models & attributes that leverage Equifax’s vast data... assets. These include decision areas covering the credit lifecycle, geodemographic & marketing attributes, ratings & fraud models, as well as any new areas where data driven decision making can be informed by predictive modeling including advanced modeling techniques and machine learning. You will extract the data you need, create new predictive models, and lead analysis of the data and share insights with peers.

What you’ll do
• Develop new tools, advanced analytical techniques and products.
• Work with key clients, stakeholders to support development of proprietary analytical products, custom scores and effectively communicate analytical results to key stakeholders using strong data visualizations, superior presentation skills and business language to emphasize the “so what” of the analysis.
• Project management including defining business and technical requirements, resource planning and analytical solution design.
• Provide recommendations and market insights that support solving complex business problems.
• Ensure quality control of all analytical output.

What experience you need
• 2+ years of data science experience with strong knowledge of Python, SQL, R or SAS in a large data environment.
• Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks.
• Proficiency designing, building and implementing analytical solutions to solve real world problems, with limited direct supervision required.
• Proven track record of building models with the best packages including scikit learn, XGBoost, Tensorflow, PyTorch, Transformers.
• Bachelor’s or advanced degree in a quantitative discipline such as Engineering, Economics, Mathematics, Statistics, or Physics is essential.

What could set you apart
• A background in financial services, telecommunications or utilities.
• Experience working with credit or fraud data.
• Experience with development and deployment of models in a cloud based environment such as AWS or GCP is preferred.
• Master’s level degree in a business-related field/MBA","[{'items': ['Do you have a passion for being at the forefront of Data Science innovation and building cutting edge, scalable analytical solutions? Are you a tech savvy individual looking for an exciting, dynamic role to grow your career fast with one of the largest global data analytics and technology companies? Do you want to create new products and push business forward enabling Canadians to live their financial best? If you get excited about designing & developing Machine Learning solutions blending science, art & business logic and unlocking the power of data to solve complex business problems, we would love to hear from you!\n\nAs a Data scientist within the Data & Analytics team at Equifax Canada, you will be essential to driving Data Science forward, working closely with the rest of the Canadian Equifax Data Science & Insights team. You will partner with peers, internal stakeholders and external clients to deliver the best decision science models & attributes that leverage Equifax’s vast data... assets. These include decision areas covering the credit lifecycle, geodemographic & marketing attributes, ratings & fraud models, as well as any new areas where data driven decision making can be informed by predictive modeling including advanced modeling techniques and machine learning. You will extract the data you need, create new predictive models, and lead analysis of the data and share insights with peers.\n\nWhat you’ll do\n• Develop new tools, advanced analytical techniques and products.\n• Work with key clients, stakeholders to support development of proprietary analytical products, custom scores and effectively communicate analytical results to key stakeholders using strong data visualizations, superior presentation skills and business language to emphasize the “so what” of the analysis.\n• Project management including defining business and technical requirements, resource planning and analytical solution design.\n• Provide recommendations and market insights that support solving complex business problems.\n• Ensure quality control of all analytical output.\n\nWhat experience you need\n• 2+ years of data science experience with strong knowledge of Python, SQL, R or SAS in a large data environment.\n• Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks.\n• Proficiency designing, building and implementing analytical solutions to solve real world problems, with limited direct supervision required.\n• Proven track record of building models with the best packages including scikit learn, XGBoost, Tensorflow, PyTorch, Transformers.\n• Bachelor’s or advanced degree in a quantitative discipline such as Engineering, Economics, Mathematics, Statistics, or Physics is essential.\n\nWhat could set you apart\n• A background in financial services, telecommunications or utilities.\n• Experience working with credit or fraud data.\n• Experience with development and deployment of models in a cloud based environment such as AWS or GCP is preferred.\n• Master’s level degree in a business-related field/MBA']}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=Equifax&sa=X&ved=0ahUKEwirvtnb176FAxW6RjABHef6BgEQmJACCIwJ', 'text': 'See web results for Equifax'}]",['Full-time'],{'scheduleType': 'Full-time'},"{'title': 'Apply on Equifax Careers', 'link': 'https://careers.equifax.com/en/jobs/j00152353/data-scientist/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Scientist,2024-04-13 03:39:10.093019
Director of Data Science,Omnicom Media Group,Toronto,via LinkedIn,"Position:

Director, Data Science

About Omnicom Media Group Canada

As a leading global media network, with data at the core, Omnicom Media Group (OMG) creates end-to-end solutions for clients, anywhere, swiftly and efficiently. OMG considers client business needs from the start and keeps consumer behavior at the heart of everything we do. OMG is compromised of the full-service media networks OMD, PHD, XLR8 (aka Touché) and Hearts & Science; as well as Annalect (OMG’s data and analytics division) and a number of specialty media communications companies. OMG offers unparalleled clout in the marketplace and a depth of capabilities and experience that drive leadership and innovation in every media platform.

OMG Canada’s Capabilities group brings together a team of experts in marketing and advertising technology, digital platforms and marketplaces, data solutions and marketing science, and content and influencer marketing, to support the four brand agencies of OMG Canada. This team of... specialist supports new business growth, product development and digital operational excellence including programmatic media buying for all digital channels, audience segmentation and measurement, and media insights derived from rigorous statistical analysis.

Position and Responsibilities

This role is responsible for leading data science team talent and unified measurement solutions, including media mix modeling (MMM). You will lead client engagements for Unified Measurement (Agile MMM + MTA), Agile MMM and traditional MMM, and data-driven attribution solutions in Walled Gardens data clean rooms (Google Ads Data Hub (ADH), Amazon Marketing Cloud (AMC)).

As a member of OMG Capabilities group, you’ll work with agency partners and strategists to create data-driven solutions that shape the strategic direction of your client’s marketing investment. You will also collaborate with other data scientists, globally, to build custom models to optimize media investment and performance.

Core Responsibilities
• Develop, manage & implement econometric models (such as Agile MMM) for all OMG clients in Canada
• Optimize existing MMM solutions into holistic, future-proof unified measurement & Agile MMM solutions: integrate real-time data signals and cross-validate with data-driven attribution models and formal incrementality tests
• Advise on optimal media investment plans (quarterly or monthly refreshes)
• Proactively recommend MMM and other data-driven measurement solutions to clients and internal OMG teams (based upon business requirements)

Adjacent Responsibilities
• Evaluate and customize open-source MMM models from Google, Amazon, Meta based upon business requirements and client suitability (able to score/rank advertisers by model suitability and business ROI)
• Serve as subject matter expert for data modeling solutions
• Deliver projects employing marketing analytics and data science approaches to help clients better understand their customers and to inform media strategies that improve engagement and business ROI
• Lead the agency marketing science teams in the data sourcing and development of key data science capabilities

You must be able to work independently and as part of the OMG Capabilities team to coordinate efforts, collaborate, and build strong relationships with internal stakeholders and clients.

Key Skills and Experience
• Bachelor's degree in Statistics, Computer Science, Engineering, or Mathematics, related quantitative discipline, or equivalent practical experience
• 5+ years’ experience in delivering end-to-end analytics projects
• 3+ years’ experience in developing and executing media performance measurement strategies, inclusive of brand and performance/demand marketing
• Hands-on expertise in Python/R, especially with data preparation, transformation, modeling packages and machine learning algorithms; SQL proficiency preferred
• Strong familiarity with the adtech and martech landscape, programmatic advertising, tagging/tracking methodologies and outputs from Google Marketing Platform (GMP), Amazon Ads, The Trade Desk DSP and Facebook Business Manager
• Experience conducting analyses in Google Ads Data Hub (ADH) and/or Amazon Marketing Cloud (AMC) data clean rooms
• Experience in collaboratively ideating and building modeling solutions that aid with model transparency, visualization of optimization effects and performance measurement
• Aware of Meta Robyn and/or Google Meridian open source MMM models (strengths, limitations, selection criteria)
• Familiar with digital identifiers (e.g. LiveRamp, Experian/Tapad, Lotame, The Trade Desk) and with identity resolution
• Strong business communication skills. Ability to communicate the implications and recommendations of complex analyses in clean, concise, language for mid- to senior-level client management
• Skilled at presenting and defending findings to client-side data science teams
• Comfortable interacting with client and programmatic teams (agency and external) to plan & execute optimization strategies - based on model outputs - as well as testing & measurement plans and media performance
• Proactive in documenting and sharing knowledge via OMG repositories and with global colleagues

This position reports directly to the Senior Director, Head of Data Science on the Capabilities team. The successful candidate will have the opportunity to collaborate across the Capabilities team, with colleagues in investment, platforms and activation, ad operations, data science, engineering and commerce. Please email careers.canada@omnicommediagroup.com

COMMITMENT TO IDEA

OMG is dedicated to cultivating a workplace that not only respects but actively champions Inclusion, Diversity and Equity through Action (IDEA). This commitment ensures that our workforce composition intentionally reflects the rich cultural mosaic of Canada with representation from various dimensions of diversity. It also drives how our team members, leadership, client services, employment practices, and relationships with all stakeholders are shaped.

OMG Canada s'engage à offrir un environnement de travail qui non seulement respecte, mais promeut activement l'inclusion, la diversité et l'équité par l'action (IDÉA). Cet engagement a pour objectif que la composition de notre main-d'œuvre reflète la diversité avec une représentation des groupes sous-représentés. Il détermine également la façon dont les membres de notre équipe, notre leadership, notre service à la clientèle, nos pratiques de travail et nos relations avec tou.te.s les intervenant.e.s sont façonnées","[{'items': [""Position:\n\nDirector, Data Science\n\nAbout Omnicom Media Group Canada\n\nAs a leading global media network, with data at the core, Omnicom Media Group (OMG) creates end-to-end solutions for clients, anywhere, swiftly and efficiently. OMG considers client business needs from the start and keeps consumer behavior at the heart of everything we do. OMG is compromised of the full-service media networks OMD, PHD, XLR8 (aka Touché) and Hearts & Science; as well as Annalect (OMG’s data and analytics division) and a number of specialty media communications companies. OMG offers unparalleled clout in the marketplace and a depth of capabilities and experience that drive leadership and innovation in every media platform.\n\nOMG Canada’s Capabilities group brings together a team of experts in marketing and advertising technology, digital platforms and marketplaces, data solutions and marketing science, and content and influencer marketing, to support the four brand agencies of OMG Canada. This team of... specialist supports new business growth, product development and digital operational excellence including programmatic media buying for all digital channels, audience segmentation and measurement, and media insights derived from rigorous statistical analysis.\n\nPosition and Responsibilities\n\nThis role is responsible for leading data science team talent and unified measurement solutions, including media mix modeling (MMM). You will lead client engagements for Unified Measurement (Agile MMM + MTA), Agile MMM and traditional MMM, and data-driven attribution solutions in Walled Gardens data clean rooms (Google Ads Data Hub (ADH), Amazon Marketing Cloud (AMC)).\n\nAs a member of OMG Capabilities group, you’ll work with agency partners and strategists to create data-driven solutions that shape the strategic direction of your client’s marketing investment. You will also collaborate with other data scientists, globally, to build custom models to optimize media investment and performance.\n\nCore Responsibilities\n• Develop, manage & implement econometric models (such as Agile MMM) for all OMG clients in Canada\n• Optimize existing MMM solutions into holistic, future-proof unified measurement & Agile MMM solutions: integrate real-time data signals and cross-validate with data-driven attribution models and formal incrementality tests\n• Advise on optimal media investment plans (quarterly or monthly refreshes)\n• Proactively recommend MMM and other data-driven measurement solutions to clients and internal OMG teams (based upon business requirements)\n\nAdjacent Responsibilities\n• Evaluate and customize open-source MMM models from Google, Amazon, Meta based upon business requirements and client suitability (able to score/rank advertisers by model suitability and business ROI)\n• Serve as subject matter expert for data modeling solutions\n• Deliver projects employing marketing analytics and data science approaches to help clients better understand their customers and to inform media strategies that improve engagement and business ROI\n• Lead the agency marketing science teams in the data sourcing and development of key data science capabilities\n\nYou must be able to work independently and as part of the OMG Capabilities team to coordinate efforts, collaborate, and build strong relationships with internal stakeholders and clients.\n\nKey Skills and Experience\n• Bachelor's degree in Statistics, Computer Science, Engineering, or Mathematics, related quantitative discipline, or equivalent practical experience\n• 5+ years’ experience in delivering end-to-end analytics projects\n• 3+ years’ experience in developing and executing media performance measurement strategies, inclusive of brand and performance/demand marketing\n• Hands-on expertise in Python/R, especially with data preparation, transformation, modeling packages and machine learning algorithms; SQL proficiency preferred\n• Strong familiarity with the adtech and martech landscape, programmatic advertising, tagging/tracking methodologies and outputs from Google Marketing Platform (GMP), Amazon Ads, The Trade Desk DSP and Facebook Business Manager\n• Experience conducting analyses in Google Ads Data Hub (ADH) and/or Amazon Marketing Cloud (AMC) data clean rooms\n• Experience in collaboratively ideating and building modeling solutions that aid with model transparency, visualization of optimization effects and performance measurement\n• Aware of Meta Robyn and/or Google Meridian open source MMM models (strengths, limitations, selection criteria)\n• Familiar with digital identifiers (e.g. LiveRamp, Experian/Tapad, Lotame, The Trade Desk) and with identity resolution\n• Strong business communication skills. Ability to communicate the implications and recommendations of complex analyses in clean, concise, language for mid- to senior-level client management\n• Skilled at presenting and defending findings to client-side data science teams\n• Comfortable interacting with client and programmatic teams (agency and external) to plan & execute optimization strategies - based on model outputs - as well as testing & measurement plans and media performance\n• Proactive in documenting and sharing knowledge via OMG repositories and with global colleagues\n\nThis position reports directly to the Senior Director, Head of Data Science on the Capabilities team. The successful candidate will have the opportunity to collaborate across the Capabilities team, with colleagues in investment, platforms and activation, ad operations, data science, engineering and commerce. Please email careers.canada@omnicommediagroup.com\n\nCOMMITMENT TO IDEA\n\nOMG is dedicated to cultivating a workplace that not only respects but actively champions Inclusion, Diversity and Equity through Action (IDEA). This commitment ensures that our workforce composition intentionally reflects the rich cultural mosaic of Canada with representation from various dimensions of diversity. It also drives how our team members, leadership, client services, employment practices, and relationships with all stakeholders are shaped.\n\nOMG Canada s'engage à offrir un environnement de travail qui non seulement respecte, mais promeut activement l'inclusion, la diversité et l'équité par l'action (IDÉA). Cet engagement a pour objectif que la composition de notre main-d'œuvre reflète la diversité avec une représentation des groupes sous-représentés. Il détermine également la façon dont les membres de notre équipe, notre leadership, notre service à la clientèle, nos pratiques de travail et nos relations avec tou.te.s les intervenant.e.s sont façonnées""]}]","[{'link': 'http://www.omnicommediagroup.com/', 'text': 'omnicommediagroup.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=Omnicom+Media+Group&sa=X&ved=0ahUKEwirvtnb176FAxW6RjABHef6BgEQmJACCMEJ', 'text': 'See web results for Omnicom Media Group'}]","['15 hours ago', 'Full-time']","{'postedAt': '15 hours ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/director-of-data-science-at-omnicom-media-group-3892387869?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Scientist,2024-04-13 03:39:10.093019
Analytics Engineer (Data Scientist),Definity Careers,Toronto,via Definity Careers,"The Analytics Engineer spearheads the development and delivery of innovative analytical solutions in collaboration with business stakeholders and technical teams across the organization.

The Analytics Engineer reports to the Director, Data Leadership as a key member of a high-performing Data and Analytics team focused on delivering impactful insights and ground-breaking solutions for digital transformation in Personal Insurance at Definity.

The Analytics Engineer is a highly technical yet well-rounded analytics professional with hands-on expertise in all facets of analytics engineering and a passion for turning innovative data science ideas into game-changing business applications. To thrive in this role, the Analytics Engineer will need to have expert-level skills in data wrangling using both SQL and Python, extensive experience with prototyping and optimizing scalable data science and ML/AI solutions on cloud platforms. In addition, a strong understanding of statistics and... exploratory data analysis are essential. Experience with modern insurance processes, data visualization best practices, and geospatial analytics are also strong assets in this role.

The Analytics Engineer leverages strong agile project management skills to drive results and lead analytics projects, guides and coaches team members, and demonstrates effective communication skills to influence strategic decisions.

What you’ll do:
• Spearhead the design and rapid prototyping of analytical solutions in close collaboration with business stakeholders and analytics leadership.
• Lead the development of analytical solutions, providing direction, coaching, and review support to more junior team members.
• Perform exploratory analysis and evaluation of new data sources to support planning and data strategy.
• Independently prepare and present proposals and updates to senior level audiences
• Propose new and improve existing approaches to perform analytics, and support leadership in promoting their uptake.
• Research cutting-edge analytical techniques and tools, and share insights with team members.

What do you bring to the role?
• A university degree in data science, statistics, computer science, operations research, or a related discipline. Preference to individuals with a Master's/Doctoral degree and/or significant technical expertise gained through analytics self-study.
• Expertise in most major areas of data science/analytics. These areas include data wrangling, data visualization, predictive modelling, statistics, machine learning, big data analytics, geospatial analytics, and optimization.
• A proven track record of developing integrated, creative analytical solutions in a business context.
• Extensive experience with at least one modern analytical programming language - such as R, Python, or Scala - with preference to candidates with expertise in multiple analytical languages.
• Experience with Google Cloud Platform
• Experience in Data engineering experience (SQL), ETL pipeline development and maintenance, Data analysis and visualization skills
• Excellent project management, communication, and problem-solving skills.
• Experience guiding and coaching more junior staff members","[{'items': [""The Analytics Engineer spearheads the development and delivery of innovative analytical solutions in collaboration with business stakeholders and technical teams across the organization.\n\nThe Analytics Engineer reports to the Director, Data Leadership as a key member of a high-performing Data and Analytics team focused on delivering impactful insights and ground-breaking solutions for digital transformation in Personal Insurance at Definity.\n\nThe Analytics Engineer is a highly technical yet well-rounded analytics professional with hands-on expertise in all facets of analytics engineering and a passion for turning innovative data science ideas into game-changing business applications. To thrive in this role, the Analytics Engineer will need to have expert-level skills in data wrangling using both SQL and Python, extensive experience with prototyping and optimizing scalable data science and ML/AI solutions on cloud platforms. In addition, a strong understanding of statistics and... exploratory data analysis are essential. Experience with modern insurance processes, data visualization best practices, and geospatial analytics are also strong assets in this role.\n\nThe Analytics Engineer leverages strong agile project management skills to drive results and lead analytics projects, guides and coaches team members, and demonstrates effective communication skills to influence strategic decisions.\n\nWhat you’ll do:\n• Spearhead the design and rapid prototyping of analytical solutions in close collaboration with business stakeholders and analytics leadership.\n• Lead the development of analytical solutions, providing direction, coaching, and review support to more junior team members.\n• Perform exploratory analysis and evaluation of new data sources to support planning and data strategy.\n• Independently prepare and present proposals and updates to senior level audiences\n• Propose new and improve existing approaches to perform analytics, and support leadership in promoting their uptake.\n• Research cutting-edge analytical techniques and tools, and share insights with team members.\n\nWhat do you bring to the role?\n• A university degree in data science, statistics, computer science, operations research, or a related discipline. Preference to individuals with a Master's/Doctoral degree and/or significant technical expertise gained through analytics self-study.\n• Expertise in most major areas of data science/analytics. These areas include data wrangling, data visualization, predictive modelling, statistics, machine learning, big data analytics, geospatial analytics, and optimization.\n• A proven track record of developing integrated, creative analytical solutions in a business context.\n• Extensive experience with at least one modern analytical programming language - such as R, Python, or Scala - with preference to candidates with expertise in multiple analytical languages.\n• Experience with Google Cloud Platform\n• Experience in Data engineering experience (SQL), ETL pipeline development and maintenance, Data analysis and visualization skills\n• Excellent project management, communication, and problem-solving skills.\n• Experience guiding and coaching more junior staff members""]}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=Definity+Careers&sa=X&ved=0ahUKEwirvtnb176FAxW6RjABHef6BgEQmJACCP0J', 'text': 'See web results for Definity Careers'}]","['4 days ago', 'CA$77.7K–CA$157K a year', 'Full-time']","{'postedAt': '4 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on Definity Careers', 'link': 'https://careers.definityfinancial.com/jobs/14225786-analytics-engineer-data-scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Scientist,2024-04-13 03:39:10.093019
Senior Data Scientist,EY,Toronto,via EY Careers,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.

EY delivers exceptional services to our clients in the data and analytics domain. We are helping our clients solve their most critical business problems. Our service offerings help our clients apply advanced analytics techniques to drive competitive advantage, use advanced learning algorithms to solve complex business problems, realize the full potential of data through vast amount of disparate data sets available to them, generating insights by capturing data from machines and devise in near real-time.

The opportunity

We are seeking a highly skilled and driven data science specialist to join our team. The ideal candidate will have... a strong understanding of machine learning methodologies and extensive experience using related Python libraries and frameworks, as well as graph theory.

Your key responsibilities

You’ll spend most of your time working with a wide variety of clients to deliver the latest data science, data analytics, and big data technologies and practices to design, build and maintain scalable and robust solutions that unify, enrich and analyse data from multiple sources.

To qualify for the role you must have
• Comprehensive understanding of machine learning methods including supervised, unsupervised, and reinforcement learning.
• Proficient in Natural Language Processing (NLP), Long Short-Term Memory networks (LSTM), Convolutional Neural Networks (CNN).
• Openness to integrating new research findings into the workstream, including reading and comprehending scientific articles and implementing these research findings into practice.
• Extensive programming experience with Python and familiarity with machine learning packages and libraries such as TensorFlow and PyTorch.
• Deep understanding of Language Models, particularly Large Language Models (LLMs).
• Knowledge of Graph theory and its applications in data science.
• Familiarity with cloud technologies, along with experience in working with both cloud and on-premise databases. Experience with SQL, Snowflake, Oracle, etc. is especially desirable.
• A master's degree (Ph.D. preferred) in Computer Science, Statistics, Data Science, or a related field.
• Excellent problem-solving abilities and an aptitude for critical thinking.
• Strong communication skills to effectively collaborate with the team and present insights to stakeholders.
• Developing machine learning models for complex problems.
• Incorporating up-to-date research findings from relevant scientific articles.
• Regularly working with various programming languages, mainly Python.
• Collaborating with team members and stakeholders to improve existing solutions and develop new approaches.

What we look for

We are looking for a self-motivated individual with a strong desire to keep learning and staying abreast of the latest developments in the field of data science. If you have a knack for problem-solving and a passion for pushing the boundaries of data science, we would love to hear from you.

What we offers

At EY, our Total Rewards package supports our commitment to creating a leading people culture - built on high-performance teaming - where everyone can achieve their potential and contribute to building a better working world for our people, our clients and our communities. It's one of the many reasons we repeatedly win awards for being a great place to work.

We offer a competitive compensation package where you’ll be rewarded based on your performance and recognized for the value you bring to our business. In addition, our Total Rewards package allows you to decide which benefits are right for you and which ones help you create a solid foundation for your future. Our Total Rewards package includes a comprehensive medical, prescription drug and dental coverage, a defined contribution pension plan, a great vacation policy plus firm paid days that allow you to enjoy longer long weekends throughout the year, statutory holidays and paid personal days (based on province of residence), and a range of exciting programs and benefits designed to support your physical, financial and social well-being. Plus, we offer:
• Support and coaching from some of the most engaging colleagues in the industry
• Learning opportunities to develop new skills and progress your career
• The freedom and flexibility to handle your role in a way that’s right for you

About EY

As a global leader in assurance, tax, transaction and advisory services, we’re using the finance products, expertise and systems we’ve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime.

Diversity and Inclusion at EY

Diversity and inclusiveness are at the heart of who we are and how we work. We’re committed to fostering an environment where differences are valued, policies and practices are equitable, and our people feel a sense of belonging. We embrace diversity and are committed to combating systemic racism, advocating for the 2SLGBT+ community, promoting our Neurodiversity Centre of Excellence and Accessibility initiatives, and are dedicated to amplifying the voices of Indigenous people (First Nations, Inuit, and Métis) nationally as we strive towards reconciliation. Our diverse experiences, abilities, backgrounds, and perspectives make our people unique and help guide us. Because when people feel free to be their authentic selves at work, they bring their best and are empowered to build a better working world.

EY | Building a better working world

EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.

Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.

Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today","[{'items': [""At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\n\nEY delivers exceptional services to our clients in the data and analytics domain. We are helping our clients solve their most critical business problems. Our service offerings help our clients apply advanced analytics techniques to drive competitive advantage, use advanced learning algorithms to solve complex business problems, realize the full potential of data through vast amount of disparate data sets available to them, generating insights by capturing data from machines and devise in near real-time.\n\nThe opportunity\n\nWe are seeking a highly skilled and driven data science specialist to join our team. The ideal candidate will have... a strong understanding of machine learning methodologies and extensive experience using related Python libraries and frameworks, as well as graph theory.\n\nYour key responsibilities\n\nYou’ll spend most of your time working with a wide variety of clients to deliver the latest data science, data analytics, and big data technologies and practices to design, build and maintain scalable and robust solutions that unify, enrich and analyse data from multiple sources.\n\nTo qualify for the role you must have\n• Comprehensive understanding of machine learning methods including supervised, unsupervised, and reinforcement learning.\n• Proficient in Natural Language Processing (NLP), Long Short-Term Memory networks (LSTM), Convolutional Neural Networks (CNN).\n• Openness to integrating new research findings into the workstream, including reading and comprehending scientific articles and implementing these research findings into practice.\n• Extensive programming experience with Python and familiarity with machine learning packages and libraries such as TensorFlow and PyTorch.\n• Deep understanding of Language Models, particularly Large Language Models (LLMs).\n• Knowledge of Graph theory and its applications in data science.\n• Familiarity with cloud technologies, along with experience in working with both cloud and on-premise databases. Experience with SQL, Snowflake, Oracle, etc. is especially desirable.\n• A master's degree (Ph.D. preferred) in Computer Science, Statistics, Data Science, or a related field.\n• Excellent problem-solving abilities and an aptitude for critical thinking.\n• Strong communication skills to effectively collaborate with the team and present insights to stakeholders.\n• Developing machine learning models for complex problems.\n• Incorporating up-to-date research findings from relevant scientific articles.\n• Regularly working with various programming languages, mainly Python.\n• Collaborating with team members and stakeholders to improve existing solutions and develop new approaches.\n\nWhat we look for\n\nWe are looking for a self-motivated individual with a strong desire to keep learning and staying abreast of the latest developments in the field of data science. If you have a knack for problem-solving and a passion for pushing the boundaries of data science, we would love to hear from you.\n\nWhat we offers\n\nAt EY, our Total Rewards package supports our commitment to creating a leading people culture - built on high-performance teaming - where everyone can achieve their potential and contribute to building a better working world for our people, our clients and our communities. It's one of the many reasons we repeatedly win awards for being a great place to work.\n\nWe offer a competitive compensation package where you’ll be rewarded based on your performance and recognized for the value you bring to our business. In addition, our Total Rewards package allows you to decide which benefits are right for you and which ones help you create a solid foundation for your future. Our Total Rewards package includes a comprehensive medical, prescription drug and dental coverage, a defined contribution pension plan, a great vacation policy plus firm paid days that allow you to enjoy longer long weekends throughout the year, statutory holidays and paid personal days (based on province of residence), and a range of exciting programs and benefits designed to support your physical, financial and social well-being. Plus, we offer:\n• Support and coaching from some of the most engaging colleagues in the industry\n• Learning opportunities to develop new skills and progress your career\n• The freedom and flexibility to handle your role in a way that’s right for you\n\nAbout EY\n\nAs a global leader in assurance, tax, transaction and advisory services, we’re using the finance products, expertise and systems we’ve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime.\n\nDiversity and Inclusion at EY\n\nDiversity and inclusiveness are at the heart of who we are and how we work. We’re committed to fostering an environment where differences are valued, policies and practices are equitable, and our people feel a sense of belonging. We embrace diversity and are committed to combating systemic racism, advocating for the 2SLGBT+ community, promoting our Neurodiversity Centre of Excellence and Accessibility initiatives, and are dedicated to amplifying the voices of Indigenous people (First Nations, Inuit, and Métis) nationally as we strive towards reconciliation. Our diverse experiences, abilities, backgrounds, and perspectives make our people unique and help guide us. Because when people feel free to be their authentic selves at work, they bring their best and are empowered to build a better working world.\n\nEY | Building a better working world\n\nEY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.\n\nEnabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.\n\nWorking across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today""]}]","[{'link': 'http://www.ey.com/', 'text': 'ey.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=EY&sa=X&ved=0ahUKEwirvtnb176FAxW6RjABHef6BgEQmJACCLsK', 'text': 'See web results for EY'}]","['11 days ago', 'Full-time']","{'postedAt': '11 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on EY Careers', 'link': 'https://careers.ey.com/ey/job/Toronto-Senior-Data-Scientist-ON-M5H-0B3/1044678601/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Scientist,2024-04-13 03:39:10.093019
"Senior Data Scientist, Scotiabank",Scotiabank,Toronto,via Scotiabank Jobs,"Requisition ID: 194791

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

The Senior Data Scientist will design and implement machine learning models, algorithms and applications that solve complex problems in the context of global operations and compliance technology.

Is this role right for you? In this role you will:
• Conduct data analysis, data cleansing, feature engineering, and exploratory data analysis to identify trends, insights, and patterns in large datasets.
• Lead research and identify new technologies, techniques and methodologies that can be applied to the development of machine learning solutions.
• Develop and maintain a deep understanding of the bank's internal operations, businesses, and processes, as well as industry best practices and emerging technologies in machine learning and lead the team in delivery.
• Collaborate with stakeholders to understand business needs and translate them into machine learning... solutions that deliver measurable value.
• Collaborate with other engineering teams and cross-functional teams to deliver proof of concepts that showcase the potential of machine learning to drive innovation and improve our internal operations and businesses.
• Communicate complex technical concepts and results to both technical and non-technical stakeholders, including senior management, business partners, and regulators.
• Stay current with the latest machine learning research and techniques, and with industry developments in machine learning and evaluate their potential impact on the organization.
• Help the team in adapting the latest AI technology and services including IBM WatsonX, Google Vertex AI, Azure OpenAI and AI Builder to support bank’s employees and improve processes.
• Foster a culture of innovation and continuous learning within the team and contribute to the development of new data science initiatives and strategies.

Do you have the skills that will enable you to succeed in this role? We'd love to work with you if you have:
• The role requires a person who is very skilled in developing AI/ML models including GEN AI (LLM), Natural Language Processing and Natural Language Understanding, Convolutional Neural Networks, Feedforward Neural Networks, and Reinforcement Learning which is critical for development of ML modules in Innovation team.
• is necessary for building the whole pipeline of AI products built in the team.
• The data analysis and data visualization skill-set is required for the team in different stages of developing a product including Exploratory Data Analysis at the beginning, Error Analysis during the product development, and Data Visualization for training of ML models as well as Monitoring of the product after deployment.
• Experience working with latest AI technology/services including multiple open-source models, Google Vertex AI, IBM WatsonX and Azure Open AI.

What's in it for you?
• Diversity, Equity, Inclusion & Allyship - We strive to create an inclusive culture where every employee is empowered to reach their fullest potential, respected for who they are, and are embraced through bias-free practices and inclusive values across Scotiabank. We embrace diversity and provide opportunities for all employee to learn, grow & participate through our various Employee Resource Groups (ERGs) that span across diverse gender identities, ethnicity, race, age, ability & veterans.
• Accessibility and Workplace Accommodations - We value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. Scotiabank continues to locate, remove and prevent barriers so that we can build a diverse and inclusive environment while meeting accessibility requirements.
• Upskilling through online courses, cross-functional development opportunities, and tuition assistance.
• Competitive Rewards program including bonus, flexible vacation, personal, sick days and benefits will start on day one.
• Community Engagement - no matter where you choose to work from; we offer opportunities for community engagement & belonging with our various programs such as hackathons, contests, cooking with friends, Humans of Digital and much more!

Working location condition: Hybrid

#LI-Hybrid

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted","[{'items': ['Requisition ID: 194791\n\nJoin a purpose driven winning team, committed to results, in an inclusive and high-performing culture.\n\nThe Senior Data Scientist will design and implement machine learning models, algorithms and applications that solve complex problems in the context of global operations and compliance technology.\n\nIs this role right for you? In this role you will:\n• Conduct data analysis, data cleansing, feature engineering, and exploratory data analysis to identify trends, insights, and patterns in large datasets.\n• Lead research and identify new technologies, techniques and methodologies that can be applied to the development of machine learning solutions.\n• Develop and maintain a deep understanding of the bank\'s internal operations, businesses, and processes, as well as industry best practices and emerging technologies in machine learning and lead the team in delivery.\n• Collaborate with stakeholders to understand business needs and translate them into machine learning... solutions that deliver measurable value.\n• Collaborate with other engineering teams and cross-functional teams to deliver proof of concepts that showcase the potential of machine learning to drive innovation and improve our internal operations and businesses.\n• Communicate complex technical concepts and results to both technical and non-technical stakeholders, including senior management, business partners, and regulators.\n• Stay current with the latest machine learning research and techniques, and with industry developments in machine learning and evaluate their potential impact on the organization.\n• Help the team in adapting the latest AI technology and services including IBM WatsonX, Google Vertex AI, Azure OpenAI and AI Builder to support bank’s employees and improve processes.\n• Foster a culture of innovation and continuous learning within the team and contribute to the development of new data science initiatives and strategies.\n\nDo you have the skills that will enable you to succeed in this role? We\'d love to work with you if you have:\n• The role requires a person who is very skilled in developing AI/ML models including GEN AI (LLM), Natural Language Processing and Natural Language Understanding, Convolutional Neural Networks, Feedforward Neural Networks, and Reinforcement Learning which is critical for development of ML modules in Innovation team.\n• is necessary for building the whole pipeline of AI products built in the team.\n• The data analysis and data visualization skill-set is required for the team in different stages of developing a product including Exploratory Data Analysis at the beginning, Error Analysis during the product development, and Data Visualization for training of ML models as well as Monitoring of the product after deployment.\n• Experience working with latest AI technology/services including multiple open-source models, Google Vertex AI, IBM WatsonX and Azure Open AI.\n\nWhat\'s in it for you?\n• Diversity, Equity, Inclusion & Allyship - We strive to create an inclusive culture where every employee is empowered to reach their fullest potential, respected for who they are, and are embraced through bias-free practices and inclusive values across Scotiabank. We embrace diversity and provide opportunities for all employee to learn, grow & participate through our various Employee Resource Groups (ERGs) that span across diverse gender identities, ethnicity, race, age, ability & veterans.\n• Accessibility and Workplace Accommodations - We value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. Scotiabank continues to locate, remove and prevent barriers so that we can build a diverse and inclusive environment while meeting accessibility requirements.\n• Upskilling through online courses, cross-functional development opportunities, and tuition assistance.\n• Competitive Rewards program including bonus, flexible vacation, personal, sick days and benefits will start on day one.\n• Community Engagement - no matter where you choose to work from; we offer opportunities for community engagement & belonging with our various programs such as hackathons, contests, cooking with friends, Humans of Digital and much more!\n\nWorking location condition: Hybrid\n\n#LI-Hybrid\n\nLocation(s): Canada : Ontario : Toronto\n\nScotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.\n\nAt Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted']}]","[{'link': 'http://www.scotiabank.com/', 'text': 'scotiabank.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=Scotiabank&sa=X&ved=0ahUKEwirvtnb176FAxW6RjABHef6BgEQmJACCPgK', 'text': 'See web results for Scotiabank'}]","['10 days ago', 'Full-time']","{'postedAt': '10 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on Scotiabank Jobs', 'link': 'https://jobs.scotiabank.com/Scotiabank%20(default)/job/Toronto-Senior-Data-Scientist%2C-Scotiabank-ON-M5H1H1/578883617/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Scientist,2024-04-13 03:39:10.093019
Data Scientist,Verisk,Toronto,via Smart Recruiters Jobs,"Company Description

We help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable.

Job Description

As the nation’s largest data aggregator, and a market leader in analytics solutions for the insurance and financial industry, Opta Information Intelligence is looking to bolster its growing data science team. By building and delivering complex machine learning-based products, you’ll have an opportunity to positively impact the decision-making of our many clients and partners.

As a Data Scientist you will be responsible for researching and developing data science and machine learning solutions related to the improving our product range.  You will collate with our team of data scientists, data engineers, and other departments to develop and deploy machine Learning & data science products that integrate seamlessly with our... production systems for both batch and real-time processes.  The ideal candidate will bring with them established best practices and an expertise in machine learning model development and deployment, statistical analysis and problem-solving skills. If you are a dedicated individual who thrives in a dynamic and results-driven environment, then this is the position for you!

Responsibilities:
• Conduct research into latest developments and provide business with solutions to the range of data science problems
• Develop end-to-end machine learning, from research and development to deployment into our production system
• Liase with Product and IT teams to push through new products
• Work with our machine learning engineers to ensure smooth deployment of models into production
• Sets the vision for the use of new and innovative tools and technology.
• Employ coding and documentation best practices
• Maintains and fosters an industry awareness of new developments in machine learning techniques and tools, and ensures quick execution in their use within the department

Qualifications
• Bachelors or Masters Degree in Quantitative Analytics, Statistics, Mathematics, similar discipline
• 3+ years of experience developing and deploying machine learning models
• 3+ years of Statistical Analysis and Modeling
• Experience running and owning Data Science projects with minimal help from senior staff
• Experience working with AWS services including: S3, Lambda, EC2, Step Functions, Redshift, SageMaker
• Expert level knowledge of Python
• Strong background in deep learning frameworks such as TensorFlow or PyTorch
• Experience dealing with non-data science teams and translating technical ideas to non-technical people
• A passion for Data Science and a strong growth mindset

Additional Information

For over 50 years, Verisk has been the leading data analytics and technology partner to the global insurance industry by delivering value to our clients through expertise and scale. We empower communities and businesses to make better decisions on risk, faster.

At Verisk, you'll have the chance to use your voice and build a rewarding career that's as unique as you are, with work flexibility and the support, coaching, and training you need to succeed.

For the eighth consecutive year, Verisk is proudly recognized as a Great Place to Work® for outstanding workplace culture in the US, fourth consecutive year in the UK, Spain, and India, and second consecutive year in Poland. We value learning, caring and results and make inclusivity and diversity a top priority. In addition to our Great Place to Work® Certification, we’ve been recognized by The Wall Street Journal as one of the Best-Managed Companies and by Forbes as a World’s Best Employer and Best Employer for Women, testaments to the value we place on workplace culture.

We’re 7,000 people strong. We relentlessly and ethically pursue innovation. And we are looking for people like you to help us translate big data into big ideas. Join us and create an exceptional experience for yourself and a better tomorrow for future generations.

Verisk Businesses

Underwriting Solutions — provides underwriting and rating solutions for auto and property, general liability, and excess and surplus to assess and price risk with speed and precision

Claims Solutions — supports end-to-end claims handling with analytic and automation tools that streamline workflow, improve claims management, and support better customer experiences

Property Estimating Solutions — offers property estimation software and tools for professionals in estimating all phases of building and repair to make day-to-day workflows the most efficient

Extreme Event Solutions — provides risk modeling solutions to help individuals, businesses, and society become more resilient to extreme events.

Specialty Business Solutions — provides an integrated suite of software for full end-to-end management of insurance and reinsurance business, helping companies manage their businesses through efficiency, flexibility, and data governance

Marketing Solutions — delivers data and insights to improve the reach, timing, relevance, and compliance of every consumer engagement

Life Insurance Solutions – offers end-to-end, data insight-driven core capabilities for carriers, distribution, and direct customers across the entire policy lifecycle of life and annuities for both individual and group.

Verisk Maplecroft — provides intelligence on sustainability, resilience, and ESG, helping people, business, and societies become stronger

Verisk Analytics is an equal opportunity employer.

All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.

http://www.verisk.com/careers.html

Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.

HR CCPA Privacy Notice.pdf","[{'items': [""Company Description\n\nWe help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable.\n\nJob Description\n\nAs the nation’s largest data aggregator, and a market leader in analytics solutions for the insurance and financial industry, Opta Information Intelligence is looking to bolster its growing data science team. By building and delivering complex machine learning-based products, you’ll have an opportunity to positively impact the decision-making of our many clients and partners.\n\nAs a Data Scientist you will be responsible for researching and developing data science and machine learning solutions related to the improving our product range.\u202f You will collate with our team of data scientists, data engineers, and other departments to develop and deploy machine Learning & data science products that integrate seamlessly with our... production systems for both batch and real-time processes.\u202f The ideal candidate will bring with them established best practices and an expertise in machine learning model development and deployment, statistical analysis and problem-solving skills. If you are a dedicated individual who thrives in a dynamic and results-driven environment, then this is the position for you!\n\nResponsibilities:\n• Conduct research into latest developments and provide business with solutions to the range of data science problems\n• Develop end-to-end machine learning, from research and development to deployment into our production system\n• Liase with Product and IT teams to push through new products\n• Work with our machine learning engineers to ensure smooth deployment of models into production\n• Sets the vision for the use of new and innovative tools and technology.\n• Employ coding and documentation best practices\n• Maintains and fosters an industry awareness of new developments in machine learning techniques and tools, and ensures quick execution in their use within the department\n\nQualifications\n• Bachelors or Masters Degree in Quantitative Analytics,\u202fStatistics, Mathematics, similar discipline\n• 3+ years of experience developing and deploying machine learning models\n• 3+ years of Statistical Analysis and Modeling\n• Experience running and owning Data Science projects with minimal help from senior staff\n• Experience working with AWS services including: S3, Lambda, EC2, Step Functions, Redshift, SageMaker\n• Expert level knowledge of Python\n• Strong background in deep learning frameworks such as TensorFlow or PyTorch\n• Experience dealing with non-data science teams and translating technical ideas to non-technical people\n• A passion for Data Science and a strong growth mindset\n\nAdditional Information\n\nFor over 50 years, Verisk has been the leading data analytics and technology partner to the global insurance industry by delivering value to our clients through expertise and scale. We empower communities and businesses to make better decisions on risk, faster.\n\nAt Verisk, you'll have the chance to use your voice and build a rewarding career that's as unique as you are, with work flexibility and the support, coaching, and training you need to succeed.\n\nFor the eighth consecutive year, Verisk is proudly recognized as a Great Place to Work® for outstanding workplace culture in the US, fourth consecutive year in the UK, Spain, and India, and second consecutive year in Poland. We value learning, caring and results and make inclusivity and diversity a top priority. In addition to our Great Place to Work® Certification, we’ve been recognized by The Wall Street Journal as one of the Best-Managed Companies and by Forbes as a World’s Best Employer and Best Employer for Women, testaments to the value we place on workplace culture.\n\nWe’re 7,000 people strong. We relentlessly and ethically pursue innovation. And we are looking for people like you to help us translate big data into big ideas. Join us and create an exceptional experience for yourself and a better tomorrow for future generations.\n\nVerisk Businesses\n\nUnderwriting Solutions — provides underwriting and rating solutions for auto and property, general liability, and excess and surplus to assess and price risk with speed and precision\n\nClaims Solutions — supports end-to-end claims handling with analytic and automation tools that streamline workflow, improve claims management, and support better customer experiences\n\nProperty Estimating Solutions — offers property estimation software and tools for professionals in estimating all phases of building and repair to make day-to-day workflows the most efficient\n\nExtreme Event Solutions — provides risk modeling solutions to help individuals, businesses, and society become more resilient to extreme events.\n\nSpecialty Business Solutions — provides an integrated suite of software for full end-to-end management of insurance and reinsurance business, helping companies manage their businesses through efficiency, flexibility, and data governance\n\nMarketing Solutions — delivers data and insights to improve the reach, timing, relevance, and compliance of every consumer engagement\n\nLife Insurance Solutions – offers end-to-end, data insight-driven core capabilities for carriers, distribution, and direct customers across the entire policy lifecycle of life and annuities for both individual and group.\n\nVerisk Maplecroft — provides intelligence on sustainability, resilience, and ESG, helping people, business, and societies become stronger\n\nVerisk Analytics is an equal opportunity employer.\n\nAll members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.\n\nhttp://www.verisk.com/careers.html\n\nUnsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.\n\nHR CCPA Privacy Notice.pdf""]}]","[{'link': 'http://www.verisk.com/', 'text': 'verisk.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=Verisk&sa=X&ved=0ahUKEwirvtnb176FAxW6RjABHef6BgEQmJACCLUL', 'text': 'See web results for Verisk'}]","['3 days ago', 'Full-time']","{'postedAt': '3 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on Smart Recruiters Jobs', 'link': 'https://jobs.smartrecruiters.com/Verisk/743999979590051-data-scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Scientist,2024-04-13 03:39:10.093019
Data Scientist - Generative AI Architect,IBM,Toronto,via Define Your Career With IBM,"Introduction
Technology sales at IBM is evolving its way of working to break beyond boundaries with innovative approaches. Preferring to ‘show’ vs. ‘tell’, Client Engineering co-creates with prospective customers, in real-time, on solutions to their hardest business challenges.

As a Data Scientist - Generative AI within a Client Engineering squad, you’ll contribute to the co-creation of Proofs of Value (PoV) and Minimal Viable Product that demonstrate business value, leading to client investment in AI strategic solutions using Foundation Models. You will engage in developing and deploying AI systems to solve real-world business problems in a wide array of industries around the globe using IBM watsonx platform. AI Engineers cover all stages of the AI solution lifecycle from Data Engineering to Train, Validate, Tune, Deploy, AI Operations, and AI Governance to create a trusted end-to-end AI solution.

As a Data Scientist - Generative AI within a Client Engineering squad, you’ll partner... with Technical Leaders across IBM sales teams and specialists to drive these experiential client engagements. You will form a sales cornerstone in partnership with.

Development, Research and Sales for rapid client delivery and product innovation.
Excellent onboarding training will set you up for success, whilst ongoing development will continue to advance your career through its upward trajectory. Our sales environment is fast-paced and supportive. Always connected to a wider team, you’ll be surrounded by other leaders and colleagues who are always willing to help and be helped – as you steer the creation of MVPs and proofs of concept (PoC) that obsess over user-centricity and business impact. All-the-while ensuring your teams are compelling clients to continually invest in IBM’s people, products, and services.

Your Role and Responsibilities

A Data Scientist - Generative AI in Client Engineering is a specialist in Foundation Models and building AI systems. You’ll leverage the Watson X platform with clients to co-create the value AI can bring to business. You will focus on Technology Patterns as our way to build the right skills and assets for repeatability to delight clients. AI Engineers work in high touch environment on all watsonx.ai opportunities.

We're passionate about success. If this role is right for you, then your achievements will mean that your career is flourishing, your team is succeeding, and our clients are thriving. To help ensure this win-win outcome, a 'day-in-the life' of this opportunity may include, but not be limited to:
• Fine Tuning pre-trained Foundation Models and assisting different stakeholders with analysis and implementation.
• Apply prompt-engineering techniques to specific use cases and types of models.
• Collaborating with the client to rapidly develop AI solutions using IBM watsonx Platform via a Proof of Experience (PoX)
• Applying Foundation Models to propose and validate hypotheses for business queries​
• Utilizing the latest IBM AI technical strategies and sales plays to unlock client opportunities, applying skills in AI development, model building, Fine-Tuning and API integration​.
• Displaying a growth mindset and genuine curiosity to grasp clients' business processes and challenges, employing statistical analysis skills to identify transformation opportunities​.

NAIWD24

#AMEWAX23
#IBMReferred_NorthAmerica

Required Technical and Professional Expertise
• Understanding of key concepts in the Foundation Models literature and expertise in building and deploying them for real-world examples.
• Knowledge of cloud technologies, specifically Kubernetes, and expertise in leveraging them for large-scale AI workloads.
• Ability to identify fundamental problems from real-world cloud use-cases and to design, build and validate successful AI solutions.
• Capability to demonstrate and evaluate AI solutions via experimental methods, particularly through hands-on creation of prototypes.
• Strong communication skills and the ability to collaborate effectively within a local team.
• 5+ Years of relevant experience.
• Excellent command of the English language, both verbal and written.
• Technical experience and knowledge in foundational security, foundational AI, architecture design:
• Deep domain expertise in deployments and migrations to the cloud, Open-source database deployments and migrations, Data Governance, Datawarehousing etc.
• Expertise in systems design with the ability to design and explain data pipelines, ML pipelines, and ML training and serving approaches.
• experience in building repeatable technical assets such as scripts, templates, reference architectures, etc. to enable clients and partnerss at the intersection of infrastructure.
• Experience training and fine tuning models in large scale environments
• Experience with distributed training and optimizing performance versus costs.
• Software development practices:
• experience in DevOps and CI/CD tool chains in the context of MLOps and LLMOp (i.e., Jenkins, GitHub) and container orchestration systems (i.e., Docker, Kubernetes,GitHub).
• Client facing
• Experience working in a customer-facing role (e.g., internal and/or external) with ability to build trusted advisor status and deep relationships to bring business value while demonstrating situational awareness and insightful listening.
• Experience creating Data & Analytics Proof of Concepts (PoC), Minimum Viable Products (MVPs) for customers that lead to production deployments.

Preferred Technical and Professional Expertise
• Strong contribution record with either publications in top peer-reviewed scientific conferences and journals or strong leadership track-record in opens source communities, with a particular focus on foundation models, or large scale machine learning models.
• Track record of being part of highly collaborative teams to tackle important problems which produce high impact solutions
• Knowledge of Large Language Models (LLM), Langchain and HuggingFace Model","[{'items': [""Introduction\nTechnology sales at IBM is evolving its way of working to break beyond boundaries with innovative approaches. Preferring to ‘show’ vs. ‘tell’, Client Engineering co-creates with prospective customers, in real-time, on solutions to their hardest business challenges.\n\nAs a Data Scientist - Generative AI within a Client Engineering squad, you’ll contribute to the co-creation of Proofs of Value (PoV) and Minimal Viable Product that demonstrate business value, leading to client investment in AI strategic solutions using Foundation Models. You will engage in developing and deploying AI systems to solve real-world business problems in a wide array of industries around the globe using IBM watsonx platform. AI Engineers cover all stages of the AI solution lifecycle from Data Engineering to Train, Validate, Tune, Deploy, AI Operations, and AI Governance to create a trusted end-to-end AI solution.\n\nAs a Data Scientist - Generative AI within a Client Engineering squad, you’ll partner... with Technical Leaders across IBM sales teams and specialists to drive these experiential client engagements. You will form a sales cornerstone in partnership with.\n\nDevelopment, Research and Sales for rapid client delivery and product innovation.\nExcellent onboarding training will set you up for success, whilst ongoing development will continue to advance your career through its upward trajectory. Our sales environment is fast-paced and supportive. Always connected to a wider team, you’ll be surrounded by other leaders and colleagues who are always willing to help and be helped – as you steer the creation of MVPs and proofs of concept (PoC) that obsess over user-centricity and business impact. All-the-while ensuring your teams are compelling clients to continually invest in IBM’s people, products, and services.\n\nYour Role and Responsibilities\n\nA Data Scientist - Generative AI in Client Engineering is a specialist in Foundation Models and building AI systems. You’ll leverage the Watson X platform with clients to co-create the value AI can bring to business. You will focus on Technology Patterns as our way to build the right skills and assets for repeatability to delight clients. AI Engineers work in high touch environment on all watsonx.ai opportunities.\n\nWe're passionate about success. If this role is right for you, then your achievements will mean that your career is flourishing, your team is succeeding, and our clients are thriving. To help ensure this win-win outcome, a 'day-in-the life' of this opportunity may include, but not be limited to:\n• Fine Tuning pre-trained Foundation Models and assisting different stakeholders with analysis and implementation.\n• Apply prompt-engineering techniques to specific use cases and types of models.\n• Collaborating with the client to rapidly develop AI solutions using IBM watsonx Platform via a Proof of Experience (PoX)\n• Applying Foundation Models to propose and validate hypotheses for business queries\u200b\n• Utilizing the latest IBM AI technical strategies and sales plays to unlock client opportunities, applying skills in AI development, model building, Fine-Tuning and API integration\u200b.\n• Displaying a growth mindset and genuine curiosity to grasp clients' business processes and challenges, employing statistical analysis skills to identify transformation opportunities\u200b.\n\nNAIWD24\n\n#AMEWAX23\n#IBMReferred_NorthAmerica\n\nRequired Technical and Professional Expertise\n• Understanding of key concepts in the Foundation Models literature and expertise in building and deploying them for real-world examples.\n• Knowledge of cloud technologies, specifically Kubernetes, and expertise in leveraging them for large-scale AI workloads.\n• Ability to identify fundamental problems from real-world cloud use-cases and to design, build and validate successful AI solutions.\n• Capability to demonstrate and evaluate AI solutions via experimental methods, particularly through hands-on creation of prototypes.\n• Strong communication skills and the ability to collaborate effectively within a local team.\n• 5+ Years of relevant experience.\n• Excellent command of the English language, both verbal and written.\n• Technical experience and knowledge in foundational security, foundational AI, architecture design:\n• Deep domain expertise in deployments and migrations to the cloud, Open-source database deployments and migrations, Data Governance, Datawarehousing etc.\n• Expertise in systems design with the ability to design and explain data pipelines, ML pipelines, and ML training and serving approaches.\n• experience in building repeatable technical assets such as scripts, templates, reference architectures, etc. to enable clients and partnerss at the intersection of infrastructure.\n• Experience training and fine tuning models in large scale environments\n• Experience with distributed training and optimizing performance versus costs.\n• Software development practices:\n• experience in DevOps and CI/CD tool chains in the context of MLOps and LLMOp (i.e., Jenkins, GitHub) and container orchestration systems (i.e., Docker, Kubernetes,GitHub).\n• Client facing\n• Experience working in a customer-facing role (e.g., internal and/or external) with ability to build trusted advisor status and deep relationships to bring business value while demonstrating situational awareness and insightful listening.\n• Experience creating Data & Analytics Proof of Concepts (PoC), Minimum Viable Products (MVPs) for customers that lead to production deployments.\n\nPreferred Technical and Professional Expertise\n• Strong contribution record with either publications in top peer-reviewed scientific conferences and journals or strong leadership track-record in opens source communities, with a particular focus on foundation models, or large scale machine learning models.\n• Track record of being part of highly collaborative teams to tackle important problems which produce high impact solutions\n• Knowledge of Large Language Models (LLM), Langchain and HuggingFace Model""]}]","[{'link': 'http://www.ibm.com/', 'text': 'ibm.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=IBM&sa=X&ved=0ahUKEwirvtnb176FAxW6RjABHef6BgEQmJACCO8L', 'text': 'See web results for IBM'}]","['24 days ago', 'Full-time']","{'postedAt': '24 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on Define Your Career With IBM', 'link': 'https://careers.ibm.com/job/19915522/data-scientist-generative-ai-architect-remote/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Scientist,2024-04-13 03:39:10.093019
Data Scientist,BeachHead,Toronto,via Beachhead Inc,"Are you a self-motivated individual who is hardworking with proven work history? Are you a driven team player who is looking to join a fast-paced, high-growth, and energetic team? Are you the talented professional we are looking? If yes, Apply Soon!

Working with one of the top financial clients this role calls for a Data Scientist who will support Senior Manager, Research and Data Science in developing liability forecasting models for different client’s loyalty programs. They will use advanced analytical algorithms and technologies (e.g. machine learning, deep learning, artificial intelligence) to mine and analyze large data sets, model behavioural patterns and produce robust predictions and forecasts for financial planning and ensure effective management and stability of the loyalty and partner programs. This role closely collaborates with other data and analytics professionals and teams to optimize, refine and scale analysis into mature analytics solutions.

Responsibilities:
•... Uses data mining and extracting usable data from valuable data sources to assess the feasibility of AI/ML solutions for improved processing and usage of organization data.
• Designs and implement advanced projection models focused on ultimate redemption rate estimates and overall liability estimates.
• Develops rewards program liability estimation models, including sensitivity impact models and measuring the impact of program changes or redesign.
• Develops customer behavior analyses that allow a program to target more profitable members and increase overall program effectiveness, using advanced predictive models.
• Works independently on end-to-end development of Machine Learning and time series forecasting models to derive insights
• Conducts large-scale analysis of information to discover patterns and trends by combining different modules and algorithms.
• Collaborate together with the product team and partners to understand and provide data-driven decision-making
• Focus is primarily on business/group within the client; may have broader, enterprise-wide focus.
• Provides specialized consulting, analytical and technical support.
• Exercises judgment to identify, diagnose, and solve problems within given rules.
• Works independently and regularly handles non-routine situations.
• Broader work or accountabilities may be assigned as needed.

Desired Skill Set:
• 5 - 7 years of relevant experience and a post-secondary degree in a related field of study or an equivalent combination of education and experience.
• Deep knowledge and technical proficiency gained through extensive education and business experience
• Intermediate level of proficiency:

• Mathematics, statistics & operations research

• Deep learning

• Machine learning

• Trust, bias and ethics

• Creative thinking

• Critical thinking

• CFA, CMA, or FSA is a plus

• Knowledge of financial modeling is a plus

• Knowledge of financial data modelling vs FI product data modelling is preferred

• Actuarial background an asset

• Banking experience is ideal
• Advanced level of proficiency:

• Big data

• Data visualization

• Computational thinking and programming

• Data wrangling

• Data preprocessing

• Creative reasoning

• Verbal & written communication skills

• Collaboration & team skills

• Analytical and problem-solving skills

• Influence skills

• Data-driven decision-making

• Expert knowledge of Python and or SAS

BeachHead is an equal opportunity agency and employer. We advocate for you and welcome anyone regardless of race, color, religion, national origin, sex, physical or mental disability, or age.

Privacy Policy","[{'items': ['Are you a self-motivated individual who is hardworking with proven work history? Are you a driven team player who is looking to join a fast-paced, high-growth, and energetic team? Are you the talented professional we are looking? If yes, Apply Soon!\n\nWorking with one of the top financial clients this role calls for a Data Scientist who will support Senior Manager, Research and Data Science in developing liability forecasting models for different client’s loyalty programs. They will use advanced analytical algorithms and technologies (e.g. machine learning, deep learning, artificial intelligence) to mine and analyze large data sets, model behavioural patterns and produce robust predictions and forecasts for financial planning and ensure effective management and stability of the loyalty and partner programs. This role closely collaborates with other data and analytics professionals and teams to optimize, refine and scale analysis into mature analytics solutions.\n\nResponsibilities:\n•... Uses data mining and extracting usable data from valuable data sources to assess the feasibility of AI/ML solutions for improved processing and usage of organization data.\n• Designs and implement advanced projection models focused on ultimate redemption rate estimates and overall liability estimates.\n• Develops rewards program liability estimation models, including sensitivity impact models and measuring the impact of program changes or redesign.\n• Develops customer behavior analyses that allow a program to target more profitable members and increase overall program effectiveness, using advanced predictive models.\n• Works independently on end-to-end development of Machine Learning and time series forecasting models to derive insights\n• Conducts large-scale analysis of information to discover patterns and trends by combining different modules and algorithms.\n• Collaborate together with the product team and partners to understand and provide data-driven decision-making\n• Focus is primarily on business/group within the client; may have broader, enterprise-wide focus.\n• Provides specialized consulting, analytical and technical support.\n• Exercises judgment to identify, diagnose, and solve problems within given rules.\n• Works independently and regularly handles non-routine situations.\n• Broader work or accountabilities may be assigned as needed.\n\nDesired Skill Set:\n• 5 - 7 years of relevant experience and a post-secondary degree in a related field of study or an equivalent combination of education and experience.\n• Deep knowledge and technical proficiency gained through extensive education and business experience\n• Intermediate level of proficiency:\n\n• Mathematics, statistics & operations research\n\n• Deep learning\n\n• Machine learning\n\n• Trust, bias and ethics\n\n• Creative thinking\n\n• Critical thinking\n\n• CFA, CMA, or FSA is a plus\n\n• Knowledge of financial modeling is a plus\n\n• Knowledge of financial data modelling vs FI product data modelling is preferred\n\n• Actuarial background an asset\n\n• Banking experience is ideal\n• Advanced level of proficiency:\n\n• Big data\n\n• Data visualization\n\n• Computational thinking and programming\n\n• Data wrangling\n\n• Data preprocessing\n\n• Creative reasoning\n\n• Verbal & written communication skills\n\n• Collaboration & team skills\n\n• Analytical and problem-solving skills\n\n• Influence skills\n\n• Data-driven decision-making\n\n• Expert knowledge of Python and or SAS\n\nBeachHead is an equal opportunity agency and employer. We advocate for you and welcome anyone regardless of race, color, religion, national origin, sex, physical or mental disability, or age.\n\nPrivacy Policy']}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&q=BeachHead&sa=X&ved=0ahUKEwirvtnb176FAxW6RjABHef6BgEQmJACCKQM', 'text': 'See web results for BeachHead'}]","['3 days ago', 'Contractor']","{'postedAt': '3 days ago', 'scheduleType': 'Contractor'}","{'title': 'Apply directly on Beachhead Inc', 'link': 'https://www.beach-head.com/jobs-search/data-scientist-16810/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Data Scientist,2024-04-13 03:39:10.093019
Software Developer - Full Stack,Cloud Vital,Toronto,via LinkedIn,"Job Title: Software Developer - Full Stack

Job Location: Toronto

Job Type: Full Time/ Contract

Deliverables and Skill Sets:
• Experience in programming and analysis
• Specialized software package support at the specified experience level
• Ability to collaborate with IT Professionals throughout the Software Development process
• Experience in Agile/Scrum methodology for the development, design, implementation and maintenance of applications
• Experience in design, coding, testing and debugging of applications
• Experience in one or more programming languages
• Experience with relational database technologies
• Experience in the use of information retrieval using query languages (e.g. SQL)
• Excellent analytical, problem-solving and decision-making skills; verbal and written communication skills; interpersonal and negotiation skills

Microsoft/Azure Development and Quality Assurance Experience

Must have

.NET Framework and/or .NET Core-based design, development, and testing

C... JavaScript

Nice to have

ASP.NET Blazor, Razor

.NET MAUI

Microservices

Azure SQL

Responsive Web front-end, Web APIs, and web services design, development, and testing

Unit testing and test automation support (e.g. NUnit, XUnit, MSTest, Karma, Jasmine)

Microservices and container-based platform development, delivery, and testing

JSON

Azure Cloud Development including PaaS and SQL services, or other cloud hosting technologies (e.g. Pivotal Cloud Foundry/PCF, Amazon Web Services/AWS, and Google Cloud Platform/GCP)

Regression testing (manual and automated), including familiarity with web-based QA automation software such as Playwright, and supporting the use of such tools via coding techniques

GIT, Azure DevOps (VSTS/TFS)

CI/CD pipeline setup and management

Experience participating in Scrum Agile development

Experience contributing as a Developer or Tester (QA) in a balanced team which is comprised of roles including Developers, Testers, product Management, and Design

Experience participating and contributing to task planning, daily stand ups, iteration demos, and review meetings

Providing input to development estimates and designs

Experience working with a team using concurrent development practices including Git-based source control, feature branches, and DevOps CI/CD pipelines","[{'items': ['Job Title: Software Developer - Full Stack\n\nJob Location: Toronto\n\nJob Type: Full Time/ Contract\n\nDeliverables and Skill Sets:\n• Experience in programming and analysis\n• Specialized software package support at the specified experience level\n• Ability to collaborate with IT Professionals throughout the Software Development process\n• Experience in Agile/Scrum methodology for the development, design, implementation and maintenance of applications\n• Experience in design, coding, testing and debugging of applications\n• Experience in one or more programming languages\n• Experience with relational database technologies\n• Experience in the use of information retrieval using query languages (e.g. SQL)\n• Excellent analytical, problem-solving and decision-making skills; verbal and written communication skills; interpersonal and negotiation skills\n\nMicrosoft/Azure Development and Quality Assurance Experience\n\nMust have\n\n.NET Framework and/or .NET Core-based design, development, and testing\n\nC... JavaScript\n\nNice to have\n\nASP.NET Blazor, Razor\n\n.NET MAUI\n\nMicroservices\n\nAzure SQL\n\nResponsive Web front-end, Web APIs, and web services design, development, and testing\n\nUnit testing and test automation support (e.g. NUnit, XUnit, MSTest, Karma, Jasmine)\n\nMicroservices and container-based platform development, delivery, and testing\n\nJSON\n\nAzure Cloud Development including PaaS and SQL services, or other cloud hosting technologies (e.g. Pivotal Cloud Foundry/PCF, Amazon Web Services/AWS, and Google Cloud Platform/GCP)\n\nRegression testing (manual and automated), including familiarity with web-based QA automation software such as Playwright, and supporting the use of such tools via coding techniques\n\nGIT, Azure DevOps (VSTS/TFS)\n\nCI/CD pipeline setup and management\n\nExperience participating in Scrum Agile development\n\nExperience contributing as a Developer or Tester (QA) in a balanced team which is comprised of roles including Developers, Testers, product Management, and Design\n\nExperience participating and contributing to task planning, daily stand ups, iteration demos, and review meetings\n\nProviding input to development estimates and designs\n\nExperience working with a team using concurrent development practices including Git-based source control, feature branches, and DevOps CI/CD pipelines']}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&ucbcb=1&q=Cloud+Vital&sa=X&ved=0ahUKEwim-o_q176FAxUzlIQIHZJbCqUQmJACCMIJ', 'text': 'See web results for Cloud Vital'}]","['18 hours ago', 'Full-time', 'No degree mentioned']","{'postedAt': '18 hours ago', 'scheduleType': 'Full-time'}","{'title': '.nFg2eb{font-weight:500}.Bi6Ddc{font-weight:500}Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/software-developer-full-stack-at-cloud-vital-3896175433?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Software Developer,2024-04-13 03:39:39.800626
Senior Software Developer (Frontend),HelloFresh,Toronto,via Careers At HelloFresh,"Our TAM Expansion team aims to grow our global footprint by launching our core products in different markets and expanding our offerings through multiple brands and verticals. We are a globally-distributed team working together on 7+ brands in 15+ countries. There are lots of other exciting projects on the go, so if you are passionate about taking on challenges like this, join us!

S’more about the team

We are a close-knit group of engineers of different stripes - developers, designers, and product owners - who are working together to solve interesting e-commerce and supply chain problems around how people eat. Sometimes, this involves implementing features to improve the user
journey and making it easier for our customers to buy amazing food. Other times, this means creating stable software solutions that keep our distribution centers running.

We are looking for a Senior Software Developer to help implement solutions & write beautiful code, working with various team members as we... build out our consumer facing applications & the infrastructure that supports them. As a member of our Toronto team, you’ll work with highly-skilled engineers, who in collaboration with our other global teams, have turned HelloFresh into the #1 meal delivery service in the world!

Lettuce share what this role will be responsible for
• Be able to design-develop-deploy software solutions for various HelloFresh markets & brands to deliver the best experience for our customers and internal users
• Take ownership of the architecture, design, development, deployment, and operations of the solutions that you develop, using DevOps practices, pair programming, and other cutting edge methodologies
• Be able to spend time learning and developing technical skills, and show off your technical chops via ambitious goals

Sound a-peeling? Here's what we're looking for
• An active, solution-oriented member of autonomous, cross-functional agile teams collaborating with Product Owners, Frontend and Backend Engineers, Designers, and Business Intelligence teams
• An individual able to develop an in-depth understanding of HelloFresh’s core products and architecture, and act as an ambassador for state of the art software solutions and industry best practices, while offering support and mentorship to colleagues
• 4+ years of working experience in an agile software development team
• 2+ years of experience working with React JS (preferred) or another similar Javascript framework (React Native, Angular, VueJS)
• Hands-on experience in continuous delivery deploying to customer-facing applications
• Experience writing unit/integration/function test cases, as well as with formalized testing methodologies (i.e. TDD, BDD)
• Experience with server-side technologies like Next.js, Nest.js, Nuxt.js, or Remix
• Experience working with UI libraries such as Solid or Svelte
• Experience with experimentation
• Bonus if you have exposure to mobile app development, either through React Native or native iOS/Android
• Would be a plus if you had working knowledge of one of the following backend languages: NodeJS, Python or GoLang

Let’s cut to the cheese, this is why you'll love it here
• Box discount - 75% discount on weekly HelloFresh and Chefs Plate meal kits
• Hybrid work model- flexible arrangement offering 50% remote work (learn more below!)
• Trust & support- own your work and push your ideas from inception to execution
• Growth & development- we support your career progression and provide learning and development opportunities
• Work hard & have fun- we take our work seriously, but we don't take ourselves too seriously. From team socials to HQ Wellness Wednesdays, you’ll have plenty of opportunity to experience the fun!
• Our office- With comfy couches, an array of board games, a gorgeous rooftop patio, and more - we have it all! Did we mention that we also have an incredible test kitchen where delicious meals are constantly ready to be tasted?
• Food puns- this one is kind of a big dill if you haven’t already noticed. We even have some punny meeting room names","[{'items': [""Our TAM Expansion team aims to grow our global footprint by launching our core products in different markets and expanding our offerings through multiple brands and verticals. We are a globally-distributed team working together on 7+ brands in 15+ countries. There are lots of other exciting projects on the go, so if you are passionate about taking on challenges like this, join us!\n\nS’more about the team\n\nWe are a close-knit group of engineers of different stripes - developers, designers, and product owners - who are working together to solve interesting e-commerce and supply chain problems around how people eat. Sometimes, this involves implementing features to improve the user\njourney and making it easier for our customers to buy amazing food. Other times, this means creating stable software solutions that keep our distribution centers running.\n\nWe are looking for a Senior Software Developer to help implement solutions & write beautiful code, working with various team members as we... build out our consumer facing applications & the infrastructure that supports them. As a member of our Toronto team, you’ll work with highly-skilled engineers, who in collaboration with our other global teams, have turned HelloFresh into the #1 meal delivery service in the world!\n\nLettuce share what this role will be responsible for\n• Be able to design-develop-deploy software solutions for various HelloFresh markets & brands to deliver the best experience for our customers and internal users\n• Take ownership of the architecture, design, development, deployment, and operations of the solutions that you develop, using DevOps practices, pair programming, and other cutting edge methodologies\n• Be able to spend time learning and developing technical skills, and show off your technical chops via ambitious goals\n\nSound a-peeling? Here's what we're looking for\n• An active, solution-oriented member of autonomous, cross-functional agile teams collaborating with Product Owners, Frontend and Backend Engineers, Designers, and Business Intelligence teams\n• An individual able to develop an in-depth understanding of HelloFresh’s core products and architecture, and act as an ambassador for state of the art software solutions and industry best practices, while offering support and mentorship to colleagues\n• 4+ years of working experience in an agile software development team\n• 2+ years of experience working with React JS (preferred) or another similar Javascript framework (React Native, Angular, VueJS)\n• Hands-on experience in continuous delivery deploying to customer-facing applications\n• Experience writing unit/integration/function test cases, as well as with formalized testing methodologies (i.e. TDD, BDD)\n• Experience with server-side technologies like Next.js, Nest.js, Nuxt.js, or Remix\n• Experience working with UI libraries such as Solid or Svelte\n• Experience with experimentation\n• Bonus if you have exposure to mobile app development, either through React Native or native iOS/Android\n• Would be a plus if you had working knowledge of one of the following backend languages: NodeJS, Python or GoLang\n\nLet’s cut to the cheese, this is why you'll love it here\n• Box discount - 75% discount on weekly HelloFresh and Chefs Plate meal kits\n• Hybrid work model- flexible arrangement offering 50% remote work (learn more below!)\n• Trust & support- own your work and push your ideas from inception to execution\n• Growth & development- we support your career progression and provide learning and development opportunities\n• Work hard & have fun- we take our work seriously, but we don't take ourselves too seriously. From team socials to HQ Wellness Wednesdays, you’ll have plenty of opportunity to experience the fun!\n• Our office- With comfy couches, an array of board games, a gorgeous rooftop patio, and more - we have it all! Did we mention that we also have an incredible test kitchen where delicious meals are constantly ready to be tasted?\n• Food puns- this one is kind of a big dill if you haven’t already noticed. We even have some punny meeting room names""]}]","[{'link': 'http://www.hellofreshgroup.com/', 'text': 'hellofreshgroup.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&ucbcb=1&q=HelloFresh&sa=X&ved=0ahUKEwim-o_q176FAxUzlIQIHZJbCqUQmJACCIIK', 'text': 'See web results for HelloFresh'}]","['2 days ago', 'Full-time', 'No degree mentioned']","{'postedAt': '2 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on Careers At HelloFresh', 'link': 'https://careers.hellofresh.com/global/en/job/5895121?gh_jid=5895121&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Software Developer,2024-04-13 03:39:39.800626
Senior Software Developer,Dye & Durham Corporation,Toronto,via LinkedIn,"Dye & Durham, a leading global provider of cloud–based software and technology solutions, provides critical information services and workflows used by clients all over the world to manage their process, information, and regulatory requirements. With clients that include major law firms, financial service institutions and government organizations in Canada, the United Kingdom, Ireland, South Africa and Australia, a fulfilling career awaits you at Dye & Durham.

We are looking for an individual who will participate in the development of our industry leading Due Diligence platform making it easy for our customers to easily manage their business records and corporate filings. The successful candidate will be collaborative, highly motivated, and keen to learn.

They will always be on the lookout for ways their team can do better. Core responsibilities will revolve around maintenance and extension of existing code base, improving the existing system with modern tools/practices, development... of new products and working with leads to meet business requirements.

WHAT WILL YOU DO?
• Support sizing and estimation processes as a part of an Agile team.
• Develop, test, and implement new capabilities for the market based on Product roadmaps.
• Help guide and support ongoing technology improvement roadmaps.
• Clearly and regularly communicate with colleagues.
• Participate in peer-reviews of solution designs and code reviews.
• Pair with and mentor others.

WHAT DO YOU NEED TO BE CONSIDERED?

Our Due Diligence platform utilizes the Microsoft .NET framework, classic ASP, and SQL Server. As we continue to work to modernize the stack, we’ll always be looking at the best technology options available to us.

If you’re comfortable in this environment come talk to us!

WHY WORK FOR US?

At Dye & Durham we strive to be visionaries! As a leader in our field, we ensure our employees are ready for the next challenge in their journey with us by offering internal and external training opportunities. We offer competitive salaries and a whole host of benefits including healthcare, pension, company discounts, wellness programs, and paid days off to move house or volunteer for your favourite charity.

WHAT NEXT?

Hit apply and your application will be reviewed by our talent acquisition team who will contact you directly.

Please note that this position is subject to security checks.

We are a hybrid work environment with a 1-day a week work from home allowance.

Dye & Durham is an equal opportunity employer. We provide opportunities without regard to race, colour, religion, sexual orientations, gender identity, national origin, marital or family status, disability status or other applicable legally protected characteristics","[{'items': ['Dye & Durham, a leading global provider of cloud–based software and technology solutions, provides critical information services and workflows used by clients all over the world to manage their process, information, and regulatory requirements. With clients that include major law firms, financial service institutions and government organizations in Canada, the United Kingdom, Ireland, South Africa and Australia, a fulfilling career awaits you at Dye & Durham.\n\nWe are looking for an individual who will participate in the development of our industry leading Due Diligence platform making it easy for our customers to easily manage their business records and corporate filings. The successful candidate will be collaborative, highly motivated, and keen to learn.\n\nThey will always be on the lookout for ways their team can do better. Core responsibilities will revolve around maintenance and extension of existing code base, improving the existing system with modern tools/practices, development... of new products and working with leads to meet business requirements.\n\nWHAT WILL YOU DO?\n• Support sizing and estimation processes as a part of an Agile team.\n• Develop, test, and implement new capabilities for the market based on Product roadmaps.\n• Help guide and support ongoing technology improvement roadmaps.\n• Clearly and regularly communicate with colleagues.\n• Participate in peer-reviews of solution designs and code reviews.\n• Pair with and mentor others.\n\nWHAT DO YOU NEED TO BE CONSIDERED?\n\nOur Due Diligence platform utilizes the Microsoft .NET framework, classic ASP, and SQL Server. As we continue to work to modernize the stack, we’ll always be looking at the best technology options available to us.\n\nIf you’re comfortable in this environment come talk to us!\n\nWHY WORK FOR US?\n\nAt Dye & Durham we strive to be visionaries! As a leader in our field, we ensure our employees are ready for the next challenge in their journey with us by offering internal and external training opportunities. We offer competitive salaries and a whole host of benefits including healthcare, pension, company discounts, wellness programs, and paid days off to move house or volunteer for your favourite charity.\n\nWHAT NEXT?\n\nHit apply and your application will be reviewed by our talent acquisition team who will contact you directly.\n\nPlease note that this position is subject to security checks.\n\nWe are a hybrid work environment with a 1-day a week work from home allowance.\n\nDye & Durham is an equal opportunity employer. We provide opportunities without regard to race, colour, religion, sexual orientations, gender identity, national origin, marital or family status, disability status or other applicable legally protected characteristics']}]","[{'link': 'http://dyedurham.com/', 'text': 'dyedurham.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&ucbcb=1&q=Dye+%26+Durham+Corporation&sa=X&ved=0ahUKEwim-o_q176FAxUzlIQIHZJbCqUQmJACCLoK', 'text': 'See web results for Dye & Durham Corporation'}]","['10 hours ago', 'Full-time']","{'postedAt': '10 hours ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/senior-software-developer-at-dye-durham-corporation-3893513277?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Software Developer,2024-04-13 03:39:39.800626
Software Engineer,Equifax,Toronto,via Equifax Careers,"Synopsis of the role

The individual in this position will be responsible for end-to-end delivery and maintenance of high-quality software engineered for cloud-nativity and scale. Working closely with local and global technology and business teams, he/she will be taking the lead on designing, coding, delivering, and supporting highly available, secure and scalable systems. The person in this role will also be expected to work with Product Owners, Product Architects, Technical Architects, Security Officers, Infrastructure team members, Scrum Masters and external parties in order to be successful in their role. This role will have a team of software engineers reporting to them, split into multiple agile delivery squads, along with responsibility of indirectly leading QE and SRE. Ownership, drive, and a passion for engineering are key attributes for success.

What you’ll do
• Working on cloud-native backends and data processing algorithms, focusing on improving and maintaining both new ... legacy systems.
• Reviewing code for adherence to best practices.
• Streamlining tedious infrastructure processes, focusing on impactful development work.
• Get hand on experience on latest technologies including Cloud Computing (GCP)
• Participate in collaborative technical discussions that focus on software user experience, design, architecture, and development
• Perform demonstrations for client stakeholders on project features and sub features, which utilizes the latest Front end and Backend development technologies
• Support continuous improvement by investigating alternatives and technologies and presenting these for architectural review.

What experience you need
• At least 4 years of professional experience as a Java developer (excluding university courses)
• Hands-on experience in designing and developing applications using Java EE platforms or Python.
• Experience for working with Object Oriented analysis and design using common design patterns.
• Profound insight of Java and JEE internals (Multi threading, Memory Management, Transaction management etc)
• Experience in the Spring Framework

What could set you apart
• Active Cloud Certification strongly preferred
• Familiarity with AI and ML tools","[{'items': ['Synopsis of the role\n\nThe individual in this position will be responsible for end-to-end delivery and maintenance of high-quality software engineered for cloud-nativity and scale. Working closely with local and global technology and business teams, he/she will be taking the lead on designing, coding, delivering, and supporting highly available, secure and scalable systems. The person in this role will also be expected to work with Product Owners, Product Architects, Technical Architects, Security Officers, Infrastructure team members, Scrum Masters and external parties in order to be successful in their role. This role will have a team of software engineers reporting to them, split into multiple agile delivery squads, along with responsibility of indirectly leading QE and SRE. Ownership, drive, and a passion for engineering are key attributes for success.\n\nWhat you’ll do\n• Working on cloud-native backends and data processing algorithms, focusing on improving and maintaining both new ... legacy systems.\n• Reviewing code for adherence to best practices.\n• Streamlining tedious infrastructure processes, focusing on impactful development work.\n• Get hand on experience on latest technologies including Cloud Computing (GCP)\n• Participate in collaborative technical discussions that focus on software user experience, design, architecture, and development\n• Perform demonstrations for client stakeholders on project features and sub features, which utilizes the latest Front end and Backend development technologies\n• Support continuous improvement by investigating alternatives and technologies and presenting these for architectural review.\n\nWhat experience you need\n• At least 4 years of professional experience as a Java developer (excluding university courses)\n• Hands-on experience in designing and developing applications using Java EE platforms or Python.\n• Experience for working with Object Oriented analysis and design using common design patterns.\n• Profound insight of Java and JEE internals (Multi threading, Memory Management, Transaction management etc)\n• Experience in the Spring Framework\n\nWhat could set you apart\n• Active Cloud Certification strongly preferred\n• Familiarity with AI and ML tools']}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&ucbcb=1&q=Equifax&sa=X&ved=0ahUKEwim-o_q176FAxUzlIQIHZJbCqUQmJACCPgK', 'text': 'See web results for Equifax'}]","['4 days ago', 'Full-time', 'No degree mentioned']","{'postedAt': '4 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on Equifax Careers', 'link': 'https://careers.equifax.com/en/jobs/j00157287/software-engineer/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Software Developer,2024-04-13 03:39:39.800626
Senior Full-Stack Software Developer,ClickJobs.io,Toronto,via LinkedIn,"About us 9569154 Canada Inc. operating as PolyFluent Software is a Canadian company developing language learning apps. We are changing the way people read, listen and watch everything in a second language, so that language learning does not require dedicated studying but happens naturally as a by-product of reading articles, books, listening to songs and audiobooks, watching movies and documentaries. Job Duties In the role of Senior Full-Stack Software Developer, you'll be an integral part of our product development team, making substantial contributions to the architecture, building, and enhancement of our products. You can expect to:
• Lead and participate in the development of web and mobile applications
• Enhance our machine learning models and linguistic resources using NLP
• Apply Python scripting for back-end services development
• Develop our WebView applications for both iOS and Android platforms
• Collaborate directly with team members, including product managers and... front-end developers to clarify project requirements and find the best solutions
• Ensure our applications perform optimally, are high-quality, and respond efficiently to user requests Required Skills and Experience:
• A bachelor's or master's degree in Computer Science or Software Engineering
• English language proficiency
• 3+ years of experience as a software developer
• Proficiency in React, Angular and TypeScript
• Experience in scripting with Python
• Good understanding of and practical experience in Natural Language Processing
• Experience in iOS and Android development
• Experience with Shell scripting and managing Linux/Unix environments.
• Experience in database design, management, and query optimization for PostgreSQL, MongoDB, and ElasticSearch Nice to have:
• Experience in using AWS for deploying, managing, and scaling applications
• Understanding of BI methodologies and ability to leverage data to drive decision making Job Details * $97,000 to $110,000 per annum, commensurate with experience.
• Permanent, full-time (40 hours per week) position.
• 4 weeks paid vacation
• English is the primary language of communication in the workplace Location 143 White Blvd, Thornhill ON L4J 5Z1 This position is primarily remote, but occasional in-person attendance may be required for specific business needs. Candidates must either reside in or be willing to relocate to the Greater Toronto Area. Contact Please send your resume to savvymeapps@gmail.com","[{'items': [""About us 9569154 Canada Inc. operating as PolyFluent Software is a Canadian company developing language learning apps. We are changing the way people read, listen and watch everything in a second language, so that language learning does not require dedicated studying but happens naturally as a by-product of reading articles, books, listening to songs and audiobooks, watching movies and documentaries. Job Duties In the role of Senior Full-Stack Software Developer, you'll be an integral part of our product development team, making substantial contributions to the architecture, building, and enhancement of our products. You can expect to:\n• Lead and participate in the development of web and mobile applications\n• Enhance our machine learning models and linguistic resources using NLP\n• Apply Python scripting for back-end services development\n• Develop our WebView applications for both iOS and Android platforms\n• Collaborate directly with team members, including product managers and... front-end developers to clarify project requirements and find the best solutions\n• Ensure our applications perform optimally, are high-quality, and respond efficiently to user requests Required Skills and Experience:\n• A bachelor's or master's degree in Computer Science or Software Engineering\n• English language proficiency\n• 3+ years of experience as a software developer\n• Proficiency in React, Angular and TypeScript\n• Experience in scripting with Python\n• Good understanding of and practical experience in Natural Language Processing\n• Experience in iOS and Android development\n• Experience with Shell scripting and managing Linux/Unix environments.\n• Experience in database design, management, and query optimization for PostgreSQL, MongoDB, and ElasticSearch Nice to have:\n• Experience in using AWS for deploying, managing, and scaling applications\n• Understanding of BI methodologies and ability to leverage data to drive decision making Job Details * $97,000 to $110,000 per annum, commensurate with experience.\n• Permanent, full-time (40 hours per week) position.\n• 4 weeks paid vacation\n• English is the primary language of communication in the workplace Location 143 White Blvd, Thornhill ON L4J 5Z1 This position is primarily remote, but occasional in-person attendance may be required for specific business needs. Candidates must either reside in or be willing to relocate to the Greater Toronto Area. Contact Please send your resume to savvymeapps@gmail.com""]}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&ucbcb=1&q=ClickJobs.io&sa=X&ved=0ahUKEwim-o_q176FAxUzlIQIHZJbCqUQmJACCK8L', 'text': 'See web results for ClickJobs.io'}]","['16 hours ago', 'Work from home', 'Full-time']","{'postedAt': '16 hours ago', 'scheduleType': 'Full-time', 'workFromHome': True}","{'title': 'Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/senior-full-stack-software-developer-at-clickjobs-io-3895310285?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Software Developer,2024-04-13 03:39:39.800626
Software Engineer Intern - PEY,Snowflake,Toronto,via Snowflake Careers,"Build the future of data. Join the Snowflake team.

There is only one Data Cloud. Snowflake’s founders started from scratch and designed a data platform built for the cloud that is effective, affordable, and accessible to all data users. But it didn’t stop there. They engineered Snowflake to power the Data Cloud, where thousands of organizations unlock the value of their data with near-unlimited scale, concurrency, and performance. This is our vision: a world with endless insights to tackle the challenges and opportunities of today and reveal the possibilities of tomorrow.

We’re looking for dedicated students who share our passion for ground-breaking technology and want to create a lasting future for you and Snowflake.

WHAT WE OFFER:
• Paid, full-time internships in the heart of the software industry
• Post-internship career opportunities (full-time and/or additional internships)
• Exposure to a fast-paced, fun and inclusive culture
• A chance to work with world-class experts on... challenging projects
• Opportunity to provide meaningful contributions to a real system used by customers
• High level of access to supervisors (manager and mentor), detailed direction without micromanagement, feedback throughout your internship, and a final evaluation

WHAT WE EXPECT:
• Must be actively enrolled in an accredited college/university program during the time of the internshipDesired class level: 3rd/4th year Undergraduates, Masters, or PhD
• Desired majors: Computer Science, Computer Engineering, Electrical Engineering, Physics, Math, or related field
• Required coursework: algorithms, data structures, and operating systems
• 12 to 16 month Professional Experience Year (PEY)
• Start Dates: /May 2024
• Paid, full-time internships in the heart of the software industry
• Post-internship career opportunities (full-time and/or additional internships)
• Exposure to a fast-paced, fun and inclusive culture
• A chance to work with world-class experts on challenging projects
• Opportunity to provide meaningful contributions to a real system used by customers
• High level of access to supervisors (manager and mentor), detailed direction without micromanagement, feedback throughout your internship, and a final evaluation
• Stuff that matters: treated as a member of the Snowflake team, included in company meetings/activities, flexible hours, casual dress code, accommodations to work from home, swag and much more
• When return to office in effect, catered lunches, access to gaming consoles, recreational games, happy hours, company outings, and more","[{'items': ['Build the future of data. Join the Snowflake team.\n\nThere is only one Data Cloud. Snowflake’s founders started from scratch and designed a data platform built for the cloud that is effective, affordable, and accessible to all data users. But it didn’t stop there. They engineered Snowflake to power the Data Cloud, where thousands of organizations unlock the value of their data with near-unlimited scale, concurrency, and performance. This is our vision: a world with endless insights to tackle the challenges and opportunities of today and reveal the possibilities of tomorrow.\n\nWe’re looking for dedicated students who share our passion for ground-breaking technology and want to create a lasting future for you and Snowflake.\n\nWHAT WE OFFER:\n• Paid, full-time internships in the heart of the software industry\n• Post-internship career opportunities (full-time and/or additional internships)\n• Exposure to a fast-paced, fun and inclusive culture\n• A chance to work with world-class experts on... challenging projects\n• Opportunity to provide meaningful contributions to a real system used by customers\n• High level of access to supervisors (manager and mentor), detailed direction without micromanagement, feedback throughout your internship, and a final evaluation\n\nWHAT WE EXPECT:\n• Must be actively enrolled in an accredited college/university program during the time of the internshipDesired class level: 3rd/4th year Undergraduates, Masters, or PhD\n• Desired majors: Computer Science, Computer Engineering, Electrical Engineering, Physics, Math, or related field\n• Required coursework: algorithms, data structures, and operating systems\n• 12 to 16 month Professional Experience Year (PEY)\n• Start Dates: /May 2024\n• Paid, full-time internships in the heart of the software industry\n• Post-internship career opportunities (full-time and/or additional internships)\n• Exposure to a fast-paced, fun and inclusive culture\n• A chance to work with world-class experts on challenging projects\n• Opportunity to provide meaningful contributions to a real system used by customers\n• High level of access to supervisors (manager and mentor), detailed direction without micromanagement, feedback throughout your internship, and a final evaluation\n• Stuff that matters: treated as a member of the Snowflake team, included in company meetings/activities, flexible hours, casual dress code, accommodations to work from home, swag and much more\n• When return to office in effect, catered lunches, access to gaming consoles, recreational games, happy hours, company outings, and more']}]","[{'link': 'http://www.snowflake.com/', 'text': 'snowflake.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&ucbcb=1&q=Snowflake&sa=X&ved=0ahUKEwim-o_q176FAxUzlIQIHZJbCqUQmJACCOsL', 'text': 'See web results for Snowflake'}]","['1 day ago', 'Full-time and Internship']","{'postedAt': '1 day ago', 'scheduleType': 'Full-time and Internship'}","{'title': 'Apply on Snowflake Careers', 'link': 'https://careers.snowflake.com/us/en/job/7064824002/Software-Engineer-Intern-PEY?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Software Developer,2024-04-13 03:39:39.800626
RQ07205 - Senior - Software Developer,Modis,Toronto,via Modis,"Ontario Government Client is actively seeking a Software Developer. As a Software Developer, where you have experience in C#, Java, and frontend technologies. The ideal candidate will have a background in public safety environments and a proven track record in software development, debugging, and optimization. Join our team to contribute to the development of critical applications that serve the public interest.

Note: The candidate is present on-site for three days each week.

Must Haves
• 8+ years of C# code development (.NET, ASP.NET, MVC, IIS, WCF)
• Proficiency in XHTML, HTML5, JavaScript, jQuery, Ajax, AngularJS, Bootstrap, XSLT, and XML
• Extensive experience in debugging, refactoring, and optimization
• Expertise in SQL development using SQL Server Management Studio

Criteria:
• Public Safety Experience
• Background in public safety environments (e.g., ambulance, fire, police)
• Familiarity with Computer Aided Dispatch (CAD) applications
• Development Experience
• Over 10... years of software development expertise covering the SDLC and Application Lifecycle Management
• Strong proficiency in Java, Spring Boot, and C# (.NET, MVC, IIS, WCF)
• Frontend development skills with Angular, React, Flutter, Ionic, and AngularJS
• In-depth knowledge of multi-threaded applications and concurrency patterns in C#
• Experience in building web applications, web services (SOAP and REST), and Windows client applications
• Technical Skills
• Familiarity with Common Language Runtime (CLR) and its functionalities
• Proficiency in object-oriented programming and design patterns
• Ability to design modules/functionality meeting business/client requirements
• Application of fundamental design principles and scalability best practices
• Understanding of UI Design Principles
• Communication Skills
• Strong consulting skills for stakeholder engagement
• Proven track record as a team player meeting deadlines
• Experience in developing enterprise-level applications securing sensitive information
• Knowledge of public sector governance methodologies (e.g., UPM, architecture gating","[{'items': ['Ontario Government Client is actively seeking a Software Developer. As a Software Developer, where you have experience in C#, Java, and frontend technologies. The ideal candidate will have a background in public safety environments and a proven track record in software development, debugging, and optimization. Join our team to contribute to the development of critical applications that serve the public interest.\n\nNote: The candidate is present on-site for three days each week.\n\nMust Haves\n• 8+ years of C# code development (.NET, ASP.NET, MVC, IIS, WCF)\n• Proficiency in XHTML, HTML5, JavaScript, jQuery, Ajax, AngularJS, Bootstrap, XSLT, and XML\n• Extensive experience in debugging, refactoring, and optimization\n• Expertise in SQL development using SQL Server Management Studio\n\nCriteria:\n• Public Safety Experience\n• Background in public safety environments (e.g., ambulance, fire, police)\n• Familiarity with Computer Aided Dispatch (CAD) applications\n• Development Experience\n• Over 10... years of software development expertise covering the SDLC and Application Lifecycle Management\n• Strong proficiency in Java, Spring Boot, and C# (.NET, MVC, IIS, WCF)\n• Frontend development skills with Angular, React, Flutter, Ionic, and AngularJS\n• In-depth knowledge of multi-threaded applications and concurrency patterns in C#\n• Experience in building web applications, web services (SOAP and REST), and Windows client applications\n• Technical Skills\n• Familiarity with Common Language Runtime (CLR) and its functionalities\n• Proficiency in object-oriented programming and design patterns\n• Ability to design modules/functionality meeting business/client requirements\n• Application of fundamental design principles and scalability best practices\n• Understanding of UI Design Principles\n• Communication Skills\n• Strong consulting skills for stakeholder engagement\n• Proven track record as a team player meeting deadlines\n• Experience in developing enterprise-level applications securing sensitive information\n• Knowledge of public sector governance methodologies (e.g., UPM, architecture gating']}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&ucbcb=1&q=Modis&sa=X&ved=0ahUKEwim-o_q176FAxUzlIQIHZJbCqUQmJACCKYM', 'text': 'See web results for Modis'}]","['1 day ago', 'Contractor and Temp work', 'No degree mentioned']","{'postedAt': '1 day ago', 'scheduleType': 'Contractor and Temp work'}","{'title': 'Apply on Modis', 'link': 'https://www.modis.com/en-ca/job-seekers/job/toronto/rq07205-senior-software-developer-/CA_EN_6_919740_1537833/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Software Developer,2024-04-13 03:39:39.800626
Software developer - Web specialist,Amiseq Inc.,Toronto,via Dice.com,"Description:

Responsibilities: Develops, updates, analyses and edits content and functionality for websites; develops content strategy; integrating web initiatives into existing templates Review and ensure websites are standards compliant for the Government of Ontario. Experience with content creation and driving content strategy Awareness of emerging trends and directions in web and their application within the Government framework Knowledge and understanding of Accessibility for Ontarians with Disability Act (AODA) and related regulations and standards Experience in standard web programming environments (e.g. HTML5, CSS3, XML, JavaScript, ASP, .NET, PHP, Ruby.ASP, Java) Knowledge of Open Source software initiatives (e.g. Linux, WordPress, Drupal, Solr, Git, Apache) (e.g. WordPress, various Search engines and web development frameworks and APIs), including design criteria, security and recovery procedures, code management and deployment practices, as well as experience in the... development/preparation of technical specifications for installation, testing frameworks, and performance of integrated, multi- service systems. Knowledge of PHP, Java, JavaScript, Angular, Node, MySQL, MongoDB, Drupal, Twig, and

Skill Set Requirements

User Experience Design/ Quality Assurance

Provides quality assurance and user experience design expertise and advice to internal stakeholders on design principles and the development and implementation of best practices in accessibility to ensure compliance with legal requirements and industry best practices..

Project Management

Leads and/or carries out large scale and sensitive projects and/or significant components of other projects with accessibility design elements, to mitigate identified risk to an acceptable level, ensuring compliance and integration with the Accessibility for Ontarians with Disabilities Act (AODA) standards and Ontario s Accessible by Design: 2022 2025 OPS Multi-Year Accessibility Plan goals; provide supervision/technical direction to teams, coordinate development of design specifications, prepare reports, estimates, and feasibility studies.

Communication and Relationship Management Skills

Demonstrated communication, consultative and advisory skills to act as the lead accessibility resource and provide expertise to ongoing contacts.

Must haves:

AODA Skills screen reader and testing

General PM skills - cross-functionality skills","[{'items': ['Description:\n\nResponsibilities: Develops, updates, analyses and edits content and functionality for websites; develops content strategy; integrating web initiatives into existing templates Review and ensure websites are standards compliant for the Government of Ontario. Experience with content creation and driving content strategy Awareness of emerging trends and directions in web and their application within the Government framework Knowledge and understanding of Accessibility for Ontarians with Disability Act (AODA) and related regulations and standards Experience in standard web programming environments (e.g. HTML5, CSS3, XML, JavaScript, ASP, .NET, PHP, Ruby.ASP, Java) Knowledge of Open Source software initiatives (e.g. Linux, WordPress, Drupal, Solr, Git, Apache) (e.g. WordPress, various Search engines and web development frameworks and APIs), including design criteria, security and recovery procedures, code management and deployment practices, as well as experience in the... development/preparation of technical specifications for installation, testing frameworks, and performance of integrated, multi- service systems. Knowledge of PHP, Java, JavaScript, Angular, Node, MySQL, MongoDB, Drupal, Twig, and\n\nSkill Set Requirements\n\nUser Experience Design/ Quality Assurance\n\nProvides quality assurance and user experience design expertise and advice to internal stakeholders on design principles and the development and implementation of best practices in accessibility to ensure compliance with legal requirements and industry best practices..\n\nProject Management\n\nLeads and/or carries out large scale and sensitive projects and/or significant components of other projects with accessibility design elements, to mitigate identified risk to an acceptable level, ensuring compliance and integration with the Accessibility for Ontarians with Disabilities Act (AODA) standards and Ontario s Accessible by Design: 2022 2025 OPS Multi-Year Accessibility Plan goals; provide supervision/technical direction to teams, coordinate development of design specifications, prepare reports, estimates, and feasibility studies.\n\nCommunication and Relationship Management Skills\n\nDemonstrated communication, consultative and advisory skills to act as the lead accessibility resource and provide expertise to ongoing contacts.\n\nMust haves:\n\nAODA Skills screen reader and testing\n\nGeneral PM skills - cross-functionality skills']}]","[{'link': 'http://www.amiseq.com/', 'text': 'amiseq.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&ucbcb=1&q=Amiseq+Inc.&sa=X&ved=0ahUKEwim-o_q176FAxUzlIQIHZJbCqUQmJACCOAM', 'text': 'See web results for Amiseq Inc.'}]","['2 days ago', 'Contractor', 'No degree mentioned']","{'postedAt': '2 days ago', 'scheduleType': 'Contractor'}","{'title': 'Apply directly on Dice.com', 'link': 'https://www.dice.com/job-detail/d64d4f16-2bdc-467f-90b6-6e1f622d360d?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Software Developer,2024-04-13 03:39:39.800626
Infotainment Software Developer,General Motors,Toronto,via General Motors Careers,"• Leads and generates technical solutions including specifying of requirements, functional decomposition, analysis, development and testing for current, new and major programs.
• Lead development of software system team design content and software anomaly corrections.
• Performs complex design analysis
• Specifies and balances system requirements
• Provide, communicate, and support common best practices among software community
• Performs as Subject Matter Expert (SME) for at least one platform or application component

Hybrid: - Position does not require an employee to be on-site full-time but the general expectation is that the employee be onsite an average of three (3) days each week.","[{'items': ['• Leads and generates technical solutions including specifying of requirements, functional decomposition, analysis, development and testing for current, new and major programs.\n• Lead development of software system team design content and software anomaly corrections.\n• Performs complex design analysis\n• Specifies and balances system requirements\n• Provide, communicate, and support common best practices among software community\n• Performs as Subject Matter Expert (SME) for at least one platform or application component\n\nHybrid: - Position does not require an employee to be on-site full-time but the general expectation is that the employee be onsite an average of three (3) days each week.']}]","[{'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&ucbcb=1&q=General+Motors&sa=X&ved=0ahUKEwim-o_q176FAxUzlIQIHZJbCqUQmJACCJwN', 'text': 'See web results for General Motors'}]","['23 days ago', 'Full-time', 'No degree mentioned']","{'postedAt': '23 days ago', 'scheduleType': 'Full-time'}","{'title': 'Apply on General Motors Careers', 'link': 'https://search-careers.gm.com/en/jobs/jr-202403856/infotainment-software-developer/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Software Developer,2024-04-13 03:39:39.800626
Senior Software Developer II,Loopio,Toronto,via LinkedIn,"Loopio is a workplace that unleashes learning & growth opportunities for our Loopers. We provide autonomous, challenging work that allows each employee to master their craft. We attract and retain people who are naturally curious, have grit and are eager to grow and build their careers. At Loopio, we genuinely support each other, because true success comes from working as #oneteam.

Loopio is looking for a passionate and endlessly curious Senior Software Developer to join one of our growing teams. You will work cross-functionally with a team of innovative Engineers, Product Managers, and Designers to deliver a world-class product to our users. We strongly focus on collaboration and working together to support each other in everything we do.

What You'll Be Doing
• Leading and rapidly building end-to-end features from scratch for Loopio’s web platform
• Proactively build features and implement tests to prevent bugs.
• Interact with and gather detailed feedback from our customers... because you understand that creating a user-centric experience comes first
• Collaborate closely with our Product Managers and Product Designers in an agile environment to bring features to life and iterate on them based on our customers' feedback
• Mentor and coach others, providing technical guidance and helping build an environment of knowledge-sharing and encouraged feedback
• Works across teams to foster a culture of architecture that allows for iterative, autonomous development and future scaling
• Often helps refine roadmaps across teams based on technical strategy & constraints
• Comfortable leading technical design discussions and facilitating technical decision making. Experience as a technical lead is a bonus!

What You'll Bring to the Team
• 7+ years of professional software development experience
• Strong experience in backend, background of either PHP, Python or Java
• Experience in frontend development, with a solid understanding of React, Javascript and TypeScript
• Strong understanding of database design and RDBMS such as MySQL, including topics like subqueries, queries optimization and indexes
• Proficient in using and designing RESTful APIs
• Mentorship to other engineers through coaching, design and code reviews
• Comfortable guiding technical design discussions and facilitating technical decision-making
• A growing passion for driving processes and improving software development productivity for your team
• Experience with architectural best practices, with a good grasp of design principles and patterns
• Passion about code quality and tests because you can’t stand crappy software
• Experience in the following is a plus: AWS, Monolithic and Microservice Architecture, Cypress, Elasticsearch, Codeception and integration with third party apps

Where You'll Work
• Loopio is a remote-first workplace because we recognize the advantages of working flexibly. We have two Hub Regions, which means that employees live and work within a 300 KM radius of Toronto (within Ontario) or Vancouver (within British Columbia) and work within regular business hours in their timezone.
• Loopio’s office headquarters are located in Toronto’s vibrant Kensington Market. All Loopers have the option to work from home. Ontario Loopers have the option to work in the Toronto HQ and BC Loopers may work from our co-working office in Gastown Vancouver. It is whatever works best for you!
• You’ll collaborate with your teams virtually (we’re just a Zoom call away!) and have established core sync hours and focus time during the workday to enable us to work smarter together

Why You'll Love Working at Loopio
• Your manager supports your development by providing ongoing feedback and regular 1-on-1s
• You have tons of autonomy and responsibility: this role provides an opportunity to try new things and push creative boundaries
• You’ll learn more than you thought was possible; our team is obsessed with personal and professional growth (every Looper receives a professional mastery allowance each year)
• You’ll be set up to work remotely with a MacBook laptop, a monthly phone and internet allowance, and a work-from-home budget to help get your home office all set up!
• Join us in regular company socials, AMA (Ask-Me-Anything), and quarterly kick-off to celebrate the big wins and milestones as #oneteam!
• You’ll be joining a culture that has thoughtfully built out opportunities for connections in a remote first environment
• We have Employee Resource Groups, House Teams (curious? ask us about it!), virtual yoga, cooking classes and many more moments for us to have fun and learn together!
• You’ll be a part of an award-winning workplace and one of Canada’s fastest growing companies with ample opportunity to make a big impact here!

We recognize that all too often, potential candidates don’t apply for a position simply because they don’t hit every single criteria included in the job description—particularly members of underrepresented groups.

Whether or not your experience checks off all the boxes on a job posting, we still encourage you to apply to ensure that your application receives a review from our team. We understand that a resume can only showcase so much during the applicant stage, so we've created prompts in the application for you to share more about yourself. If you've made a career transition (or a few!), you’re self taught in a new role, or you have skills/experience you’d like to highlight, we want to hear more about what you could bring to the table.

Loopio is an equal opportunity employer that is deeply committed to building equitable workplaces that are diverse and inclusive. We actively encourage candidates from all backgrounds and lifestyles to consider us as a future employer. Please contact a member of our Talent Experience team (work@loopio.com) should you require accommodations at any point during our virtual interview processes","[{'items': [""Loopio is a workplace that unleashes learning & growth opportunities for our Loopers. We provide autonomous, challenging work that allows each employee to master their craft. We attract and retain people who are naturally curious, have grit and are eager to grow and build their careers. At Loopio, we genuinely support each other, because true success comes from working as #oneteam.\n\nLoopio is looking for a passionate and endlessly curious Senior Software Developer to join one of our growing teams. You will work cross-functionally with a team of innovative Engineers, Product Managers, and Designers to deliver a world-class product to our users. We strongly focus on collaboration and working together to support each other in everything we do.\n\nWhat You'll Be Doing\n• Leading and rapidly building end-to-end features from scratch for Loopio’s web platform\n• Proactively build features and implement tests to prevent bugs.\n• Interact with and gather detailed feedback from our customers... because you understand that creating a user-centric experience comes first\n• Collaborate closely with our Product Managers and Product Designers in an agile environment to bring features to life and iterate on them based on our customers' feedback\n• Mentor and coach others, providing technical guidance and helping build an environment of knowledge-sharing and encouraged feedback\n• Works across teams to foster a culture of architecture that allows for iterative, autonomous development and future scaling\n• Often helps refine roadmaps across teams based on technical strategy & constraints\n• Comfortable leading technical design discussions and facilitating technical decision making. Experience as a technical lead is a bonus!\n\nWhat You'll Bring to the Team\n• 7+ years of professional software development experience\n• Strong experience in backend, background of either PHP, Python or Java\n• Experience in frontend development, with a solid understanding of React, Javascript and TypeScript\n• Strong understanding of database design and RDBMS such as MySQL, including topics like subqueries, queries optimization and indexes\n• Proficient in using and designing RESTful APIs\n• Mentorship to other engineers through coaching, design and code reviews\n• Comfortable guiding technical design discussions and facilitating technical decision-making\n• A growing passion for driving processes and improving software development productivity for your team\n• Experience with architectural best practices, with a good grasp of design principles and patterns\n• Passion about code quality and tests because you can’t stand crappy software\n• Experience in the following is a plus: AWS, Monolithic and Microservice Architecture, Cypress, Elasticsearch, Codeception and integration with third party apps\n\nWhere You'll Work\n• Loopio is a remote-first workplace because we recognize the advantages of working flexibly. We have two Hub Regions, which means that employees live and work within a 300 KM radius of Toronto (within Ontario) or Vancouver (within British Columbia) and work within regular business hours in their timezone.\n• Loopio’s office headquarters are located in Toronto’s vibrant Kensington Market. All Loopers have the option to work from home. Ontario Loopers have the option to work in the Toronto HQ and BC Loopers may work from our co-working office in Gastown Vancouver. It is whatever works best for you!\n• You’ll collaborate with your teams virtually (we’re just a Zoom call away!) and have established core sync hours and focus time during the workday to enable us to work smarter together\n\nWhy You'll Love Working at Loopio\n• Your manager supports your development by providing ongoing feedback and regular 1-on-1s\n• You have tons of autonomy and responsibility: this role provides an opportunity to try new things and push creative boundaries\n• You’ll learn more than you thought was possible; our team is obsessed with personal and professional growth (every Looper receives a professional mastery allowance each year)\n• You’ll be set up to work remotely with a MacBook laptop, a monthly phone and internet allowance, and a work-from-home budget to help get your home office all set up!\n• Join us in regular company socials, AMA (Ask-Me-Anything), and quarterly kick-off to celebrate the big wins and milestones as #oneteam!\n• You’ll be joining a culture that has thoughtfully built out opportunities for connections in a remote first environment\n• We have Employee Resource Groups, House Teams (curious? ask us about it!), virtual yoga, cooking classes and many more moments for us to have fun and learn together!\n• You’ll be a part of an award-winning workplace and one of Canada’s fastest growing companies with ample opportunity to make a big impact here!\n\nWe recognize that all too often, potential candidates don’t apply for a position simply because they don’t hit every single criteria included in the job description—particularly members of underrepresented groups.\n\nWhether or not your experience checks off all the boxes on a job posting, we still encourage you to apply to ensure that your application receives a review from our team. We understand that a resume can only showcase so much during the applicant stage, so we've created prompts in the application for you to share more about yourself. If you've made a career transition (or a few!), you’re self taught in a new role, or you have skills/experience you’d like to highlight, we want to hear more about what you could bring to the table.\n\nLoopio is an equal opportunity employer that is deeply committed to building equitable workplaces that are diverse and inclusive. We actively encourage candidates from all backgrounds and lifestyles to consider us as a future employer. Please contact a member of our Talent Experience team (work@loopio.com) should you require accommodations at any point during our virtual interview processes""]}]","[{'link': 'http://www.loopio.com/', 'text': 'loopio.com'}, {'link': 'https://www.google.com/search?sca_esv=6226dd684e23ec85&sca_upv=1&ucbcb=1&q=Loopio&sa=X&ved=0ahUKEwim-o_q176FAxUzlIQIHZJbCqUQmJACCN0N', 'text': 'See web results for Loopio'}]","['2 days ago', 'Work from home', 'Full-time', 'No degree mentioned']","{'postedAt': '2 days ago', 'scheduleType': 'Full-time', 'workFromHome': True}","{'title': 'Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/senior-software-developer-ii-at-loopio-3890887479?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}",Software Developer,2024-04-13 03:39:39.800626
